<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Learning - 4&nbsp; Parameter Estimation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./learningtypes.html" rel="next">
<link href="./linalg.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./statmodels.html">Part I. Foundation</a></li><li class="breadcrumb-item"><a href="./estimation.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistical Learning</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part I. Foundation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./biasvariance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learningtypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Types of Statistical Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Part II. Supervised Learning I: Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regglobal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Classical Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regfeature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regnlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nonlinear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regdiscrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Discrete Target Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reglocal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Local Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Part III. Supervised Learning II: Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression Approach to Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Classification with Random Inputs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supportvectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vectors</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Part IV. Decision Trees</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decisiontrees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Regression and Classification Trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treesinR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Trees in <code>R</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treesInPython.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Trees in Python</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Part V. Ensemble Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ensemble_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Bayesian Model Averaging</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Part VI. Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsuper_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Principal Component Analysis (PCA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Cluster Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mbc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Model-based Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./arules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Association Rules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Part VII. Supervised Learning III: Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Generalized Additive Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./corrdata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Correlated Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Mixed Models for Longitudinal Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Part VIII. Neural Networks and Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Training Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann_R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Neural Networks in <code>R</code> (with Keras)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reinforcement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Part IX. Explainability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./explainability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Interpretability and Explainability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">4.1</span> Introduction</a></li>
  <li><a href="#least-squares-estimation" id="toc-least-squares-estimation" class="nav-link" data-scroll-target="#least-squares-estimation"><span class="header-section-number">4.2</span> Least Squares Estimation</a>
  <ul>
  <li><a href="#sec-ols" id="toc-sec-ols" class="nav-link" data-scroll-target="#sec-ols">Ordinary Least Squares (OLS)</a>
  <ul class="collapse">
  <li><a href="#sec-least-squares-from-scratch" id="toc-sec-least-squares-from-scratch" class="nav-link" data-scroll-target="#sec-least-squares-from-scratch">Least squares from scratch</a></li>
  </ul></li>
  <li><a href="#sec-wls-gls" id="toc-sec-wls-gls" class="nav-link" data-scroll-target="#sec-wls-gls">Weighted and Generalized Least Squares</a></li>
  <li><a href="#sec-nonlinear-least-squares" id="toc-sec-nonlinear-least-squares" class="nav-link" data-scroll-target="#sec-nonlinear-least-squares">Nonlinear Least Squares</a>
  <ul class="collapse">
  <li><a href="#gauss-newton-from-scratch" id="toc-gauss-newton-from-scratch" class="nav-link" data-scroll-target="#gauss-newton-from-scratch">Gauss-Newton from scratch</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation"><span class="header-section-number">4.3</span> Maximum Likelihood Estimation</a>
  <ul>
  <li><a href="#linear-model-with-gaussian-errors" id="toc-linear-model-with-gaussian-errors" class="nav-link" data-scroll-target="#linear-model-with-gaussian-errors">Linear Model with Gaussian Errors</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./statmodels.html">Part I. Foundation</a></li><li class="breadcrumb-item"><a href="./estimation.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-estimation" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">4.1</span> Introduction</h2>
<p>Statistical models contain two types of unknown quantities, <strong>parameters</strong> and <strong>hyperparameters</strong>. Parameters describe the distributional properties of the data; they are part of the mean function or the variance-covariance structure of the model. They are estimated from the data.</p>
<p>This chapter is not concerned with tuning hyperparameters but with the principles we use to estimate parameters of a model’s mean function from data—that is, estimating the internal parameters of the model.</p>
<p>Finding parameter estimates can be expressed as a numerical problem: find the values that minimize some metric of discrepancy between data and the model. The discrepancy can be some measure of <strong>loss</strong> such as squared error between observed and predicted target values <span class="math display">\[\left( y_i - \widehat{f}_i(\textbf{x};\boldsymbol{\theta}) \right)^2\]</span> or the misclassification error <span class="math display">\[
I(y_i \ne \widehat{f}_i(\textbf{x};\boldsymbol{\theta}))
\]</span> and the loss for the entire data set is summed over all observations, for example <span class="math display">\[
\ell(\textbf{y};\boldsymbol{\theta}) = \sum_{i=1}^n \left( y_i - \widehat{y}_i \right)^2
\]</span></p>
<p>The solution to the minimization problem <span class="math display">\[
\mathop{\mathrm{arg\,min}}_\boldsymbol{\theta}\, \ell(\textbf{y};\boldsymbol{\theta})
\]</span> is the estimator <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> of the parameters <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>In some situations, this minimization problem has a closed-form solution that can be computed directly. In other cases we have to rely on numerical procedures to find a solution iteratively or approximations to simplify a complex or intractable problem. The solution <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> is unique for some problems and might be one of many solutions, not all equally good.</p>
<p>Expressing parameter estimation as a general minimization problem does not reveal the foundations of important principles in parameter estimation, in particular, least squares and maximum likelihood estimation. We introduce these principles based on geometric and probabilistic considerations, the relationship to function minimization will be obvious.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>All optimization tasks will be presented as minimization problem. Finding the maximum of a function can be turned into a minimization of its negative value.</p>
</div>
</div>
</section>
<section id="least-squares-estimation" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="least-squares-estimation"><span class="header-section-number">4.2</span> Least Squares Estimation</h2>
<p>Least squares estimation is arguably one of the most important estimation principles and rests on a geometric concept. Suppose we have a model with additive errors, <span class="math inline">\(\textbf{Y}= \mathbf{f}(\textbf{x}; \boldsymbol{\theta}) + \boldsymbol{\epsilon}\)</span>. The function <span class="math inline">\(\mathbf{f}()\)</span> is an <span class="math inline">\((n \times 1)\)</span> vector of the mean function evaluations, the <span class="math inline">\(i\)</span><sup>th</sup> value is <span class="math inline">\(f(\textbf{x}_i;\boldsymbol{\theta})\)</span>. The least squares estimate <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> of <span class="math inline">\(\boldsymbol{\theta}\)</span> is the value that is closest to <span class="math inline">\(\textbf{Y}\)</span> among all possible values <span class="math inline">\(\tilde{\boldsymbol{\theta}}\)</span>.</p>
<section id="sec-ols" class="level3">
<h3 class="anchored" data-anchor-id="sec-ols">Ordinary Least Squares (OLS)</h3>
<p>Consider the identity</p>
<p><span class="math display">\[
\textbf{Y}= \textbf{f}(\textbf{x};\tilde{\boldsymbol{\theta}}) + \left(\textbf{Y}- \textbf{f}(\textbf{x};\tilde{\boldsymbol{\theta}}) \right)
\]</span></p>
<p>that expresses the observed data <span class="math inline">\(\textbf{Y}\)</span> as the sum of fitted values and residuals.</p>
<p>By the Pythagorean theorem, the solution <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> with the smallest vector of residuals is the orthogonal projection of <span class="math inline">\(\textbf{Y}\)</span> onto <span class="math inline">\(\textbf{f}\)</span>, which implies that <span class="math display">\[
\left(\textbf{Y}- \textbf{f}(\textbf{x};\widehat{\boldsymbol{\theta}}) \right)^\prime \textbf{f}(\textbf{x};\widehat{\boldsymbol{\theta}}) = \textbf{0}
\]</span> When <span class="math inline">\(\textbf{f}(\textbf{x};\boldsymbol{\theta})\)</span> is linear in the parameters, it is common to denote the coefficients (parameters) as <span class="math inline">\(\boldsymbol{\beta}\)</span> instead of the more generic <span class="math inline">\(\boldsymbol{\theta}\)</span>. We thus write the standard linear (regression) as <span class="math display">\[
\textbf{Y}= \textbf{X}\boldsymbol{\beta}+ \boldsymbol{\epsilon}
\]</span> and the orthogonality criterion becomes <span class="math display">\[
\left(\textbf{Y}- \textbf{X}\widehat{\boldsymbol{\beta}}\right)^\prime \textbf{X}\widehat{\boldsymbol{\beta}} = \textbf{0}
\]</span> It is easy to show that this implies <span class="math display">\[
\textbf{X}^\prime\textbf{X}\widehat{\boldsymbol{\beta}} = \textbf{X}^\prime\textbf{Y}
\]</span> and if the <strong>cross-product matrix</strong> <span class="math inline">\(\textbf{X}^\prime\textbf{X}\)</span> is of full rank, the (ordinary) least squares estimator is <span class="math display">\[
\widehat{\boldsymbol{\beta}} = (\textbf{X}^\prime\textbf{X})^{-1}\textbf{X}^\prime\textbf{Y}
\]</span> Expressed as the problem of minimizing a loss function, <strong>ordinary least squares</strong> (OLS) is approached as follows. Suppose that we measure loss as squared-error loss <span class="math inline">\((y_i - \widehat{y}_i)^2\)</span>. In the linear model where <span class="math inline">\(\widehat{y}_i = \textbf{x}_i^\prime \widehat{\boldsymbol{\beta}}\)</span>, the loss function is the residual (error) sum of squares <span class="math display">\[
\text{SSE}(\boldsymbol{\beta}) = \boldsymbol{\epsilon}^\prime\boldsymbol{\epsilon}= \left( \textbf{Y}-\textbf{X}^\prime\boldsymbol{\beta}\right)^\prime \left(\textbf{Y}-\textbf{X}^\prime\boldsymbol{\beta}\right)
\]</span> and the minimization problem is <span class="math display">\[
\mathop{\mathrm{arg\,min}}_\boldsymbol{\beta}\, \text{SSE}(\boldsymbol{\beta})
\]</span></p>
<p>To find the minimum we set to zero the derivative of <span class="math inline">\(\text{SSE}(\boldsymbol{\beta})\)</span> with respect to <span class="math inline">\(\boldsymbol{\beta}\)</span>. Expanding the residual sum of squares yields <span class="math display">\[
SSE(\boldsymbol{\beta}) = \textbf{Y}^\prime\textbf{Y}- 2\boldsymbol{\beta}^\prime\textbf{X}^\prime\textbf{Y}+ \boldsymbol{\beta}^\prime\textbf{X}^\prime\textbf{X}\boldsymbol{\beta}
\]</span></p>
<p>The derivative (<a href="linalg.html#sec-matrix-differentiation" class="quarto-xref"><span>Section 3.8</span></a>) with respect to <span class="math inline">\(\boldsymbol{\beta}\)</span> is <span class="math display">\[
\frac{\partial\,\text{SSE}(\boldsymbol{\beta})}{\partial\boldsymbol{\beta}} = -2\textbf{X}^\prime\textbf{Y}+ 2\textbf{X}^\prime\textbf{X}\boldsymbol{\beta}
\]</span></p>
<p>Setting the derivative to zero and solving yields the <strong>normal equations</strong> as above: <span class="math display">\[
\textbf{X}^\prime\textbf{X}\widehat{\boldsymbol{\beta}} = \textbf{X}^\prime\textbf{Y}
\]</span> and the OLS estimator <span class="math display">\[
\widehat{\boldsymbol{\beta}} = (\textbf{X}^\prime\textbf{X})^{-1}\textbf{X}^\prime\textbf{Y}
\]</span> The vector of fitted values, <span class="math inline">\(\widehat{\textbf{y}}\)</span> is obtained by pre-multiplying with the data matrix</p>
<p><span class="math display">\[\begin{align*}
    \widehat{\textbf{Y}} &amp;= \textbf{X}^\prime\widehat{\boldsymbol{\beta}} = (\textbf{X}^\prime\textbf{X})^{-1}\textbf{X}^\prime\textbf{Y}\\
                  &amp;= \textbf{H}\textbf{Y}
\end{align*}\]</span></p>
<p>The matrix <span class="math inline">\(\textbf{H}\)</span> is called the “Hat” matrix, because pre-multiplying <span class="math inline">\(\textbf{Y}\)</span> with <span class="math inline">\(\textbf{H}\)</span> “puts hats on the <span class="math inline">\(y\)</span>s” (<a href="linalg.html#sec-hat-matrix" class="quarto-xref"><span>Section 3.6.2</span></a>). The last equation shows that the OLS estimator is a linear estimator, <span class="math inline">\(\widehat{y}_i\)</span> is a linear combination of all <span class="math inline">\(y_i\)</span>, the weights of the linear combination are given by the entries of the hat matrix.</p>
<p>The statistical properties of the OLS estimator depend on the nature of the random error process. The most common assumption is that the <span class="math inline">\(\epsilon_i\)</span> have zero mean and are <em>iid</em>, independently and identically distributed, formally, <span class="math inline">\(\boldsymbol{\epsilon}\sim (\textbf{0},\sigma^2\textbf{I})\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The statement <span class="math inline">\(\boldsymbol{\epsilon}\sim (\textbf{0},\sigma^2\textbf{I})\)</span> is technically weaker than stating independence, it implies zero correlations among the observations. Independent random variables are uncorrelated, but the reverse is not necessarily true. You can conclude independence from lack of correlations for Gaussian (normal) random variables, but not generally.</p>
</div>
</div>
<p>In the <em>iid</em> case, the OLS estimator is unbiased, <span class="math inline">\(\text{E}[\widehat{\boldsymbol{\beta}}] = \boldsymbol{\beta}\)</span> and has variance <span class="math inline">\(\text{Var}[\widehat{\boldsymbol{\beta}}] = \sigma^2(\textbf{X}^\prime\textbf{X})^{-1}\)</span>. In fact, it is a <strong>BLUE</strong> (best linear unbiased estimator) in this situation. No other unbiased estimator has smaller variance than the OLS estimator. However, it is possible that other estimators have smaller <strong>mean squared error</strong> than the OLS estimator, if the introduction of bias is more than offset by a reduction of the variance of the estimator. This is important in high-dimensional problems where the number of predictors (<span class="math inline">\(p\)</span>) is large. As <span class="math inline">\(p\)</span> increases, the OLS estimator becomes more unstable, especially if the predictors are highly related to each other (a condition known as multi-collinearity). The values of <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> then have a tendency to vary widely. Estimators that limit the variability of the model coefficients through regularization techniques, such as Ridge or Lasso regression, can have considerably lower variance at the expense of some bias, leading to better mean squared error.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A Gaussian distribution (normality) assumption is not a requirement of the linear model or of least squares estimation. The OLS estimator has desirable properties even if the errors are not normally distributed. However, making statements about the significance of the <span class="math inline">\(\beta_j\)</span> requires additional assumptions such as <span class="math inline">\(\boldsymbol{\epsilon}\sim G(\textbf{0},\sigma^2\textbf{I})\)</span>.</p>
<p>When <span class="math inline">\(\boldsymbol{\epsilon}\sim G(\textbf{0},\sigma^2\textbf{I})\)</span>, the OLS estimator is not only BLUE but a minimum variance unbiased estimator (<strong>MVUE</strong>), best among all unbiased estimators, not only those estimators linear in <span class="math inline">\(\textbf{Y}\)</span>.</p>
</div>
</div>
<section id="sec-least-squares-from-scratch" class="level4">
<h4 class="anchored" data-anchor-id="sec-least-squares-from-scratch">Least squares from scratch</h4>
<p>To understand statistical computing, it is a good idea to implement some algorithms from scratch. That also helps to identify the numbers reported by statistical software. Here we implement the OLS estimator from scratch in <code>R</code> using the <code>fitness</code> data set. The data comprise measurements of aerobic capacity and other attributes on 31 men involved in a physical fitness course at N.C. State University.</p>
<p>Aerobic capacity is the ability of the heart and lungs to provide the body with oxygen. It is a measure of fitness and expressed as the oxygen intake in ml per kg body weight per minute. Measuring aerobic capacity is expensive and time consuming compared to attributes such as age, weight, and pulse. The question is whether aerobic capacity can be predicted from the easily measurable attributes. If so, a predictive equation can reduce time and effort to assess aerobic capacity.</p>
<p>The variables are</p>
<ul>
<li><strong>Age</strong>: age in years</li>
<li><strong>Weight</strong>: weight in kg</li>
<li><strong>Oxygen</strong>: oxygen intake rate (ml per kg body weight per minute)</li>
<li><strong>RunTime</strong>: time to run 1.5 miles (minutes)</li>
<li><strong>RestPulse</strong>: heart rate while resting</li>
<li><strong>RunPulse</strong>: heart rate while running (same time Oxygen rate measured)</li>
<li><strong>MaxPulse</strong>: maximum heart rate recorded while running</li>
</ul>
<p>The linear model we have in mind is <span class="math display">\[
\text{Oxygen}_i = \beta_0 + \beta_1\text{Age}_i + \beta_2\text{Weight}_i + \beta_3\text{RunTime}_i + \beta_4\text{RestPulse}_i + \beta_5\text{RunPulse}_i + \beta_6\text{MaxPulse}_i + \epsilon_i
\]</span> and the <span class="math inline">\(\epsilon_i\)</span> are assumed zero-mean random variables with common variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The following code loads the data from the <code>ads</code> DuckDB database.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"duckdb"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>con <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(<span class="fu">duckdb</span>(),<span class="at">dbdir =</span> <span class="st">"ads.ddb"</span>,<span class="at">read_only=</span><span class="cn">TRUE</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">dbGetQuery</span>(con, <span class="st">"SELECT * FROM fitness"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Age Weight Oxygen RunTime RestPulse RunPulse MaxPulse
1  44  89.47 44.609   11.37        62      178      182
2  40  75.07 45.313   10.07        62      185      185
3  44  85.84 54.297    8.65        45      156      168
4  42  68.15 59.571    8.17        40      166      172
5  38  89.02 49.874    9.22        55      178      180
6  47  77.45 44.811   11.63        58      176      176</code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>con <span class="op">=</span> duckdb.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"ads.ddb"</span>, read_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> con.sql(<span class="st">"SELECT * FROM fitness"</span>).df()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>con.close()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>fit.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Age  Weight  Oxygen  RunTime  RestPulse  RunPulse  MaxPulse
0   44   89.47  44.609    11.37         62       178       182
1   40   75.07  45.313    10.07         62       185       185
2   44   85.84  54.297     8.65         45       156       168
3   42   68.15  59.571     8.17         40       166       172
4   38   89.02  49.874     9.22         55       178       180</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The target variable for the linear model is <code>Oxygen</code>, the remaining variables are inputs to the regression. The next statements create the <span class="math inline">\(\textbf{y}\)</span> vector and the <span class="math inline">\(\textbf{X}\)</span> matrix for the model. Note that the first column of <span class="math inline">\(\textbf{X}\)</span> is a vector of ones, representing the “input” for the intercept <span class="math inline">\(\beta_0\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(fit[,<span class="fu">which</span>(<span class="fu">names</span>(fit)<span class="sc">==</span><span class="st">"Oxygen"</span>)])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(<span class="at">Intcpt=</span><span class="fu">rep</span>(<span class="dv">1</span>,<span class="fu">nrow</span>(fit)), </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                     fit[,<span class="fu">which</span>(<span class="fu">names</span>(fit)<span class="sc">!=</span><span class="st">"Oxygen"</span>)]))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Intcpt Age Weight RunTime RestPulse RunPulse MaxPulse
[1,]      1  44  89.47   11.37        62      178      182
[2,]      1  40  75.07   10.07        62      185      185
[3,]      1  44  85.84    8.65        45      156      168
[4,]      1  42  68.15    8.17        40      166      172
[5,]      1  38  89.02    9.22        55      178      180
[6,]      1  47  77.45   11.63        58      176      176</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> fit[[<span class="st">'Oxygen'</span>]].values</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># First create a column of 1s for the intercept</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> np.ones((<span class="bu">len</span>(fit), <span class="dv">1</span>))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all columns except Oxygen</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>X_without_intercept <span class="op">=</span> fit.drop(<span class="st">'Oxygen'</span>, axis<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine intercept and other columns and add column names</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.hstack((intercept, X_without_intercept))</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>X_column_names <span class="op">=</span> [<span class="st">'Intcpt'</span>] <span class="op">+</span> <span class="bu">list</span>(fit.drop(<span class="st">'Oxygen'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First few rows of X:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>First few rows of X:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X[:<span class="dv">5</span>, :])  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[  1.    44.    89.47  11.37  62.   178.   182.  ]
 [  1.    40.    75.07  10.07  62.   185.   185.  ]
 [  1.    44.    85.84   8.65  45.   156.   168.  ]
 [  1.    42.    68.15   8.17  40.   166.   172.  ]
 [  1.    38.    89.02   9.22  55.   178.   180.  ]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Column names:"</span>, X_column_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Column names: ['Intcpt', 'Age', 'Weight', 'RunTime', 'RestPulse', 'RunPulse', 'MaxPulse']</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>Next we are building the <span class="math inline">\(\textbf{X}^\prime\textbf{X}\)</span> matrix and compute its inverse, <span class="math inline">\((\textbf{X}^\prime\textbf{X})^{-1}\)</span>, with the <code>solve()</code> function. <code>t()</code> transposes a matrix and <code>%*%</code> indicates that we are performing matrix multiplication rather than elementwise multiplication.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>XpX <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> X</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>XpXInv <span class="ot">&lt;-</span> <span class="fu">solve</span>(XpX)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Next we are building the <span class="math inline">\(\textbf{X}^\prime\textbf{X}\)</span> matrix and compute its inverse, <span class="math inline">\((\textbf{X}^\prime\textbf{X})^{-1}\)</span>, with the <code>np.linalg.inv()</code> function. <code>.T</code> transposes a matrix and <code>@</code> indicates that we are performing matrix multiplication rather than elementwise multiplication.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>XpX <span class="op">=</span> X.T <span class="op">@</span> X</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative: XpX = np.matmul(X.T, X)</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>XpXInv <span class="op">=</span> np.linalg.inv(XpX)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>We can verify that <code>XpxInv</code> is indeed the inverse of <code>XpX</code> by multiplying the two. This should yield the identity matrix</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(XpX <span class="sc">%*%</span> XpXInv,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Intcpt Age Weight RunTime RestPulse RunPulse MaxPulse
Intcpt         1   0      0       0         0        0        0
Age            0   1      0       0         0        0        0
Weight         0   0      1       0         0        0        0
RunTime        0   0      0       1         0        0        0
RestPulse      0   0      0       0         1        0        0
RunPulse       0   0      0       0         0        1        0
MaxPulse       0   0      0       0         0        0        1</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">round</span>(XpX <span class="op">@</span> XpXInv,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([[ 1.,  0., -0.,  0.,  0., -0.,  0.],
       [-0.,  1.,  0.,  0.,  0.,  0., -0.],
       [ 0.,  0.,  1.,  0.,  0., -0.,  0.],
       [-0.,  0., -0.,  1.,  0., -0.,  0.],
       [-0.,  0., -0.,  0.,  1., -0.,  0.],
       [-0.,  0., -0.,  0.,  0.,  1.,  0.],
       [-0., -0., -0.,  0.,  0., -0.,  1.]])</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Next we compute the OLS estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span> and the predicted values <span class="math inline">\(\widehat{\textbf{y}} = \textbf{X}\widehat{\boldsymbol{\beta}}\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="ot">&lt;-</span> XpXInv <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  [,1]
Intcpt    102.93447948
Age        -0.22697380
Weight     -0.07417741
RunTime    -2.62865282
RestPulse  -0.02153364
RunPulse   -0.36962776
MaxPulse    0.30321713</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="op">=</span> XpXInv <span class="op">@</span> X.T <span class="op">@</span> y</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(beta_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 1.02934479e+02]
 [-2.26973796e-01]
 [-7.41774137e-02]
 [-2.62865282e+00]
 [-2.15336398e-02]
 [-3.69627758e-01]
 [ 3.03217129e-01]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> X <span class="op">@</span> beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>The estimate of the intercept is <span class="math inline">\(\widehat{\beta}_0\)</span> = 102.9344795, the estimate of the coefficient for <code>Age</code> is <span class="math inline">\(\widehat{\beta}_1\)</span> = -0.2269738 and so on.</p>
<p>The residuals <span class="math inline">\(\widehat{\boldsymbol{\epsilon}} = \textbf{y}- \widehat{\textbf{y}}\)</span>, the error sum of squares</p>
<p><span class="math display">\[
\text{SSE} = (\textbf{y}- \widehat{\textbf{y}} )^\prime (\textbf{y}- \widehat{\textbf{y}}) = \sum_{i=1}^n \left(y_i - \widehat{y}_i\right)^2
\]</span> and the estimate of the residual variance <span class="math display">\[
\widehat{\sigma}^2 = \frac{1}{n-r(\textbf{X})} \, \text{SSE}
\]</span></p>
<p>are computed as</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"Matrix"</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> y <span class="sc">-</span> y_hat</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>SSE <span class="ot">&lt;-</span> <span class="fu">sum</span>(residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(fit)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>rankX <span class="ot">&lt;-</span> <span class="fu">rankMatrix</span>(XpX)[<span class="dv">1</span>]</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>sigma2_hat <span class="ot">&lt;-</span> SSE<span class="sc">/</span>(n <span class="sc">-</span> rankX)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>SSE</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 128.8379</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>sigma2_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.368247</code></pre>
</div>
</div>
<p>We used the <code>rankMatrix</code> function in the <code>Matrix</code> package to compute the rank of <span class="math inline">\(\textbf{X}\)</span>, which is identical to the rank of <span class="math inline">\(\textbf{X}^\prime\textbf{X}\)</span>.</p>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y <span class="op">-</span> y_hat</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>SSE <span class="op">=</span> np.<span class="bu">sum</span>(residuals<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(fit)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>rankX <span class="op">=</span> np.linalg.matrix_rank(XpX)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>sigma2_hat <span class="op">=</span> SSE <span class="op">/</span> (n <span class="op">-</span> rankX)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"SSE: </span><span class="sc">{</span>SSE<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>SSE: 128.8379</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"sigma2_hat: </span><span class="sc">{</span>sigma2_hat<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>sigma2_hat: 5.3682</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>With these quantities available, the variance-covariance matrix of <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, <span class="math display">\[
\text{Var}[\widehat{\boldsymbol{\beta}}] = \sigma^2 (\textbf{X}^\prime\textbf{X})^{-1}
\]</span> can be estimated by substituting <span class="math inline">\(\widehat{\sigma}^2\)</span>. The standard errors of the regression coefficient estimates are the square roots of the diagonal values of this matrix.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>Var_beta_hat <span class="ot">&lt;-</span> sigma2_hat <span class="sc">*</span> XpXInv</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>se_beta_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(Var_beta_hat))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>se_beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Intcpt         Age      Weight     RunTime   RestPulse    RunPulse 
12.40325810  0.09983747  0.05459316  0.38456220  0.06605428  0.11985294 
   MaxPulse 
 0.13649519 </code></pre>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>Var_beta_hat <span class="op">=</span> sigma2_hat <span class="op">*</span> XpXInv</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>se_beta_hat <span class="op">=</span> np.sqrt(np.diag(Var_beta_hat))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(se_beta_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[12.4032581   0.09983747  0.05459316  0.3845622   0.06605428  0.11985294
  0.13649519]</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>Now let’s compare our results to the output from the <code>lm()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>linmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(Oxygen <span class="sc">~</span> ., <span class="at">data=</span>fit)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linmod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Oxygen ~ ., data = fit)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.4026 -0.8991  0.0706  1.0496  5.3847 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 102.93448   12.40326   8.299 1.64e-08 ***
Age          -0.22697    0.09984  -2.273  0.03224 *  
Weight       -0.07418    0.05459  -1.359  0.18687    
RunTime      -2.62865    0.38456  -6.835 4.54e-07 ***
RestPulse    -0.02153    0.06605  -0.326  0.74725    
RunPulse     -0.36963    0.11985  -3.084  0.00508 ** 
MaxPulse      0.30322    0.13650   2.221  0.03601 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.317 on 24 degrees of freedom
Multiple R-squared:  0.8487,    Adjusted R-squared:  0.8108 
F-statistic: 22.43 on 6 and 24 DF,  p-value: 9.715e-09</code></pre>
</div>
</div>
<p>Based on the quantities calculated earlier, the following code reproduces the <code>lm</code> summary in <code>R</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>tvals <span class="ot">&lt;-</span> beta_hat<span class="sc">/</span>se_beta_hat</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>pvals <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pt</span>(<span class="fu">abs</span>(tvals),n<span class="sc">-</span>rankX))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">cbind</span>(beta_hat, se_beta_hat, tvals, pvals)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(result) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Estimate"</span>, <span class="st">"Std. Error"</span>, <span class="st">"t value"</span>, <span class="st">"Pr(&gt;|t|)"</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(result,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Estimate Std. Error  t value Pr(&gt;|t|)
Intcpt    102.93448   12.40326  8.29899  0.00000
Age        -0.22697    0.09984 -2.27343  0.03224
Weight     -0.07418    0.05459 -1.35873  0.18687
RunTime    -2.62865    0.38456 -6.83544  0.00000
RestPulse  -0.02153    0.06605 -0.32600  0.74725
RunPulse   -0.36963    0.11985 -3.08401  0.00508
MaxPulse    0.30322    0.13650  2.22145  0.03601</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Residual standard error: "</span>, <span class="fu">sqrt</span>(sigma2_hat),<span class="st">" on "</span>, n<span class="sc">-</span>rankX, <span class="st">"degrees of freedom</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Residual standard error:  2.316948  on  24 degrees of freedom</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>( (y <span class="sc">-</span><span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span> )</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Multiple R-squared: "</span>, <span class="dv">1</span><span class="sc">-</span>SSE<span class="sc">/</span>SST, </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Adjusted R-squared: "</span>, <span class="dv">1</span> <span class="sc">-</span> (SSE<span class="sc">/</span>SST)<span class="sc">*</span>(n<span class="dv">-1</span>)<span class="sc">/</span>(n<span class="sc">-</span>rankX), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multiple R-squared:  0.8486719 Adjusted R-squared:  0.8108399 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>Fstat <span class="ot">&lt;-</span> ((SST<span class="sc">-</span>SSE)<span class="sc">/</span>(rankX<span class="dv">-1</span>)) <span class="sc">/</span> (SSE<span class="sc">/</span>(n<span class="sc">-</span>rankX))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"F-statistic: "</span>, Fstat, <span class="st">"on "</span>, </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    rankX<span class="dv">-1</span>, <span class="st">"and"</span>, n<span class="sc">-</span>rankX, <span class="st">"DF, p-value:"</span>, <span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(Fstat,rankX<span class="dv">-1</span>,n<span class="sc">-</span>rankX))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F-statistic:  22.43263 on  6 and 24 DF, p-value: 9.715305e-09</code></pre>
</div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<p>Now let’s compare our results to the output to the ordinary least squares fit in <code>statsmodels</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(fit.drop(<span class="st">'Oxygen'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> fit[<span class="st">'Oxygen'</span>]</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>linmod <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(linmod.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Oxygen   R-squared:                       0.849
Model:                            OLS   Adj. R-squared:                  0.811
Method:                 Least Squares   F-statistic:                     22.43
Date:                Tue, 10 Jun 2025   Prob (F-statistic):           9.72e-09
Time:                        11:55:17   Log-Likelihood:                -66.068
No. Observations:                  31   AIC:                             146.1
Df Residuals:                      24   BIC:                             156.2
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        102.9345     12.403      8.299      0.000      77.335     128.534
Age           -0.2270      0.100     -2.273      0.032      -0.433      -0.021
Weight        -0.0742      0.055     -1.359      0.187      -0.187       0.038
RunTime       -2.6287      0.385     -6.835      0.000      -3.422      -1.835
RestPulse     -0.0215      0.066     -0.326      0.747      -0.158       0.115
RunPulse      -0.3696      0.120     -3.084      0.005      -0.617      -0.122
MaxPulse       0.3032      0.136      2.221      0.036       0.022       0.585
==============================================================================
Omnibus:                        2.609   Durbin-Watson:                   1.711
Prob(Omnibus):                  0.271   Jarque-Bera (JB):                1.465
Skew:                          -0.069   Prob(JB):                        0.481
Kurtosis:                       4.056   Cond. No.                     7.91e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 7.91e+03. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># If you want to access specific components:</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Coefficients:", linmod.params)</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Standard errors:", linmod.bse)</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print("R-squared:", linmod.rsquared)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-wls-gls" class="level3">
<h3 class="anchored" data-anchor-id="sec-wls-gls">Weighted and Generalized Least Squares</h3>
<p>Another interesting feature of the OLS estimator is that it does not depend on the variability of the model errors. Whether <span class="math inline">\(\sigma^2\)</span> is large or small, the OLS estimator is only a function of <span class="math inline">\(\textbf{Y}\)</span> and <span class="math inline">\(\textbf{X}\)</span>. However, the error variance affects the variability of <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>.</p>
<p>When the error distribution is more complex than the <em>iid</em> case, the variance and covariances of the errors must be taken into account for least squares estimators to retain their optimality. The first case is that of uncorrelated errors that have unequal variances, a situation known as <strong>heteroscedasticity</strong>. The variance-covariance matrix of the <span class="math inline">\(\boldsymbol{\epsilon}\)</span> is then a diagonal matrix. Let’s call the inverse of the variance-covariance matrix <span class="math inline">\(\textbf{W}\)</span>. <span class="math inline">\(\textbf{W}\)</span> is a <span class="math inline">\((n \times n)\)</span> d iagonal matrix with <span class="math inline">\(1/\sigma^2_i\)</span>, the inverse of the variance of the <span class="math inline">\(i\)</span><sup>th</sup> observation, in the <span class="math inline">\(i\)</span><sup>th</sup> diagonal cell. The <strong>weighted least squares</strong> estimator <span class="math display">\[
\widehat{\boldsymbol{\beta}}_{WLS} = (\textbf{X}^\prime\textbf{W}\textbf{X})^{-1}\textbf{X}^\prime\textbf{W}\textbf{Y}
\]</span> is the optimal estimator in this situation.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>A weighted analysis is the correct approach when the weights are inversely proportional to the variance of the observations. This makes sense if we think of the weights as expressing how strongly the analysis should depend on a particular observation. A larger variance means that we are less certain about the observed value and thus should give the observation less weight.</p>
</div>
</div>
<p>In the weighted model the variance-covariance matrix of the errors are diagonal, the observations have unequal variances but are uncorrelated. If the errors are correlated, the variance-covariance matrix is not diagonal. Suppose that <span class="math inline">\(\boldsymbol{\epsilon}\sim (\textbf{0}, \textbf{V})\)</span>, the optimal least squares estimator is the <strong>generalized least squares</strong> estimator <span class="math display">\[
\widehat{\boldsymbol{\beta}}_{GLS} = (\textbf{X}^\prime\textbf{V}^{-1}\textbf{X})^{-1}\textbf{X}^\prime\textbf{V}^{-1}\textbf{Y}
\]</span></p>
<p>This seems like a small change from the weighted case, replacing <span class="math inline">\(\textbf{W}\)</span> with <span class="math inline">\(\textbf{V}\)</span>. So what is the big deal? In weighted analyses the weights are often known, at least up to a multiple. For example, when the variability of the target variable increases proportionally with one of the inputs, <span class="math inline">\(x_2\)</span> say, then <span class="math inline">\(\textbf{W}\)</span> is essentially known. In situations where we apply GLS estimation, <span class="math inline">\(\textbf{V}\)</span> is often not known and depends itself on parameters. The overall model then composes a model for the mean function that depends on <span class="math inline">\(\boldsymbol{\beta}\)</span> and a model for the error structure that depends on <span class="math inline">\(\boldsymbol{\theta}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
    \textbf{Y}&amp;= \textbf{X}\boldsymbol{\beta}+ \boldsymbol{\epsilon}\\
    \boldsymbol{\epsilon}&amp; \sim (\textbf{0}, \textbf{V}(\boldsymbol{\theta}))
\end{align*}\]</span></p>
<p>and both sets of parameters must be derived from the data. This is somewhat of a cat-and-mouse game. You need to know <span class="math inline">\(\boldsymbol{\beta}\)</span> to estimate <span class="math inline">\(\boldsymbol{\theta}\)</span> and the estimates of <span class="math inline">\(\boldsymbol{\theta}\)</span> depend on <span class="math inline">\(\boldsymbol{\beta}\)</span>. This tension is resolved by the <strong>estimated generalized least squares</strong> principle. Given an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span>, you compute the estimated GLS estimator <span class="math display">\[
\widehat{\boldsymbol{\beta}}_{EGLS} =  (\textbf{X}^\prime\textbf{V}(\widehat{\boldsymbol{\theta}})^{-1}\textbf{X})^{-1}\textbf{X}^\prime\textbf{V}(\widehat{\boldsymbol{\theta}})^{-1}\textbf{Y}
\]</span></p>
<p>With an updated estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span> you use a different estimation principle to compute an updated estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span>. This is the principle behind restricted maximum likelihood, a likelihood-based estimation principle important for mixed models.</p>
</section>
<section id="sec-nonlinear-least-squares" class="level3">
<h3 class="anchored" data-anchor-id="sec-nonlinear-least-squares">Nonlinear Least Squares</h3>
<p>The linear structure of the model <span class="math inline">\(\textbf{Y}= \textbf{X}\boldsymbol{\beta}+ \boldsymbol{\epsilon}\)</span> leads to a closed form solution of the least squares problem <span class="math display">\[
\widehat{\boldsymbol{\beta}} = (\textbf{X}^\prime\textbf{X})^{-1}\textbf{X}^\prime\textbf{Y}
\]</span></p>
<p>When the model is nonlinear in the parameters, <span class="math inline">\(\textbf{Y}= \textbf{f}(\textbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}\)</span>, finding the solution that minimizes</p>
<p><span id="eq-nonlin-sse"><span class="math display">\[
\text{SSE} = \left(\textbf{Y}- \textbf{f}(\textbf{x};\boldsymbol{\theta})\right)^\prime \left(\textbf{Y}- \textbf{f}(\textbf{x};\boldsymbol{\theta})\right)
\tag{4.1}\]</span></span></p>
<p>is not so straightforward, it requires an iterative approach. Starting from some initial guess for <span class="math inline">\(\boldsymbol{\theta}\)</span>, call it <span class="math inline">\(\widehat{\boldsymbol{\theta}}^{(0)}\)</span>, we iteratively update the guess until we have arrived at step <span class="math inline">\(t\)</span> at <span class="math inline">\(\widehat{\boldsymbol{\theta}}^{(t)}\)</span> such that <span class="math display">\[
\frac{\partial \,\text{SSE}}{\partial\boldsymbol{\theta}} \lvert_{\widehat{\boldsymbol{\theta}}^{(t)}} = \textbf{0}
\]</span> The left hand side of the previous expression is read as the derivative of SSE with respect to <span class="math inline">\(\boldsymbol{\theta}\)</span>, evaluated at <span class="math inline">\(\widehat{\boldsymbol{\theta}}^{t}\)</span>.</p>
<p>Common iterative approaches to solve this optimization problem involve the Gauss-Newton and Newton-Raphson algorithms. We introduce the <strong>Gauss-Newton</strong> method here. The basic idea is that we can approximate the nonlinear mean function with a linear version that depends on some current values for <span class="math inline">\(\boldsymbol{\theta}\)</span>. Linear least squares can be applied to the linearized form to compute an update of the estimate for <span class="math inline">\(\boldsymbol{\theta}\)</span>. With the updated estimate the approximation can be refined and another least squares step is performed. This sequence is repeated until some convergence criterion is met.</p>
<p>We start by approximating <span class="math inline">\(\textbf{f}(\textbf{x};\boldsymbol{\theta})\)</span> with a first-order Taylor series about <span class="math inline">\(\boldsymbol{\theta}^{(0)}\)</span> <span class="math display">\[
    \textbf{f}(\textbf{x}; \boldsymbol{\theta}) \approx \textbf{f}(\textbf{x};\boldsymbol{\theta}^{(0)}) + \textbf{F}^{(0)}(\boldsymbol{\theta}-\boldsymbol{\theta}^{(0)})
\]</span> where <span class="math inline">\(\textbf{F}^{(0)}\)</span> is a matrix of derivatives of <span class="math inline">\(\textbf{f}(\textbf{x};\boldsymbol{\theta})\)</span> evaluated at the value <span class="math inline">\(\boldsymbol{\theta}^{(0)}\)</span>. The residual <span class="math inline">\(\textbf{y}- \textbf{f}(\textbf{x};\boldsymbol{\theta})\)</span> can now be approximated as <span class="math inline">\(\textbf{r}(\boldsymbol{\theta}^{(0)}) = \textbf{y}- \textbf{f}(\textbf{x};\boldsymbol{\theta}^{(0)}) - \textbf{F}^{(0)}(\boldsymbol{\theta}- \boldsymbol{\theta}^{(0)})\)</span>. Substitute this expression into <a href="#eq-nonlin-sse" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> we get an approximate error sums of squares</p>
<p><span class="math display">\[
\text{SSE} \approx \textbf{r}(\boldsymbol{\theta}^{(0)})^\prime \textbf{r}(\boldsymbol{\theta}^{(0)}) - 2 \textbf{r}(\boldsymbol{\theta}^{(0)})\textbf{F}^{(0)}(\boldsymbol{\theta}- \boldsymbol{\theta}^{(0)}) +
(\boldsymbol{\theta}- \boldsymbol{\theta}^{(0)})^\prime \textbf{F}^{(0)\prime}\textbf{F}^{(0)} (\boldsymbol{\theta}- \boldsymbol{\theta}^{(0)})
\]</span></p>
<p>Taking derivatives with respect to <span class="math inline">\(\boldsymbol{\theta}\)</span> and setting to zero results in the following condition <span class="math display">\[
(\boldsymbol{\theta}- \boldsymbol{\theta}^{(0)}) = \left(\textbf{F}^{(0)\prime}\textbf{F}^{(0)}\right)^{-1}\textbf{F}^{(0)\prime}\textbf{r}(\boldsymbol{\theta}^{(0)})
\]</span> This is a really interesting expression. Imagine replacing on the right hand side <span class="math inline">\(\textbf{F}^{(0)}\)</span> with <span class="math inline">\(\textbf{X}\)</span> and <span class="math inline">\(\textbf{r}(\boldsymbol{\theta}^{(0)})\)</span> with <span class="math inline">\(\textbf{y}\)</span>. The right hand side is an ordinary least squares solution in a linear model where the <span class="math inline">\(x\)</span>-matrix is given by the derivatives of the nonlinear model and the target variable is the difference between the actual <span class="math inline">\(y\)</span>-values and the approximated mean function. The left hand side of the equation is the difference between the parameter estimate and our current guess. This suggests the following iterative updates <span class="math display">\[
    \boldsymbol{\theta}^{(t+1)} = \boldsymbol{\theta}^{(t)} + \left(\textbf{F}^{(t)\prime}\textbf{F}^{(t)}\right)^{-1}\textbf{F}^{(t)\prime}\textbf{r}(\boldsymbol{\theta}^{(t)})
\]</span></p>
<p>and is known as the Gauss-Newton algorithm.</p>
<section id="gauss-newton-from-scratch" class="level4">
<h4 class="anchored" data-anchor-id="gauss-newton-from-scratch">Gauss-Newton from scratch</h4>
<p>Just like with the OLS problem, we are going to implement a nonlinear least squares solution from scratch, based on the linear algebra presented in this section. The nonlinear model chosen for this exercise has two parameters, <span class="math inline">\(\boldsymbol{\theta}= [\theta_1, \theta_2]\)</span>, one input variable <span class="math inline">\(x\)</span>, and mean function <span class="math display">\[
    f(x; \boldsymbol{\theta}) = 1 - \theta_1 \exp \{-x^{\theta_2}\}
\]</span> We fit this model to a tiny data set with just five observations</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="&quot;language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="&quot;language">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.9</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">1.8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.9</span>])</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">1.8</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>The derivatives of the mean function with respect to the parameters are given by</p>
<p><span class="math display">\[\begin{align*}
  \frac{\partial f(x;\boldsymbol{\theta})}{\partial \theta_1} &amp;= -\exp\{-x^{\theta_2}\} \\
  \frac{\partial f(x;\boldsymbol{\theta})}{\partial \theta_2} &amp;= \theta_1 \log(x) x^{\theta_2} \exp\{-x^{\theta_2}\}
\end{align*}\]</span></p>
<p>and we can write a simple function to compute the derivative matrix <span class="math inline">\(\textbf{F}\)</span> based on a current estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span>. The function <code>getres</code> computes <span class="math inline">\(\textbf{r}(\boldsymbol{\theta}^{(t)})\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="&quot;language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="&quot;language">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>getF <span class="ot">&lt;-</span> <span class="cf">function</span>(x, theta) {</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    exterm <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>x<span class="sc">^</span>theta[<span class="dv">2</span>])</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    der1 <span class="ot">&lt;-</span> <span class="sc">-</span>exterm</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    der2 <span class="ot">&lt;-</span> theta[<span class="dv">1</span>] <span class="sc">*</span> <span class="fu">log</span>(x) <span class="sc">*</span> (x<span class="sc">^</span>theta[<span class="dv">2</span>]) <span class="sc">*</span> exterm</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">cbind</span>(der1,der2))</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>getres <span class="ot">&lt;-</span> <span class="cf">function</span>(y,x,theta) {</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    fx <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> theta[<span class="dv">1</span>] <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span>x<span class="sc">^</span>theta[<span class="dv">2</span>])</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(y <span class="sc">-</span> fx)</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> getF(x, theta):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    exterm <span class="op">=</span> np.exp(<span class="op">-</span>x<span class="op">**</span>theta[<span class="dv">1</span>])</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    der1 <span class="op">=</span> <span class="op">-</span>exterm</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    der2 <span class="op">=</span> theta[<span class="dv">0</span>] <span class="op">*</span> np.log(x) <span class="op">*</span> (x<span class="op">**</span>theta[<span class="dv">1</span>]) <span class="op">*</span> exterm</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.column_stack((der1, der2))</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> getres(y, x, theta):</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    fx <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> theta[<span class="dv">0</span>] <span class="op">*</span> np.exp(<span class="op">-</span>x<span class="op">**</span>theta[<span class="dv">1</span>])</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y <span class="op">-</span> fx</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Now all we need is starting values <span class="math inline">\(\boldsymbol{\theta}^{(0)}\)</span> and a loop that iterates until the estimation routine has converged. It is a good idea to not take a full Gauss-Newton step in the updates since there is no guarantee that SSE at iterate <span class="math inline">\(t+1\)</span> is lower than at iterate <span class="math inline">\(t\)</span>. We thus multiply the update to the current value by the hyperparameter <span class="math inline">\(\alpha &lt; 1\)</span>. In machine learning, this step size is known as the <strong>learning rate</strong>. A full implementation of the Gauss-Newton algorithm could determine <span class="math inline">\(\alpha\)</span> dynamically at each iteration through a line search algorithm.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="&quot;language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-2" role="tab" aria-controls="tabset-11-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="&quot;language">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>maxiter <span class="ot">&lt;-</span> <span class="dv">50</span>          <span class="co"># the max number of iterations</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.5</span>           <span class="co"># the learning rate</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.3</span>)     <span class="co"># the starting values</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>tol <span class="ot">&lt;-</span> <span class="fl">1e-6</span>            <span class="co"># the convergence tolerance</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Main loop</span></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (iter <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>maxiter) {</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">getF</span>(x,theta)</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">getres</span>(y,x,theta)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The linear least squares update</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    new_theta <span class="ot">&lt;-</span> theta <span class="sc">+</span> alpha <span class="sc">*</span> (<span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> r)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now we check a convergence criterion. We take the maximum relative</span></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># change in the parameter estimates. If that is less than some tolerance</span></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the algorithm is considered converged.</span></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    crit <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">abs</span>(new_theta<span class="sc">-</span>theta)<span class="sc">/</span><span class="fu">abs</span>(theta))</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (crit <span class="sc">&lt;</span> tol) {</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>        <span class="fu">cat</span>( <span class="st">"Algorithm converged after"</span>, iter,<span class="st">" iterations! SSE ="</span>, <span class="fu">sum</span>(r<span class="sc">^</span><span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span> )</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span> (new_theta)</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a>        theta <span class="ot">&lt;-</span> new_theta</span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span> (crit)</span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03047302
[1] 0.01661031
[1] 0.008692942
[1] 0.004446789
[1] 0.002248043
[1] 0.001129919
[1] 0.000566354
[1] 0.0002835054
[1] 0.0001418301
[1] 7.093331e-05
[1] 3.547098e-05
[1] 1.773652e-05
[1] 8.868505e-06
[1] 4.434311e-06
[1] 2.21717e-06
[1] 1.108588e-06
Algorithm converged after 17  iterations! SSE = 0.01569114 
          [,1]
der1 0.9366938
der2 1.2791919</code></pre>
</div>
</div>
</div>
<div id="tabset-11-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>maxiter <span class="op">=</span> <span class="dv">50</span>                   <span class="co"># the max number of iterations</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.5</span>                    <span class="co"># the learning rate</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="fl">1.3</span>])     <span class="co"># the starting values</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>tol <span class="op">=</span> <span class="fl">1e-6</span>                     <span class="co"># the convergence tolerance</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Main loop</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, maxiter <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> getF(x, theta)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> getres(y, x, theta)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The linear least squares update</span></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    new_theta <span class="op">=</span> theta <span class="op">+</span> alpha <span class="op">*</span> (np.linalg.solve(X.T <span class="op">@</span> X, X.T <span class="op">@</span> r))</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check convergence criterion</span></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    crit <span class="op">=</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(new_theta <span class="op">-</span> theta) <span class="op">/</span> np.<span class="bu">abs</span>(theta))</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> crit <span class="op">&lt;</span> tol:</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Algorithm converged after </span><span class="sc">{</span><span class="bu">iter</span><span class="sc">}</span><span class="ss"> iterations! SSE = </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(r<span class="op">**</span><span class="dv">2</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(new_theta)</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>        theta <span class="op">=</span> new_theta</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(crit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.030473021008723622
0.01661030945285771
0.008692942194143186
0.004446789411742169
0.0022480433797805043
0.0011299191151095287
0.0005663540002912544
0.00028350544057947886
0.00014183009245741758
7.093331231823904e-05
3.547098173238101e-05
1.7736518771472344e-05
8.868504534648017e-06
4.434310944509424e-06
2.2171695661416083e-06
1.1085881797187592e-06
Algorithm converged after 17 iterations! SSE = 0.015691138399833392
[0.93669384 1.2791919 ]</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>After 17 iterations with a learning rate (step size) of <span class="math inline">\(\alpha=0.5\)</span> the algorithm converged on parameter estimates <span class="math inline">\(\widehat{\theta}_1\)</span> = 0.9366 and <span class="math inline">\(\widehat{\theta}_2\)</span> = 1.2791.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-12-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-2" role="tab" aria-controls="tabset-12-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<p>We can validate these results with the <code>nls</code> function from the <code>nls2</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nls2)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>nonlin_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">cbind</span>(<span class="at">y=</span>y,<span class="at">x=</span>x))</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>f_x <span class="ot">&lt;-</span> y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">-</span> theta1 <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span>x<span class="sc">^</span>theta2)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">nls</span>(f_x, </span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">start=</span><span class="fu">list</span>(<span class="at">theta1=</span><span class="dv">1</span>, <span class="at">theta2=</span><span class="fl">1.3</span>), </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>nonlin_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Nonlinear regression model
  model: y ~ 1 - theta1 * exp(-x^theta2)
   data: nonlin_data
theta1 theta2 
0.9367 1.2792 
 residual sum-of-squares: 0.01569

Number of iterations to convergence: 15 
Achieved convergence tolerance: 6.109e-06</code></pre>
</div>
</div>
</div>
<div id="tabset-12-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-12-2-tab">
<p>We can validate these results with <code>curve_fit</code> in <code>scipy</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> curve_fit</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the function to fit</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func(x, theta1, theta2):</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> theta1 <span class="op">*</span> np.exp(<span class="op">-</span>x<span class="op">**</span>theta2)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>initial_params <span class="op">=</span> [<span class="dv">1</span>, <span class="fl">1.3</span>]</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform the non-linear least squares fit</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>params, pcov <span class="op">=</span> curve_fit(func, x, y, p0<span class="op">=</span>initial_params)</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated parameters:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated parameters:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"theta1 = </span><span class="sc">{</span>params[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>theta1 = 0.9366993225575078</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"theta2 = </span><span class="sc">{</span>params[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>theta2 = 1.279162600773984</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate standard errors</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>perr <span class="op">=</span> np.sqrt(np.diag(pcov))</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standard errors:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Standard errors:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"theta1 error = </span><span class="sc">{</span>perr[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>theta1 error = 0.1287337773028948</code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"theta2 error = </span><span class="sc">{</span>perr[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>theta2 error = 0.5206349577899593</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the fitted values</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>y_fit <span class="op">=</span> func(x, params[<span class="dv">0</span>], params[<span class="dv">1</span>])</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate sum of squared residuals</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y <span class="op">-</span> y_fit</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>ssr <span class="op">=</span> np.<span class="bu">sum</span>(residuals<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Sum of squared residuals: </span><span class="sc">{</span>ssr<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Sum of squared residuals: 0.015691138436968982</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="maximum-likelihood-estimation" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="maximum-likelihood-estimation"><span class="header-section-number">4.3</span> Maximum Likelihood Estimation</h2>
<p>Maximum likelihood estimation (MLE) is an intuitive and important estimation principle in statistics. It is based on the distributional properties of the data, hence it applies to stochastic data modeling. If the observed data <span class="math inline">\(\textbf{y}\)</span> are the realization of a data-generating random mechanism, then it makes sense to examine the probability distribution of the data and choose as parameter estimates those values that make it most likely to have observed the data. In other words, we use the probability distribution to find the most likely explanation for the data–hence the name <strong>maximum likelihood</strong>.</p>
<p>Making progress with MLE requires that we know the joint distribution of the random vector <span class="math inline">\(\textbf{Y}\)</span>, an <span class="math inline">\(n\)</span>-dimensional distribution. The distribution depends on a vector <span class="math inline">\(\boldsymbol{\theta}\)</span> of unknown parameters and we denote it as <span class="math inline">\(f(\textbf{y}; \boldsymbol{\theta})\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Whenever you calculate a maximum likelihood estimator, you are making assumptions about the distribution of the data. If software packages report MLEs, check the documentation regarding distributional assumptions.</p>
</div>
</div>
<p>When the observations are independent, the joint density is the product of the individual densities, <span class="math display">\[
f(\textbf{y}; \boldsymbol{\theta}) = \prod_{i=1}^n \, f(y_i; \boldsymbol{\theta})
\]</span></p>
<p>For example, the joint mass function of <span class="math inline">\(n\)</span> <em>iid</em> Bernoulli(<span class="math inline">\(\pi\)</span>) random variables is <span class="math display">\[
    f(\textbf{y}; \pi) = \prod_{i=1}^n \, \pi^{y_i} \, (1-\pi)^{1-y_i}
\]</span></p>
<p>The <strong>likelihood function</strong> is the joint density or mass function of the data, but we interpret it as a function of the parameters evaluated at the data, whereas the density (mass) function is a function of the data evaluated at the parameter values. The <strong>log-likelihood</strong> function is the natural log of the likelihood function, denoted <span class="math inline">\(\mathcal{l}(\boldsymbol{\theta}; \textbf{y})\)</span>. The parameters that maximize the likelihood function also maximize the log of the function. Logarithms are much easier to work with since they turn products into sums and exponents into multipliers.</p>
<div class="example">
<div class="example-header">
<p>Example: Likelihood Function for Poisson Data</p>
</div>
<div class="example-container">
<p>If <span class="math inline">\(Y_1, \cdots, Y_n\)</span> are a random sample from a Poisson(<span class="math inline">\(\lambda\)</span>) distribution, the log-likelihood function is</p>
<p><span class="math display">\[
    \mathcal{l}(\lambda; \textbf{y}) = \sum_{i=1}^n \left( y_i \log(\lambda) - \lambda - \log(y_i!) \right ) =
    \log(\lambda)\sum_{i=1}^n y_i - n\lambda - \sum_{i=1}^n \log(y_i!)
\]</span> Setting the derivative with respect to <span class="math inline">\(\lambda\)</span> to zero yields <span class="math display">\[
    \frac{1}{\lambda}\sum_{i=1}^n y_i = n
\]</span> The MLE of <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(\widehat{\lambda} = \overline{y}\)</span>, the sample mean.</p>
<p>Suppose that <span class="math inline">\(n=4\)</span> and we observe <span class="math inline">\(\textbf{y}= [3, 4, 2, 2]\)</span>. The sample mean is <span class="math inline">\(\overline{y} = 2.75\)</span>. The following <code>R</code> code computes the log-likelihood function <span class="math inline">\(\mathcal{l}(\lambda; \textbf{y})\)</span> for different values of <span class="math inline">\(\lambda\)</span>. The log-likelihood function has a maximum at <span class="math inline">\(\overline{y} = 2.75\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-13-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-1" role="tab" aria-controls="tabset-13-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-13-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-2" role="tab" aria-controls="tabset-13-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-13-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-13-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the original data</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>sumy <span class="ot">&lt;-</span> <span class="fu">sum</span>(y)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>sumlogfac <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">factorial</span>(y)))</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a range of lambda values</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="dv">5</span>, <span class="fl">0.1</span>)</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log likelihood for each lambda</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>loglike <span class="ot">&lt;-</span> <span class="fu">log</span>(lambda)<span class="sc">*</span>sumy <span class="sc">-</span> n<span class="sc">*</span>lambda <span class="sc">-</span> sumlogfac</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lambda,loglike,<span class="at">type=</span><span class="st">"l"</span>,<span class="at">bty=</span><span class="st">"l"</span>,<span class="at">lwd=</span><span class="fl">1.5</span>,</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="fu">expression</span>(lambda),</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"log likelihood"</span>)</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(y),<span class="at">lty=</span><span class="st">"dotted"</span>,<span class="at">lwd=</span><span class="fl">1.5</span>,<span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="estimation_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-13-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-13-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> factorial</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the original data</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>sumy <span class="op">=</span> np.<span class="bu">sum</span>(y)</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>sumlogfac <span class="op">=</span> np.<span class="bu">sum</span>(np.log(factorial(y)))</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a range of lambda values</span></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>lambda_values <span class="op">=</span> np.arange(<span class="fl">0.1</span>, <span class="fl">5.1</span>, <span class="fl">0.1</span>)</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log likelihood for each lambda</span></span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>loglike <span class="op">=</span> sumy <span class="op">*</span> np.log(lambda_values) <span class="op">-</span> n <span class="op">*</span> lambda_values <span class="op">-</span> sumlogfac</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>plt.plot(lambda_values, loglike, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>np.mean(y), linestyle<span class="op">=</span><span class="st">'dotted'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'λ'</span>)</span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'log likelihood'</span>)</span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>plt.box(<span class="va">False</span>)</span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="estimation_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="example">
<div class="example-header">
<p>Example: MLE for iid Bernoulli Experiments</p>
</div>
<div class="example-container">
<p>To find the maximum likelihood estimator of <span class="math inline">\(\pi\)</span> in <span class="math inline">\(n\)</span> <em>iid</em> Bernoulli(<span class="math inline">\(\pi\)</span>) experiments, we need to find the value <span class="math inline">\(\widehat{\pi}\)</span> that maximizes the log-likelihood function</p>
<p><span class="math display">\[\begin{align*}
    \mathcal{l}(\pi; \textbf{y}) &amp;= \log\left(\prod_{i=1}^n \, \pi^{y_i} \, (1-\pi)^{1-y_i}\right) \\
                          &amp;= \sum_{i=1}^n \, y_i\log(\pi) + (1-y_i)\log(1-\pi)
\end{align*}\]</span></p>
<p><span class="math inline">\(\mathcal{l}(\pi; \textbf{y}) = \sum_i y_i\log(\pi) + (1-y_i)\log(1-\pi)\)</span>. The derivative with respect to <span class="math inline">\(\pi\)</span> is</p>
<p><span class="math display">\[\begin{align*}
    \frac{\partial \mathcal{l}(\pi; \textbf{y})}{\partial \pi} &amp;= \frac{1}{\pi}\sum_{i=1}^n y_i - \frac{1}{1-\pi}\sum_{i=1}^n(1-y_i) \\
    &amp;= \frac{1}{\pi} n\overline{y} - \frac{1}{1-\pi}(n - n\overline{y})
\end{align*}\]</span></p>
<p>Setting the derivative to zero and rearranging terms we get</p>
<p><span class="math display">\[\begin{align*}
    \frac{1-\widehat{\pi}}{\widehat{\pi}} &amp;= \frac{n-n\overline{y}}{n\overline{y}} \\
    \frac{1}{\widehat{\pi}} &amp;= \frac{n - n\overline{y}}{n\overline{y}} + 1 \\
    \widehat{\pi} &amp;= \overline{y}
\end{align*}\]</span></p>
<p>The MLE of <span class="math inline">\(\pi\)</span> is the sample mean.</p>
</div>
</div>
<p>Maximum likelihood estimation is popular because it is an intuitive principle if we accept a random data-generating mechanism. MLEs have very appealing properties, for example, they are <strong>invariant</strong> estimators. If <span class="math inline">\(\widehat{\theta}\)</span> is the MLE of <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(g(\widehat{\theta})\)</span> is the maximum likelihood estimator of <span class="math inline">\(g(\theta)\)</span>.</p>
<div class="example">
<div class="example-header">
<p>Example: MLEs of Confidence Intervals</p>
</div>
<div class="example-container">
<p>In generalized linear models, a linear predictor is related to a transformation of the mean through the link function <span class="math display">\[
    g(\mu) = \eta = \beta_0 + \beta_1x_1 + \cdots + \beta_p x_p
\]</span> For example, if the data are Poisson random variables, <span class="math inline">\(g(\cdot)\)</span> is typically the log function (the log link). The coefficient estimates have a linear interpretation on the logarithmic scale. Suppose <span class="math inline">\(\boldsymbol{\beta}\)</span> is estimated by maximum likelihood and is used to construct a 95% confidence interval <span class="math inline">\([\widehat{\eta}_{.025},\widehat{\eta}_{.975}]\)</span> for <span class="math inline">\(\eta\)</span>.</p>
<p>You can transform from <span class="math inline">\(\eta\)</span> to <span class="math inline">\(\mu\)</span> by inverting the link function, <span class="math inline">\(\mu = g^{-1}(\mu)\)</span>. Thus, <span class="math display">\[
    \left[ \exp\{\widehat{\eta}_{.025}\}, \exp\{\widehat{\eta}_{.975}\} \right]
\]</span> is a 95% confidence interval for <span class="math inline">\(\mu\)</span>.</p>
</div>
</div>
<p>For a finite sample size, MLEs are not necessarily optimal estimators but they have appealing properties as the sample size grows. As <span class="math inline">\(n \rightarrow \infty\)</span>, maximum likelihood estimators</p>
<ul>
<li>are consistent, that means they converge in probability to the true value</li>
<li>are normally distributed</li>
<li>are efficient in that no other estimator has an asymptotically smaller mean squared error</li>
</ul>
<section id="linear-model-with-gaussian-errors" class="level3">
<h3 class="anchored" data-anchor-id="linear-model-with-gaussian-errors">Linear Model with Gaussian Errors</h3>
<p>Suppose we want to find an estimator for <span class="math inline">\(\boldsymbol{\beta}\)</span> in the linear model <span class="math inline">\(\textbf{Y}= \textbf{X}\boldsymbol{\beta}+ \boldsymbol{\epsilon}\)</span> where the model errors follow a Gaussian distribution with mean <span class="math inline">\(\textbf{0}\)</span> and variance <span class="math inline">\(\textbf{V}\)</span>. <span class="math inline">\(\textbf{Y}\)</span> then follows a Gaussian distribution because it is a linear function of <span class="math inline">\(\boldsymbol{\epsilon}\)</span> (see <a href="linalg.html#sec-multi-gaussian" class="quarto-xref"><span>Section 3.9</span></a>). The probability density function of <span class="math inline">\(\textbf{Y}\)</span> is</p>
<p><span class="math display">\[
f\left( \textbf{Y}\right)=\frac{\left| \textbf{V}\right|^{- 1/2}}{(2\pi)^{\frac{n}{2}}}\exp\left\{ - \frac{1}{2}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\textbf{V}^{- 1}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right) \right\}
\]</span></p>
<p>This joint distribution of the data can be used to derive the maximum likelihood estimator (MLE) of <span class="math inline">\(\boldsymbol{\beta}\)</span>. Maximum likelihood estimation considers this as a function of <span class="math inline">\(\boldsymbol{\beta}\)</span> rather than a function of <span class="math inline">\(\textbf{Y}.\)</span> Maximizing this likelihood function <span class="math inline">\(\mathcal{l}(\boldsymbol{\beta};\textbf{Y})\)</span> is equivalent to maximizing its logarithm. The log-likelihood function for this problem is given by</p>
<p><span class="math display">\[
\log\mathcal{l}\left( \boldsymbol{\beta};\textbf{Y}\right\} = l\left( \boldsymbol{\beta};\textbf{Y}\right) = - \frac{1}{2}\log\left( \left| \textbf{V}\right| \right) - \frac{n}{2}\log(2\pi) - \frac{1}{2}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\textbf{V}^{- 1}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)
\]</span></p>
<p>Finding the maximum of this function with respect to <span class="math inline">\(\boldsymbol{\beta}\)</span> is equivalent to minimizing the quadratic form <span class="math display">\[
\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\textbf{V}^{-1}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)
\]</span> with respect to <span class="math inline">\(\boldsymbol{\beta}\)</span>. Applying the results about matrix differentiation in <a href="linalg.html#sec-matrix-differentiation" class="quarto-xref"><span>Section 3.8</span></a> leads to</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial}{\partial\boldsymbol{\beta}}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\textbf{V}^{- 1}\left( \textbf{Y}- \textbf{X}\boldsymbol{\beta}\right) &amp;= \frac{\partial}{\partial\boldsymbol{\beta}}\left\{ \textbf{Y}^\prime\textbf{V}^{- 1}\textbf{Y}- 2\textbf{Y}^\prime\textbf{V}^{- 1}\textbf{X}\boldsymbol{\beta}+ \boldsymbol{\beta}^\prime\textbf{X}^\prime\textbf{V}^{- 1}\textbf{X}\boldsymbol{\beta}\right\} \\

  &amp;= - 2\textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}+ 2\textbf{X}^\prime\textbf{V}^{- 1}\textbf{X}\boldsymbol{\beta}
\end{align*}\]</span></p>
<p>The derivative is zero when <span class="math inline">\(\textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}= \textbf{X}^\prime\textbf{V}^{- 1}\textbf{X}\boldsymbol{\beta}\)</span>.</p>
<p>If <span class="math inline">\(\textbf{X}\)</span> is of full column rank, then <span class="math inline">\(\textbf{X}^\prime\textbf{V}^{- 1}\textbf{X}\)</span> is non-singular and its inverse exists. Pre-multiplying both sides of the equation with that inverse yields the solution</p>
<p><span class="math display">\[\begin{align*}
    \textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}&amp;= \textbf{X}^\prime\textbf{V}^{- 1}\textbf{X}\widehat{\boldsymbol{\beta}} \\

    \left( \textbf{X}^{\prime}\textbf{V}^{- 1}\textbf{X}\right)^{- 1}\textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}&amp;= {\left( \textbf{X}^{\prime}\textbf{V}^{- 1}\textbf{X}\right)^{- 1}\textbf{X}}^\prime\textbf{V}^{- 1}\textbf{X}\widehat{\boldsymbol{\beta}} \\

    \left( \textbf{X}^{\prime}\textbf{V}^{- 1}\textbf{X}\right)^{- 1}\textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}&amp;= \widehat{\boldsymbol{\beta}}
\end{align*}\]</span></p>
<p>The maximum likelihood estimator of <span class="math inline">\(\boldsymbol{\beta}\)</span> is the <strong>generalized</strong> least squares estimator</p>
<p><span class="math display">\[\widehat{\boldsymbol{\beta}}_{GLS} = \left( \textbf{X}^{\prime}\textbf{V}^{- 1}\textbf{X}\right)^{- 1}\textbf{X}^\prime\textbf{V}^{- 1}\textbf{Y}\]</span></p>
<p>A special case arises when the model errors <span class="math inline">\(\boldsymbol{\epsilon}\)</span> are uncorrelated and the variance matrix <span class="math inline">\(\textbf{V}\)</span> is a diagonal matrix:</p>
<p><span class="math display">\[
\textbf{V}= \begin{bmatrix}
\sigma_{1}^{2} &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \sigma_{n}^{2}
\end{bmatrix}
\]</span></p>
<p>Since the errors are Gaussian distributed, we know that the errors are then independent. The MLE of <span class="math inline">\(\boldsymbol{\beta}\)</span> is the <strong>weighted</strong> least squares estimator</p>
<p><span class="math display">\[
\widehat{\boldsymbol{\beta}}_{WLS} = \left(\textbf{X}^\prime\textbf{W}\textbf{X}\right)^{-1}\textbf{X}^\prime\textbf{W}\textbf{Y}
\]</span> where <span class="math inline">\(\textbf{W}= \textbf{V}^{-1}\)</span>.</p>
<p>A further special case arises when the diagonal entries are all the same,</p>
<p><span class="math display">\[\textbf{V}= \begin{bmatrix}
\sigma^{2}\  &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \sigma^{2}
\end{bmatrix} = \sigma^{2}\textbf{I}\]</span></p>
<p>We can write the error distribution in this case as <span class="math inline">\(\boldsymbol{\epsilon}\sim G\left(\textbf{0},\sigma^{2}\textbf{I}\right)\)</span> and the model for <span class="math inline">\(\textbf{Y}\)</span> as <span class="math inline">\(\textbf{Y}\sim G\left( \textbf{X}\boldsymbol{\beta},\sigma^{2}\textbf{I}\right)\)</span>.</p>
<p>Under this <em>iid</em> assumption for the Gaussian linear model we can substitute <span class="math inline">\(\sigma^{2}\textbf{I}\)</span> for <span class="math inline">\(\textbf{V}\)</span> in the formula for <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. The maximum likelihood estimator for <span class="math inline">\(\boldsymbol{\beta}\)</span> is the ordinary least squares estimator:</p>
<p><span class="math display">\[\widehat{\boldsymbol{\beta}}_{OLS} = \left( \textbf{X}^{\prime}\textbf{X}\right)^{- 1}\textbf{X}^\prime\textbf{Y}\]</span></p>
<p>Notice that <span class="math inline">\(\sigma^{2}\)</span> cancels out of the formula; the value of the OLS estimator does not depend on the inherent variability of the data. However, the variability of the OLS estimator does depend on <span class="math inline">\(\sigma^{2}\)</span> (and on <span class="math inline">\(\textbf{X}\)</span>).</p>
<p>Now that we have found the MLE of <span class="math inline">\(\boldsymbol{\beta}\)</span>, the parameters in the mean function, we can also derive the MLE of the parameters in the variance-covariance structure of the multi-variate Gaussian. Let’s do this for the <em>iid</em> case, <span class="math inline">\(\boldsymbol{\epsilon}\sim G(\textbf{0},\sigma^2\textbf{I})\)</span>. The joint density of the data can then be written as <span class="math display">\[
    f(\textbf{Y}) = \prod_{i=1}^n (2 \pi\sigma^2)^{-1/2} \exp\left\{-\frac{1}{2\sigma^2} (y_i - \textbf{x}_i^\prime\boldsymbol{\beta})^2\right\}
\]</span> Taking logs and arranging terms, the log-likelihood function for <span class="math inline">\(\sigma^2\)</span> is <span class="math display">\[
\mathcal{l}(\sigma^2; \textbf{y}) = -\frac{n}{2}\log(2\pi\sigma^2) -\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i - \textbf{x}_i\prime\boldsymbol{\beta})^2
\]</span></p>
<p>Taking the derivative of <span class="math inline">\(\mathcal{l}(\sigma^2; \textbf{y})\)</span> with respect to <span class="math inline">\(\sigma^2\)</span>, setting it to zero and arranging terms results in <span class="math display">\[
    \frac{1}{\sigma^4}\sum_{i=1}^n(y_i - \textbf{x}_i^\prime\boldsymbol{\beta})^2 = \frac{n}{\sigma^2}
\]</span> The MLE of <span class="math inline">\(\sigma^2\)</span> in this case is <span class="math display">\[
    \widehat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n(y_i - \textbf{x}_i^\prime\boldsymbol{\beta})^2
\]</span> The MLE of <span class="math inline">\(\sigma^2\)</span> looks similar to the estimator we used in the OLS case, <span class="math display">\[
    \frac{1}{n-r(\textbf{X})} \sum_{i=1}^n(y_i - \textbf{x}_i^\prime \widehat{\boldsymbol{\beta}})^2 = \frac{1}{n-r(\textbf{X})} \, \text{SSE}
\]</span> with two important differences. The divisor in the MLE is <span class="math inline">\(n\)</span> instead of <span class="math inline">\(n-r(\textbf{X})\)</span> and the MLE uses <span class="math inline">\(\boldsymbol{\beta}\)</span> rather than the OLS estimator <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> in the sum-of-squares term. In practice, we would substitute the MLE for <span class="math inline">\(\boldsymbol{\beta}\)</span> to compute <span class="math inline">\(\widehat{\sigma}^2\)</span>, so that the least squares-based estimator and the maximum likelihood estimator differ only in the divisor. Consequently, they cannot be both unbiased estimators of <span class="math inline">\(\sigma^2\)</span>. Which should we choose?</p>
<p>We can think of the divisor <span class="math inline">\(n-r(\textbf{X})\)</span> as accounting for the actual degrees of freedom, the amount of information if you will, in the estimator. Since we are using an estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span> to compute SSE, we have “used up” information in the amount of the rank of <span class="math inline">\(\textbf{X}\)</span>. This is the same rationale that computes the estimate of the sample variance as <span class="math display">\[
    s^2 = \frac{1}{n-1} \sum_{i=1}^n \left(y_i - \overline{y}\right)^2
\]</span> because we are using the sample mean <span class="math inline">\(\overline{y}\)</span> in the computation rather than the true mean. Once the sample mean is known, only <span class="math inline">\((n-1)\)</span> of the <span class="math inline">\(y_i\)</span> can be chosen freely, the value of the last one is determined.</p>
<p>The reason the MLE divides by <span class="math inline">\(n\)</span> instead of <span class="math inline">\(n-r(\textbf{X})\)</span> is that it uses <span class="math inline">\(\boldsymbol{\beta}\)</span> and does not need to account for information already “used up” in the estimation of the mean function. If you substitute <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> for <span class="math inline">\(\boldsymbol{\beta}\)</span>, the MLE of <span class="math inline">\(\sigma^2\)</span> is a biased estimator.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./linalg.html" class="pagination-link" aria-label="Linear Algebra Review">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./learningtypes.html" class="pagination-link" aria-label="Types of Statistical Learning">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Types of Statistical Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Statistical Learning by Oliver Schabenberger</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>