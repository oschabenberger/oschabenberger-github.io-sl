<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Learning - 8&nbsp; Feature Selection and Regularization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./regnlr.html" rel="next">
<link href="./regglobal.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regintro.html">Part II. Supervised Learning I: Regression</a></li><li class="breadcrumb-item"><a href="./regfeature.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistical Learning</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part I. Foundation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./biasvariance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learningtypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Types of Statistical Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Part II. Supervised Learning I: Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regglobal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Classical Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regfeature.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regnlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nonlinear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regdiscrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Discrete Target Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reglocal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Local Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Part III. Supervised Learning II: Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression Approach to Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Classification with Random Inputs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supportvectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vectors</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Part IV. Decision Trees</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decisiontrees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Regression and Classification Trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treesinR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Trees in <code>R</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treesInPython.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Trees in Python</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Part V. Ensemble Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ensemble_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Bayesian Model Averaging</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Part VI. Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsuper_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Principal Component Analysis (PCA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Cluster Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mbc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Model-based Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./arules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Association Rules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Part VII. Supervised Learning III: Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Generalized Additive Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./corrdata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Correlated Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Mixed Models for Longitudinal Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Part VIII. Neural Networks and Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Training Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann_R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Neural Networks in <code>R</code> (with Keras)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reinforcement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Part IX. Explainability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./explainability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Interpretability and Explainability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-feature-select" id="toc-sec-feature-select" class="nav-link active" data-scroll-target="#sec-feature-select"><span class="header-section-number">8.1</span> Algorithmic Feature Selection</a>
  <ul>
  <li><a href="#two-step-procedure" id="toc-two-step-procedure" class="nav-link" data-scroll-target="#two-step-procedure">Two-step Procedure</a></li>
  <li><a href="#indirect-estimates-of-test-error" id="toc-indirect-estimates-of-test-error" class="nav-link" data-scroll-target="#indirect-estimates-of-test-error">Indirect Estimates of Test Error</a>
  <ul class="collapse">
  <li><a href="#mallows-c_p" id="toc-mallows-c_p" class="nav-link" data-scroll-target="#mallows-c_p">Mallows’ <span class="math inline">\(C_p\)</span></a></li>
  <li><a href="#aic-and-bic" id="toc-aic-and-bic" class="nav-link" data-scroll-target="#aic-and-bic">AIC and BIC</a></li>
  <li><a href="#adjusted-r2" id="toc-adjusted-r2" class="nav-link" data-scroll-target="#adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></a></li>
  </ul></li>
  <li><a href="#best-subset-selection" id="toc-best-subset-selection" class="nav-link" data-scroll-target="#best-subset-selection">Best Subset Selection</a></li>
  <li><a href="#forward-selection" id="toc-forward-selection" class="nav-link" data-scroll-target="#forward-selection">Forward Selection</a></li>
  <li><a href="#backward-selection" id="toc-backward-selection" class="nav-link" data-scroll-target="#backward-selection">Backward Selection</a></li>
  <li><a href="#stepwise-selection" id="toc-stepwise-selection" class="nav-link" data-scroll-target="#stepwise-selection">Stepwise Selection</a></li>
  <li><a href="#feature-selection-with-cross-validation" id="toc-feature-selection-with-cross-validation" class="nav-link" data-scroll-target="#feature-selection-with-cross-validation">Feature Selection with Cross-validation</a></li>
  </ul></li>
  <li><a href="#sec-regularization" id="toc-sec-regularization" class="nav-link" data-scroll-target="#sec-regularization"><span class="header-section-number">8.2</span> Regularization</a>
  <ul>
  <li><a href="#shrinkage-estimation" id="toc-shrinkage-estimation" class="nav-link" data-scroll-target="#shrinkage-estimation">Shrinkage Estimation</a></li>
  <li><a href="#sec-regularization-ridge" id="toc-sec-regularization-ridge" class="nav-link" data-scroll-target="#sec-regularization-ridge">Ridge Regression</a>
  <ul class="collapse">
  <li><a href="#cross-validation-for-lambda" id="toc-cross-validation-for-lambda" class="nav-link" data-scroll-target="#cross-validation-for-lambda">Cross-validation for <span class="math inline">\(\lambda\)</span></a></li>
  <li><a href="#ridge-trace" id="toc-ridge-trace" class="nav-link" data-scroll-target="#ridge-trace">Ridge trace</a></li>
  <li><a href="#high-dimensional-ridge-regression" id="toc-high-dimensional-ridge-regression" class="nav-link" data-scroll-target="#high-dimensional-ridge-regression">High-dimensional ridge regression</a></li>
  </ul></li>
  <li><a href="#sec-regularization-lasso" id="toc-sec-regularization-lasso" class="nav-link" data-scroll-target="#sec-regularization-lasso">Lasso Regression</a>
  <ul class="collapse">
  <li><a href="#high-dimensional-lasso-regression" id="toc-high-dimensional-lasso-regression" class="nav-link" data-scroll-target="#high-dimensional-lasso-regression">High-dimensional lasso regression</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-feature-dimred" id="toc-sec-feature-dimred" class="nav-link" data-scroll-target="#sec-feature-dimred"><span class="header-section-number">8.3</span> Dimension Reduction</a>
  <ul>
  <li><a href="#principal-components" id="toc-principal-components" class="nav-link" data-scroll-target="#principal-components">Principal Components</a></li>
  <li><a href="#sec-pcr" id="toc-sec-pcr" class="nav-link" data-scroll-target="#sec-pcr">Principal Component Regression (PCR)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regintro.html">Part II. Supervised Learning I: Regression</a></li><li class="breadcrumb-item"><a href="./regfeature.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-feature-reg" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The classical linear model is a workhorse in data science and statistical learning. It is interpretable, intuitive, easy to fit and to explain. The model is computationally and mathematically straightforward, the properties of parameter estimators are easily derived and well understood.</p>
<p>Also, the classical linear model is surprisingly competitive against more complex alternatives.</p>
<div class="example">
<div class="example-header">
<p>Example: XOR Gate</p>
</div>
<div class="example-container">
<p>The exclusive OR function–also called the XOR Gate–has two binary inputs, <span class="math inline">\(X_1 \in \{0,1\}\)</span> and <span class="math inline">\(X_2 \in \{0,1\}\)</span>. The result of the gate is <span class="math inline">\(Y = 1\)</span> if exactly one of the <span class="math inline">\(X\)</span>s is 1, <span class="math inline">\(Y=0\)</span> otherwise.</p>
<table class="table">
<caption>XOR Gate</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(X_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>We will see in <a href="ann.html" class="quarto-xref"><span>Chapter 32</span></a> how to model the XOR gate with an artificial neural network with a single hidden layer with 2 units. The neural network requires 9 parameters to perfectly model the gate. We could also create a linear model that perfectly models the gate, requiring only three parameters.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x1=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">x2=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">y=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>reg_ia <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x1<span class="sc">*</span>x2 <span class="sc">-</span><span class="dv">1</span>, <span class="at">data=</span>dat)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(reg_ia)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x1 + x2 + x1 * x2 - 1, data = dat)

Residuals:
         1          2          3          4 
-1.178e-16 -1.424e-32  1.298e-32  6.588e-34 

Coefficients:
        Estimate Std. Error    t value Pr(&gt;|t|)    
x1     1.000e+00  1.178e-16  8.489e+15   &lt;2e-16 ***
x2     1.000e+00  1.178e-16  8.489e+15   &lt;2e-16 ***
x1:x2 -2.000e+00  2.040e-16 -9.802e+15   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.178e-16 on 1 degrees of freedom
Multiple R-squared:      1, Adjusted R-squared:      1 
F-statistic: 4.804e+31 on 3 and 1 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(reg_ia),<span class="dv">3</span>)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 2 3 4 
0 1 1 0 </code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'x1'</span>: [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>], <span class="st">'x2'</span>: [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>], <span class="st">'x1x2'</span>: [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>], <span class="st">'y'</span>: [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>]}</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'x1'</span>, <span class="st">'x2'</span>, <span class="st">'x1x2'</span>]]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'y'</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>reg_ia <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(reg_ia.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   1.000
Model:                            OLS   Adj. R-squared (uncentered):              1.000
Method:                 Least Squares   F-statistic:                          6.761e+29
Date:                Fri, 06 Jun 2025   Prob (F-statistic):                    8.94e-16
Time:                        08:21:36   Log-Likelihood:                          135.28
No. Observations:                   4   AIC:                                     -264.6
Df Residuals:                       1   BIC:                                     -266.4
Df Model:                           3                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             1.0000   9.93e-16   1.01e+15      0.000       1.000       1.000
x2             1.0000   9.93e-16   1.01e+15      0.000       1.000       1.000
x1x2          -2.0000   1.72e-15  -1.16e+15      0.000      -2.000      -2.000
==============================================================================
Omnibus:                          nan   Durbin-Watson:                   2.000
Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.419
Skew:                           0.652   Prob(JB):                        0.811
Kurtosis:                       2.097   Cond. No.                         3.73
==============================================================================

Notes:
[1] R² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(reg_ia.predict(),<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 0.  1.  1. -0.]</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The model <span class="math inline">\(Y = x_1 + x_2 - 2 x_1 x_2\)</span> perfectly fits the gate. It has an <span class="math inline">\(R^2=1\)</span>, <span class="math inline">\(SSE=0\)</span>, and still one degree of freedom left for the error. The model has 1/3 the parameters of the neural network and is intrinsically interpretable.</p>
</div>
</div>
<p>The classical linear model works well if <span class="math inline">\(n \gg p\)</span> and the input variables do not exhibit multicollinearity. If the model errors have zero mean, the least-squares estimators are unbiased, and thus the model is unbiased. However, it does not necessarily have the lowest mean-squared error. As <span class="math inline">\(p\)</span> grows, for fixed sample size <span class="math inline">\(n\)</span>, problems start to mount:</p>
<ul>
<li>The OLS estimator becomes more unstable, exacerbated by multicollinearity.</li>
<li>When <span class="math inline">\(p &gt; n\)</span>, a unique OLS estimator does not exist, <span class="math inline">\((\textbf{X}^\prime\textbf{X})^{-1}\)</span> cannot be computed.</li>
<li>Other estimation approaches lead to models with smaller mean-squared prediction error.</li>
</ul>
<p>With increasing <span class="math inline">\(p\)</span>, relative to <span class="math inline">\(n\)</span>, the regression problem turns into a <strong>high-dimensional</strong> problem. Situations in which there are more input variables than observations are not at all uncommon.</p>
<div class="example">
<div class="example-header">
<p>Example: Microarray Analysis</p>
</div>
<div class="example-container">
<p>A microarray is a rectangular array in which the expression of genes is compared between two samples, often a reference (healthy individual) and an experimental sample (cancer patient). The samples are dyed green and red. If gene expression is higher [lower] in the experimental sample the corresponding spot on the microarray appears red [green]. A 20 x 20 array yields 400 inputs, but you might have only data on 10 arrays.</p>
<div id="fig-microarray" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig.align="center" data-out.width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-microarray-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/microarray.png" class="img-fluid figure-img" data-fig.align="center" data-out.width="80%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-microarray-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: A gene expression microarray
</figcaption>
</figure>
</div>
</div>
</div>
<p>How can we address the shortcomings of the classical linear model as problems become higher dimensional?</p>
<p><strong>Algorithmic feature selection</strong> uses search techniques and cross-validation to find well-fitting models among the <span class="math inline">\(2^p\)</span> possible linear models you can build with <span class="math inline">\(p\)</span> inputs (<a href="#sec-feature-select" class="quarto-xref"><span>Section 8.1</span></a>). The goal is to find a relatively small set of inputs that explains sufficient variability in the data and to eliminate inputs that do not contribute (much) to explaining the variability.</p>
<p><strong>Regularization</strong> techniques consider all <span class="math inline">\(p\)</span> inputs, even if <span class="math inline">\(p\)</span> is large, and allay the shortcomings of the ordinary least squares estimator by penalizing its tendency toward instability (<a href="#sec-regularization" class="quarto-xref"><span>Section 8.2</span></a>). Regularization penalties shrink the estimators toward zero, thereby limiting the variability they can inflict on the model. The resulting estimators are biased, but at the same time their variability is suppressed enough to lead to an overall smaller mean-square prediction error compared to ordinary least squares.</p>
<p><strong>Dimension reduction</strong> methods derive <span class="math inline">\(m\)</span> linear combinations of the <span class="math inline">\(p\)</span> inputs where <span class="math inline">\(m \ll p\)</span>. The <span class="math inline">\(m\)</span> combinations are treated as inputs to the model, thereby reducing the dimension of the regression while still consuming information from all <span class="math inline">\(p\)</span> inputs (<a href="#sec-feature-dimred" class="quarto-xref"><span>Section 8.3</span></a>).</p>
<p>In summary, feature selection chooses a subset of the <span class="math inline">\(p\)</span> inputs, regularization keeps all <span class="math inline">\(p\)</span> inputs and introduces bias to limit variability, dimension reduction uses <span class="math inline">\(m &lt; p\)</span> linear combinations of the variables.</p>
<section id="sec-feature-select" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="sec-feature-select"><span class="header-section-number">8.1</span> Algorithmic Feature Selection</h2>
<p>Suppose you have <span class="math inline">\(p\)</span> candidate input variables. How many possible linear models are there? One model without any inputs, one model with all <span class="math inline">\(p\)</span> inputs, <span class="math inline">\(p\)</span> models have a single input, and so on. The number of models having <span class="math inline">\(k \le p\)</span> inputs is <span class="math display">\[
{p \choose k} = \frac{p!}{k!(p-k)!}
\]</span> and the total number of models is <span class="math display">\[
\sum_{k=0}^p {p\choose k} = {p\choose0} + {p\choose 1} + \cdots + {p\choose p-1} + {p\choose p}
\]</span> By the <strong>binomial theorem</strong>, <span class="math inline">\((x+y)^n = \sum_{k=0}^n {n\choose k}x^{n-k}y^{k}\)</span>. Setting <span class="math inline">\(x=y=1\)</span>, we find that the total number of models equals <span class="math inline">\(2^p\)</span>. This is a very large number even for moderate <span class="math inline">\(p\)</span>. With <span class="math inline">\(p=10\)</span> there are “only” 1,024 models, with <span class="math inline">\(p=20\)</span> this number increases to 1,048,576, with <span class="math inline">\(p=30\)</span> there are 1,073,741,824 models–more than a billion.</p>
<section id="two-step-procedure" class="level3">
<h3 class="anchored" data-anchor-id="two-step-procedure">Two-step Procedure</h3>
<p>Evaluating all regression models becomes unfeasible quickly due to the large number of models. Instead, we use a two-step process:</p>
<ol type="1">
<li>Among the set <span class="math inline">\(\{M_k\}\)</span> of <span class="math inline">\(k\)</span>-size models, find the best candidate and call it <span class="math inline">\(M_k^*\)</span>.</li>
<li>Choose the single best model among <span class="math inline">\(M_0^*, M_1^*, \cdots, M_p^*\)</span> (the “best of the best”).</li>
</ol>
<p>The feature selection methods differ in how they construct the candidate sets <span class="math inline">\(\{M_k\}\)</span> in step 1. For example, best subset selection uses efficient search algorithms to explore the space of possible models, forward selection considers <span class="math inline">\(\{M_k\}\)</span> as a superset of <span class="math inline">\(\{M_{k-1}\}\)</span>, backward selection considers <span class="math inline">\(\{M_k\}\)</span> as a subset of <span class="math inline">\(\{M_{k+1\}\)</span>.</p>
<p>In step 1 the “best” model is chosen among the <span class="math inline">\(k\)</span>-size models using criteria such as SSE, <span class="math inline">\(R^2\)</span>, <span class="math inline">\(p\)</span>-values, etc.</p>
<p>In step 2 the models are compared based on an estimate of test error using cross-validation or, more commonly, an indirect estimate of test error.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>When choosing <span class="math inline">\(p\)</span>-values to judge models against each other during variable selection, you are performing many tests and you are not testing hypotheses in the typical sense. Feature selection is not akin to formulating a research hypothesis, collecting data, and testing whether the data support the hypothesis. The use of <span class="math inline">\(p\)</span>-values during variable selection is more akin to a rough check whether adding or removing a feature should be considered. Thus, larger thresholds such as <span class="math inline">\(p=0.1\)</span> or <span class="math inline">\(p=0.2\)</span> are used, rather than <span class="math inline">\(p=0.01\)</span> or <span class="math inline">\(p=0.05\)</span> as in standard hypothesis testing.</p>
<p>Even if the process would be testing hypotheses in the usual sense, the large number of comparisons, each with a chance of a Type-I or Type-II error, creates a massive <strong>multiplicity</strong> (multiple testing) problem.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Feature selection methods in software do not necessarily use a two-step procedure. For example, software might use <span class="math inline">\(p\)</span>-values to determine whether adding input variables in forward selection significantly improves the model and stop the process if no input variable that is currently not in the model improves the model according to the <span class="math inline">\(p\)</span>-value threshold. Similarly, in backward elimination the process might stop if no input variable can be removed from the model without “significantly” (according to the chosen <span class="math inline">\(p\)</span>-level) deteriorating the model.</p>
<p>These procedures do not seek the best <span class="math inline">\(k\)</span>-input models and do not compare them in a second step.</p>
</div>
</div>
</section>
<section id="indirect-estimates-of-test-error" class="level3">
<h3 class="anchored" data-anchor-id="indirect-estimates-of-test-error">Indirect Estimates of Test Error</h3>
<p>Cross-validation approaches such as train:test split, leave-one-out cross-validation, or <span class="math inline">\(k\)</span>-fold cross-validation produce a <strong>direct</strong> estimate of the mean-squared prediction error. <strong>Indirect</strong> estimates of the test error make adjustments to quantities derived from the training data and are easy to compute. These estimates are used to quickly quantify model performance without random elements and to compare non-nested models. The best <span class="math inline">\(M_k^*\)</span> and best <span class="math inline">\(M_j^*\)</span> models in feature selection are not necessarily nested in the sense that one model can be reduced from the other–they might have completely different inputs. Those models cannot be compared based on <span class="math inline">\(p\)</span>-values or just SSE. Some adjustments is necessary to incorporate the model complexity and to avoid overfitting.</p>
<section id="mallows-c_p" class="level4">
<h4 class="anchored" data-anchor-id="mallows-c_p">Mallows’ <span class="math inline">\(C_p\)</span></h4>
<p>The <span class="math inline">\(C_p\)</span> statistic of <span class="citation" data-cites="Mallows1973">Mallows (<a href="references.html#ref-Mallows1973" role="doc-biblioref">1973</a>)</span> estimates the average sum of prediction errors <span class="math display">\[
\Gamma_p = \frac{1}{\sigma^2}\text{E}\left [\sum_{i=1}^n \left(\widehat{Y}_i - \text{E}[Y_i|\textbf{x}_i]\right)^2 \right]
\]</span> It is a prediction-oriented criteria that seeks to strike a balance between the bias of an underfit model and the variability of an overfit model. <span class="math inline">\(\Gamma_p\)</span> expands into <span id="eq-cp-pop"><span class="math display">\[
\Gamma_p = \frac{1}{\sigma^2} \left(\sum_{i=1}^n\text{Var}[\widehat{Y}_i] + \sum_{i=1}^n\left[\text{Bias}(\widehat{Y}_i)\right]^2 \right)
\tag{8.1}\]</span></span></p>
<p>The contribution of an overfit model is the first term in parentheses, <span class="math inline">\(\text{Var}[\widehat{Y}_i]\)</span>, the contribution of an underfit model is the squared bias term. It is insightful to take a look at the first piece, the sum of the variances of the predicted values. Suppose we have a model with <span class="math inline">\(d\)</span> inputs. From <span class="math inline">\(\widehat{\textbf{Y}} = \textbf{X}\widehat{\boldsymbol{\beta}}\)</span> it follows that <span class="math display">\[
\text{Var}[\widehat{\textbf{Y}}] = \sigma^2 \textbf{X}(\textbf{X}^\prime\textbf{X})^{-1}\textbf{X}^\prime = \sigma^2 \textbf{H}
\]</span> The Hat matrix is a projection matrix of rank <span class="math inline">\(d+1\)</span> and thus <span class="math display">\[
\sum_{i=1}^n \text{Var}[\widehat{Y}_i] = \sigma^2(d+1)
\]</span></p>
<p>The sum of the variances of the predicted values will go up when inputs are added to the model, whether the inputs are useful in explaining variability in <span class="math inline">\(Y\)</span> or not. Adding junk variables to a model results in greater variability of the predicted values–there is “no free lunch”.</p>
<p>The bias term in <a href="#eq-cp-pop" class="quarto-xref">Equation&nbsp;<span>8.1</span></a> can be estimated as <span class="math display">\[
(\widehat{\sigma}^2_d - \sigma^2)(n-d-1)
\]</span> where <span class="math inline">\(\widehat{\sigma}^2_d\)</span> is the estimate of <span class="math inline">\(\sigma^2\)</span> in a model with <span class="math inline">\(d\)</span> inputs. Putting everything together we arrive at an estimator of <span class="math inline">\(\Gamma_p\)</span>, known as Mallow’s <span class="math inline">\(C_p\)</span> statistic <span class="math display">\[
C_p = \frac{1}{\widehat{\sigma}^2}\left(\widehat{\sigma}^2(d+1) + (\widehat{\sigma}^2_d - \widehat{\sigma}^2)(n-d-1) \right) = \frac{\text{SSE}}{\widehat{\sigma}^2} - n + 2(d+1)
\]</span> where <span class="math inline">\(d\)</span> is the number of inputs in the model, <span class="math inline">\((d+1)\)</span> accounts for the intercept. In feature selection, <span class="math inline">\(\widehat{\sigma}^2\)</span> is based on the full model with <span class="math inline">\(p\)</span> inputs, since this model most likely yields the least biased estimator of the variance of the model errors. Among a set of competing models, select the one with the <strong>smallest</strong> <span class="math inline">\(C_p\)</span> statistic. Among models with the same number of inputs, <span class="math inline">\(d\)</span>, selection based on <span class="math inline">\(C_p\)</span> leads to choosing the model with the smallest SSE. The term <span class="math inline">\(2(d+1)\)</span> can be viewed as a penalty term for model complexity. A larger model has to reduce SSE more substantially to overcome the additional parameters.</p>
<p>An alternative formulation for Mallow’s statistic is <span class="math display">\[
C_p^\prime = \frac{1}{n}\left(\text{SSE} + 2(d+1)\widehat{\sigma}^2\right)
\]</span> <span class="math inline">\(C_p\)</span> and <span class="math inline">\(C_p^\prime\)</span> are not identical but they lead to the selection of the same model if models are chosen according to smaller <span class="math inline">\(C_p\)</span> or smaller <span class="math inline">\(C_p^\prime\)</span> values.</p>
</section>
<section id="aic-and-bic" class="level4">
<h4 class="anchored" data-anchor-id="aic-and-bic">AIC and BIC</h4>
<p>Akaike’s Information Criterion (AIC) and the Bayesian Information Criterion (BIC) are based on likelihood theory and assume a distribution for the data, given the parameter estimates. In linear models, this distribution is typically Gaussian, and the criteria are computed as follows:</p>
<p><span class="math display">\[
\begin{align*}
\text{AIC} &amp;= n\log \left(\frac{\text{SSE}}{n}\right) + 2(d+1) \\
\text{BIC} &amp;= n\log \left(\frac{\text{SSE}}{n}\right) + \log(n)(d+1)
\end{align*}
\]</span> In this formulation, choose the model with the smaller AIC and smaller BIC. Selection based on AIC and <span class="math inline">\(C_p\)</span> lead to the same model.</p>
<p>BIC applies a stronger complexity penalty when <span class="math inline">\(\log(n) &gt; 2\)</span>, (<span class="math inline">\(n &gt; 7\)</span>), and thus tends to select models smaller than <span class="math inline">\(C_p\)</span> or AIC.</p>
</section>
<section id="adjusted-r2" class="level4">
<h4 class="anchored" data-anchor-id="adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></h4>
<p>This statistic applies a correction to <span class="math inline">\(R^2\)</span> that penalizes larger models. It is not an estimate of the test error, but is still useful to select models. For a model with <span class="math inline">\(d\)</span> inputs, <span class="math display">\[
\text{Adjusted } R^2 = 1 - \frac{\text{SSE}}{\text{SST}}\left(\frac{n-1}{n-d-1} \right) = 1-(1-R^2)\left(\frac{n-1}{n-d-1} \right)
\]</span> When inputs are added to a model, SSE decreases and <span class="math inline">\(R^2\)</span> increases. However, <span class="math inline">\(\text{SSE}/(n-d-1)\)</span> may increase or decrease. If unimportant variables are added, the reduction in SSE does not offset the loss of degree of freedom and Adjusted <span class="math inline">\(R^2\)</span> will be smaller. When selecting models based on Adjusted <span class="math inline">\(R^2\)</span>, choose the model with the larger value.</p>
<!--

::: {.cell}

```{.r .cell-code}
library(ISLR2)
regfit <- lm(Balance ~ .,data=Credit)
s <- summary(regfit)
r2 <- s$r.squared
d <- length(s$coefficients[,1])-1
n <- length(s$residuals)
adjr2 <- 1 - (1-r2)*(n-1)/(n-d-1)
adjr2
```

::: {.cell-output .cell-output-stdout}

```
[1] 0.9538287
```


:::
:::

-->
</section>
</section>
<section id="best-subset-selection" class="level3">
<h3 class="anchored" data-anchor-id="best-subset-selection">Best Subset Selection</h3>
<p>The concept of best subset selection is simple, find the model that has the best value of a fit criterion such as <span class="math inline">\(C_p\)</span>, AIC, BIC, etc., among all possible models. As outlined previously, model selection is carried out in two steps: find the best 1-input, 2-input, 3-input, …, model in the first step and identify the best <span class="math inline">\(k\)</span>-input model in the second step.</p>
<p>Exploring the space of all possible models by brute force is computationally expensive and possibly prohibitive as <span class="math inline">\(p\)</span> grows. The LEAPS algorithm of <span class="citation" data-cites="FurnivalWilson1974">Furnival and Wilson (<a href="references.html#ref-FurnivalWilson1974" role="doc-biblioref">1974</a>)</span> uses an efficient branch-and-bound algorithm to explore the model space and avoids visiting all possible models. It uses a separate tree as the bounding function that eliminates models that need not be considered given the branches of models that have already been seen. This algorithm is implemented as <code>method="exhaustive"</code> in the <code>regsubsets</code> function of the <code>leaps</code> package in <code>R</code>. In Python there is no implementation of the LEAPS algorithm, performing best subset regression uses a brute force method that iterates over all possible models.</p>
<div class="example">
<div class="example-header">
<p>Example: Credit Data from ISLR2</p>
</div>
<div class="example-container">
<p>We are using here the <code>Credit</code> data from <span class="citation" data-cites="James2013_ISLR2">James et al. (<a href="references.html#ref-James2013_ISLR2" role="doc-biblioref">2021</a>, Sec 3.3, p.85)</span>. The data are simulated observations (400) on</p>
<ul>
<li>Income: income in $1,000</li>
<li>Limit: credit limit</li>
<li>Rating: credit rating</li>
<li>Cards: number of credit cards</li>
<li>Age: age in years</li>
<li>Education: education in years</li>
<li>Own: two-level factor whether individual owns a home (“Yes”/“No”)</li>
<li>Student: two-level factor whether individual is a student (“Yes”/“No”)</li>
<li>Married: two-level factor whether individual is married (“Yes”/“No”)</li>
<li>Region: three-level factor of geographic location (“East”, “South”, “West”)</li>
<li>Balance: average credit card balance in $</li>
</ul>
<p>The target variable is <code>Balance</code>.</p>
<p>There are 10 input variables, 6 numeric variables, 3 two-level factors and one three-level factor (<code>Region</code>). When all variables are included, this leads to a model with <span class="math inline">\(p = 6 + 3 + 2 = 11\)</span> predictors. The three-level <code>Region</code> variable expands to two columns in <span class="math inline">\(\textbf{X}\)</span>, the first level serves as default as the reference level.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>The following code performs best subset regression with the leaps algorithm. The <code>nvmax</code> parameter limits the maximum size of subsets to examine by the leaps-and-bound algorithm; the default is <code>nvmax=8</code>. Setting it to <code>NULL</code> forces the algorithm to consider all subsets up to size <span class="math inline">\(p\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>regfit <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Balance <span class="sc">~</span> ., <span class="at">data=</span>Credit, <span class="at">method=</span><span class="st">"exhaustive"</span>, <span class="at">nvmax=</span><span class="cn">NULL</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>s_all <span class="ot">&lt;-</span> <span class="fu">summary</span>(regfit)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>s_all</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
Call: regsubsets.formula(Balance ~ ., data = Credit, method = "exhaustive", 
    nvmax = NULL)
11 Variables  (and intercept)
            Forced in Forced out
Income          FALSE      FALSE
Limit           FALSE      FALSE
Rating          FALSE      FALSE
Cards           FALSE      FALSE
Age             FALSE      FALSE
Education       FALSE      FALSE
OwnYes          FALSE      FALSE
StudentYes      FALSE      FALSE
MarriedYes      FALSE      FALSE
RegionSouth     FALSE      FALSE
RegionWest      FALSE      FALSE
1 subsets of each size up to 11
Selection Algorithm: exhaustive
          Income Limit Rating Cards Age Education OwnYes StudentYes MarriedYes
1  ( 1 )  " "    " "   "*"    " "   " " " "       " "    " "        " "       
2  ( 1 )  "*"    " "   "*"    " "   " " " "       " "    " "        " "       
3  ( 1 )  "*"    " "   "*"    " "   " " " "       " "    "*"        " "       
4  ( 1 )  "*"    "*"   " "    "*"   " " " "       " "    "*"        " "       
5  ( 1 )  "*"    "*"   "*"    "*"   " " " "       " "    "*"        " "       
6  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       " "    "*"        " "       
7  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
8  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
9  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
10  ( 1 ) "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
11  ( 1 ) "*"    "*"   "*"    "*"   "*" "*"       "*"    "*"        "*"       
          RegionSouth RegionWest
1  ( 1 )  " "         " "       
2  ( 1 )  " "         " "       
3  ( 1 )  " "         " "       
4  ( 1 )  " "         " "       
5  ( 1 )  " "         " "       
6  ( 1 )  " "         " "       
7  ( 1 )  " "         " "       
8  ( 1 )  " "         "*"       
9  ( 1 )  " "         "*"       
10  ( 1 ) "*"         "*"       
11  ( 1 ) "*"         "*"       </code></pre>
</div>
</div>
<!---

::: {.cell}

```{.r .cell-code}
X <- model.matrix(Balance ~ ., data=Credit)
XpX = t(X) %*% X
H = X %*% solve(XpX) %*% t(X)
sum(diag(H))
```

::: {.cell-output .cell-output-stdout}

```
[1] 12
```


:::

```{.r .cell-code}
ncol(X)
```

::: {.cell-output .cell-output-stdout}

```
[1] 12
```


:::

```{.r .cell-code}
X[1:10,]
```

::: {.cell-output .cell-output-stdout}

```
   (Intercept)  Income Limit Rating Cards Age Education OwnYes StudentYes
1            1  14.891  3606    283     2  34        11      0          0
2            1 106.025  6645    483     3  82        15      1          1
3            1 104.593  7075    514     4  71        11      0          0
4            1 148.924  9504    681     3  36        11      1          0
5            1  55.882  4897    357     2  68        16      0          0
6            1  80.180  8047    569     4  77        10      0          0
7            1  20.996  3388    259     2  37        12      1          0
8            1  71.408  7114    512     2  87         9      0          0
9            1  15.125  3300    266     5  66        13      1          0
10           1  71.061  6819    491     3  41        19      1          1
   MarriedYes RegionSouth RegionWest
1           1           1          0
2           1           0          1
3           0           0          1
4           0           0          1
5           1           1          0
6           0           1          0
7           0           0          0
8           0           0          1
9           0           1          0
10          1           0          0
```


:::
:::

--->
<p>With <span class="math inline">\(p=11\)</span> predictors, there are 11 sets <span class="math inline">\(\{M_1\}, \cdots, \{M_{11}\}\)</span>. The best single-predictor model–the best model in the set <span class="math inline">\(\{M_1\}\)</span>– is <span class="math display">\[
M_1^*: \text{Balance} = \beta_0 + \beta_1\text{Rating} + \epsilon
\]</span> The best model in <span class="math inline">\(\{M_2\}\)</span> is <span class="math display">\[
M_2^*: \text{Balance} = \beta_0 + \beta_1\text{Income} + \beta_2\text{Rating} + \epsilon
\]</span> and so on. Notice that <code>Rating</code> is included in <span class="math inline">\(M_1^*\)</span>, <span class="math inline">\(M_2^*\)</span>, and <span class="math inline">\(M_3^*\)</span> but is not present in <span class="math inline">\(M_4^*\)</span>.</p>
<p>To select the best model from the best <span class="math inline">\(k\)</span>-input models, we look at the model summary performance measures:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>s_all<span class="sc">$</span>cp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 1800.308406  685.196514   41.133867   11.148910    8.131573    5.574883
 [7]    6.462042    7.845931    9.192355   10.472883   12.000000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>s_all<span class="sc">$</span>bic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  -535.9468  -814.1798 -1173.3585 -1198.0527 -1197.0957 -1195.7321
 [7] -1190.8790 -1185.5192 -1180.1989 -1174.9476 -1169.4433</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>s_all<span class="sc">$</span>adjr2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.7452098 0.8744888 0.9494991 0.9531099 0.9535789 0.9539961 0.9540098
 [8] 0.9539649 0.9539243 0.9538912 0.9538287</code></pre>
</div>
</div>
<p>Selecting models according to <span class="math inline">\(C_p\)</span>, the best 6-input model is chosen. Based on BIC and Adjusted <span class="math inline">\(R^2\)</span>, we would choose the best 4-input and best 7-input model, respectively (<a href="#fig-best-subset-results" class="quarto-xref">Figure&nbsp;<span>8.2</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(s_all<span class="sc">$</span>cp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(s_all<span class="sc">$</span>bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(s_all<span class="sc">$</span>adjr2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-best-subset-results" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-best-subset-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-best-subset-results-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-best-subset-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: Results of best subsets regression.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>The following statements read the Credit data set from the DuckDB database and convert the categorical variables to numeric variables using one-hot encoding with <code>pd.get_dummies</code>. One of the encoded columns is dropped for each categorical variable to match the design matrix layout in <code>R</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>con <span class="op">=</span> duckdb.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"ads.ddb"</span>, read_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>credit_df <span class="op">=</span> con.sql(<span class="st">"SELECT * FROM Credit;"</span>).df()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>con.close()</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>credit_encoded <span class="op">=</span> pd.get_dummies(credit_df, prefix_sep<span class="op">=</span><span class="st">''</span>, dtype<span class="op">=</span><span class="st">'float64'</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>credit_encoded <span class="op">=</span> credit_encoded.drop([<span class="st">'OwnNo'</span>, <span class="st">'StudentNo'</span>,<span class="st">'MarriedNo'</span>,<span class="st">'RegionEast'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>credit_encoded.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Income   Limit  Rating  ...  MarriedYes  RegionSouth  RegionWest
0   14.891  3606.0   283.0  ...         1.0          1.0         0.0
1  106.025  6645.0   483.0  ...         1.0          0.0         1.0
2  104.593  7075.0   514.0  ...         0.0          0.0         1.0
3  148.924  9504.0   681.0  ...         0.0          0.0         1.0
4   55.882  4897.0   357.0  ...         1.0          1.0         0.0

[5 rows x 12 columns]</code></pre>
</div>
</div>
<p>Python does not have a function to perform best subset regression with the LEAPS algorithm, so we roll our own brute force implementation. After parsing the model formula and extracting the target and input variables, <code>itertools</code> is used to create the sets <span class="math inline">\(\{M_1\}, \cdots, \{M_11\}\)</span> and the best <span class="math inline">\(k\)</span>-input model is selected based on the highest <span class="math inline">\(R^2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regsubsets(formula, data, method<span class="op">=</span><span class="st">"exhaustive"</span>, nvmax<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Python implementation similar to R's regsubsets function</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">    formula : str</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">        A formula like 'y ~ x1 + x2 + x3'</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co">    data : pandas.DataFrame</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co">        The dataset containing the variables</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co">    method : str</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Method for subset selection ('exhaustive' is implemented here)</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co">    nvmax : int or None</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Maximum number of predictors to consider</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : A dictionary containing results for each model size</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse formula</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>    y_var, x_vars <span class="op">=</span> formula.split(<span class="st">'~'</span>)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    y_var <span class="op">=</span> y_var.strip()</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    x_vars <span class="op">=</span> [x.strip() <span class="cf">for</span> x <span class="kw">in</span> x_vars.split(<span class="st">'+'</span>)]</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove '.' and replace with all columns except y_var</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'.'</span> <span class="kw">in</span> x_vars:</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>        x_vars.remove(<span class="st">'.'</span>)</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        all_cols <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> data.columns <span class="cf">if</span> col <span class="op">!=</span> y_var]</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        x_vars.extend(all_cols)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove duplicates</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x_vars = list(set(x_vars))</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare response variable</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> data[y_var]</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set nvmax if not specified</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> nvmax <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        nvmax <span class="op">=</span> <span class="bu">len</span>(x_vars)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        nvmax <span class="op">=</span> <span class="bu">min</span>(nvmax, <span class="bu">len</span>(x_vars))</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Results container</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">'which'</span>: [],  <span class="co"># Boolean matrix of selected variables</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">'rsq'</span>: [],    <span class="co"># R-squared values</span></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">'rss'</span>: [],    <span class="co"># Residual sum of squares</span></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'adjr2'</span>: [],  <span class="co"># Adjusted R-squared</span></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cp'</span>: [],     <span class="co"># Mallows' Cp</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bic'</span>: [],    <span class="co"># BIC</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'outmat'</span>: [], <span class="co"># Matrix of coefficients</span></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'nvars'</span>: [],  <span class="co"># Number of variables in each model</span></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">'var_names'</span>: x_vars  <span class="co"># Variable names</span></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate full model RSS for Cp statistic</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>    X_full <span class="op">=</span> sm.add_constant(data[x_vars])</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>    full_model <span class="op">=</span> sm.OLS(y, np.asarray(X_full)).fit()</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>    full_rss <span class="op">=</span> <span class="bu">sum</span>(full_model.resid <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>    p_full <span class="op">=</span> <span class="bu">len</span>(x_vars) <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for intercept</span></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate all possible subsets</span></span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> size <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, nvmax <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a>        best_rsq <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a>        best_model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a>        best_vars <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For each subset size, try all combinations</span></span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> combo <span class="kw">in</span> combinations(x_vars, size):</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Prepare predictors (add constant for intercept)</span></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>            X <span class="op">=</span> sm.add_constant(data[<span class="bu">list</span>(combo)])</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Fit the model</span></span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate metrics</span></span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>                rsq <span class="op">=</span> model.rsquared</span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Keep track of the best model for this size</span></span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> rsq <span class="op">&gt;</span> best_rsq:</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>                    best_rsq <span class="op">=</span> rsq</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>                    best_model <span class="op">=</span> model</span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>                    best_vars <span class="op">=</span> combo</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span>:</span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_model <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create boolean vector for selected variables</span></span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>            which <span class="op">=</span> [x <span class="kw">in</span> best_vars <span class="cf">for</span> x <span class="kw">in</span> x_vars]</span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate metrics for the best model of this size</span></span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>            rss <span class="op">=</span> <span class="bu">sum</span>(best_model.resid <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>            <span class="co"># rsq = best_model.rsquared</span></span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>            adjr2 <span class="op">=</span> best_model.rsquared_adj</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a>            p <span class="op">=</span> size <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for intercept</span></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>            cp <span class="op">=</span> (rss <span class="op">/</span> (full_rss <span class="op">/</span> (n <span class="op">-</span> p_full))) <span class="op">-</span> (n <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> p)</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>            bic <span class="op">=</span> n <span class="op">*</span> np.log(rss <span class="op">/</span> n) <span class="op">+</span> p <span class="op">*</span> np.log(n)</span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get coefficients</span></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a>            coefs <span class="op">=</span> best_model.params.tolist()</span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store results</span></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'which'</span>].append(which)</span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'rsq'</span>].append(rsq)</span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'rss'</span>].append(rss)</span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'adjr2'</span>].append(adjr2)</span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'cp'</span>].append(cp)</span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'bic'</span>].append(bic)</span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'outmat'</span>].append(coefs)</span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a>            results[<span class="st">'nvars'</span>].append(size)</span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following code calls the <code>regsubsets</code> function and displays the input variables for the <span class="math inline">\(k\)</span>-input step.</p>
<p>With <span class="math inline">\(p=11\)</span> predictors, there are 11 sets <span class="math inline">\(\{M_1\}, \cdots, \{M_{11}\}\)</span>. The best single-predictor model–the best model in the set <span class="math inline">\(\{M_1\}\)</span>– is <span class="math display">\[
M_1^*: \text{Balance} = \beta_0 + \beta_1\text{Rating} + \epsilon
\]</span> The best model in <span class="math inline">\(\{M_2\}\)</span> is <span class="math display">\[
M_2^*: \text{Balance} = \beta_0 + \beta_1\text{Income} + \beta_2\text{Rating} + \epsilon
\]</span> and so on. Notice that <code>Rating</code> is included in <span class="math inline">\(M_1^*\)</span>, <span class="math inline">\(M_2^*\)</span>, and <span class="math inline">\(M_3^*\)</span> but is not present in <span class="math inline">\(M_4^*\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> compress</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>regfit <span class="op">=</span> regsubsets(<span class="st">"Balance ~ ."</span>, data<span class="op">=</span>credit_encoded, method<span class="op">=</span><span class="st">"exhaustive"</span>, nvmax<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(regfit[<span class="st">'which'</span>])):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> <span class="bu">list</span>(compress(regfit[<span class="st">'var_names'</span>],regfit[<span class="st">'which'</span>][i]))</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best model with </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> predictors: </span><span class="sc">{</span>ll<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best model with 1 predictors: ['Rating']
Best model with 2 predictors: ['Income', 'Rating']
Best model with 3 predictors: ['Income', 'Rating', 'StudentYes']
Best model with 4 predictors: ['Income', 'Limit', 'Cards', 'StudentYes']
Best model with 5 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'StudentYes']
Best model with 6 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'StudentYes']
Best model with 7 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes']
Best model with 8 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'RegionWest']
Best model with 9 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionWest']
Best model with 10 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionSouth', 'RegionWest']
Best model with 11 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionSouth', 'RegionWest']</code></pre>
</div>
</div>
<p><a href="#fig-best-subset-py" class="quarto-xref">Figure&nbsp;<span>8.3</span></a> displays the Adjusted <span class="math inline">\(R^2\)</span>, <span class="math inline">\(C_p\)</span>, and BIC values of the best <span class="math inline">\(k\)</span>-input regressions. If selection of the best model in step 2 of the process is based on Adjusted <span class="math inline">\(R^2\)</span>, the best seven-predictor model is chosen. If selection is based on <span class="math inline">\(C_p\)</span> or BIC, the best models with 6 or 4 inputs are chosen, respectively.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_regsubsets(summary_results):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Plot the results from regsubsets</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co">    summary_results : dict</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Results from summary_regsubsets function</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> [<span class="st">'adjr2'</span>, <span class="st">'cp'</span>, <span class="st">'bic'</span>]</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    n_plots <span class="op">=</span> <span class="bu">len</span>(metrics)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(n_plots, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">12</span>))</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, metric <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        l <span class="op">=</span> summary_results[metric]</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        axes[i].plot(summary_results[<span class="st">'nvars'</span>], l, <span class="st">'bo-'</span>)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        axes[i].set_xlabel(<span class="st">'Number of Variables'</span>)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        axes[i].set_ylabel(metric)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        axes[i].grid(<span class="va">True</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> metric <span class="op">==</span> <span class="st">'adjr2'</span>:</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>            lev_vars <span class="op">=</span> l.index(<span class="bu">max</span>(l))<span class="op">+</span><span class="dv">1</span></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>            lev_vars <span class="op">=</span> l.index(<span class="bu">min</span>(l))<span class="op">+</span><span class="dv">1</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        axes[i].axvline(x<span class="op">=</span>lev_vars, linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>plot_regsubsets(regfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-best-subset-py" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-best-subset-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="regfeature_files/figure-html/fig-best-subset-py-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1"><img src="regfeature_files/figure-html/fig-best-subset-py-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-best-subset-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: Fit statistics for the best <span class="math inline">\(k\)</span>-input models from best subset regression.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="forward-selection" class="level3">
<h3 class="anchored" data-anchor-id="forward-selection">Forward Selection</h3>
<p>Forward selection greatly reduces the number of models being evaluated, since at each stage <span class="math inline">\(k\)</span>, the set <span class="math inline">\(\{M_{k+1}\}\)</span> contains the <span class="math inline">\(p-k\)</span> models with one additional predictor variable. The process starts with the null model, <span class="math inline">\(M_0\)</span>, containing only the intercept. All <span class="math inline">\(p\)</span> predictors are then evaluated and the “best” is added to the model. Depending on the criteria, this is the predictor that reduces SSE or increases <span class="math inline">\(R^2\)</span> the most, or has the smallest <span class="math inline">\(p\)</span>-value. Suppose that <span class="math inline">\(x_4\)</span> was added to the model in this round. We now have <span class="math inline">\(M_1^*\)</span> and define as <span class="math inline">\(\{M_2\}\)</span> the set of models that contain <span class="math inline">\(x_4\)</span> and one additional predictor. At this stage we evaluate only <span class="math inline">\(p-1\)</span> models, rather than <span class="math inline">\({p \choose 2}\)</span> models.</p>
<p>In summary, only one predictor is added during each stage of forward selection, input variables that have been added in a previous stage remain in the model, and the total number of models evaluated is <span class="math display">\[
\sum_{k=0}^p (p-k) = 1 + \frac{p(p+1)}{2}
\]</span> Recall that with <span class="math inline">\(p=30\)</span>, evaluating all models requires visiting 1,073,741,824 models. Forward selection evaluates only 466 of them.</p>
<p>Forward selection has clear advantages:</p>
<ul>
<li>the number of models evaluated is small</li>
<li>the algorithm can be applied when <span class="math inline">\(p &gt; n\)</span> since it does not need to fit a model with all predictors</li>
</ul>
<p>There are also some clear disadvantages:</p>
<ul>
<li>it is not guaranteed that the algorithm visits the best model; in fact it is not even guaranteed that the algorithm finds the best <span class="math inline">\(k\)</span>-size model if <span class="math inline">\(k \ge 1\)</span>.</li>
<li>variables that are added early in the cycle can become unimportant with the addition of variables later in the cycle. A variable is not removed by the algorithm once it is added to the model.</li>
</ul>
<p>To illustrate these points, consider that <span class="math inline">\(x_4\)</span> is added to the model at stage <span class="math inline">\(k=0\)</span>. At <span class="math inline">\(k=1\)</span> input variable <span class="math inline">\(x_2\)</span> is chosen because it reduces SSE the most when one of the remaining predictors are added to a model that contains <span class="math inline">\(x_4\)</span>. The model <span class="math inline">\(M_2^*\)</span> has inputs <span class="math inline">\(\{x_4, x_2\}\)</span> according to forward selection. The best two-predictor model might be <span class="math inline">\(\{x_1,x_3\}\)</span> if all possible models with <span class="math inline">\(p=2\)</span> had been examined.</p>
<p>After the best <span class="math inline">\(k\)</span>-size models are found, the winning model is selected among those based on <span class="math inline">\(C_p\)</span>, BIC, Adjusted <span class="math inline">\(R^2\)</span>, or cross-validation. This is the second step of the general procedure for feature selection.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A form of forward selection does not select among the <span class="math inline">\(M_k^*\)</span> models in the second step. Instead, it specifies threshold values that a variable has to overcome to get added to the model, for example, a <span class="math inline">\(p\)</span>-value &lt; 0.1. Forward selection then continues until no variable outside of the model can be added to the model. If this happens at stage <span class="math inline">\(k+1\)</span>, the process stops and <span class="math inline">\(M_k^*\)</span> is chosen as the winning model.</p>
</div>
</div>
<div class="example">
<div class="example-header">
<p>Example: Credit Data from ISLR2 (Cont’d)</p>
</div>
<div class="example-container">
<p>Forward selection can be performed with <code>method="forward"</code> in <code>regsubsets</code>:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>regfit <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Balance <span class="sc">~</span> ., <span class="at">data=</span>Credit, <span class="at">method=</span><span class="st">"forward"</span>, <span class="at">nvmax=</span><span class="cn">NULL</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>s_forw <span class="ot">&lt;-</span> <span class="fu">summary</span>(regfit)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>s_forw</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
Call: regsubsets.formula(Balance ~ ., data = Credit, method = "forward", 
    nvmax = NULL)
11 Variables  (and intercept)
            Forced in Forced out
Income          FALSE      FALSE
Limit           FALSE      FALSE
Rating          FALSE      FALSE
Cards           FALSE      FALSE
Age             FALSE      FALSE
Education       FALSE      FALSE
OwnYes          FALSE      FALSE
StudentYes      FALSE      FALSE
MarriedYes      FALSE      FALSE
RegionSouth     FALSE      FALSE
RegionWest      FALSE      FALSE
1 subsets of each size up to 11
Selection Algorithm: forward
          Income Limit Rating Cards Age Education OwnYes StudentYes MarriedYes
1  ( 1 )  " "    " "   "*"    " "   " " " "       " "    " "        " "       
2  ( 1 )  "*"    " "   "*"    " "   " " " "       " "    " "        " "       
3  ( 1 )  "*"    " "   "*"    " "   " " " "       " "    "*"        " "       
4  ( 1 )  "*"    "*"   "*"    " "   " " " "       " "    "*"        " "       
5  ( 1 )  "*"    "*"   "*"    "*"   " " " "       " "    "*"        " "       
6  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       " "    "*"        " "       
7  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
8  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
9  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
10  ( 1 ) "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
11  ( 1 ) "*"    "*"   "*"    "*"   "*" "*"       "*"    "*"        "*"       
          RegionSouth RegionWest
1  ( 1 )  " "         " "       
2  ( 1 )  " "         " "       
3  ( 1 )  " "         " "       
4  ( 1 )  " "         " "       
5  ( 1 )  " "         " "       
6  ( 1 )  " "         " "       
7  ( 1 )  " "         " "       
8  ( 1 )  " "         "*"       
9  ( 1 )  " "         "*"       
10  ( 1 ) "*"         "*"       
11  ( 1 ) "*"         "*"       </code></pre>
</div>
</div>
<p>In the first step of the algorithm, <span class="math inline">\(k=0\)</span>, the variable <code>Rating</code> is added. It adds the greatest improvement over the intercept-only model among the 11 predictor variables. From now on, every model will contain the <code>Rating</code> variable. Recall that in best subset selection this variable was not part of the best 4-predictor model.</p>
<p>Choosing BIC as the criterion to select among <span class="math inline">\(M_1^*\)</span>–<span class="math inline">\(M_{11}^*\)</span>, the 5-predictor model is chosen; it has the smallest BIC:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>s_forw<span class="sc">$</span>bic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  -535.9468  -814.1798 -1173.3585 -1186.2300 -1197.0957 -1195.7321
 [7] -1190.8790 -1185.5192 -1180.1989 -1174.9476 -1169.4433</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(s_forw<span class="sc">$</span>bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<p>The best subset selection and forward selection algorithm lead to similar models</p>
<table class="table">
<caption>Models selected by best subset and forward selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1197.1</td>
</tr>
</tbody>
</table>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Forward selection (and other feature selection methods) are implemented in the <code>mlxtend</code> library for regression models or classifiers from <code>scikit-learn</code>. The <code>SequentialFeatureSelector</code> supports forward, backward, and “floating” versions of those in which inputs that were added (dropped) can be included (excluded) later on. That makes the floating versions akin to stepwise selection (see below).</p>
<p>Because <code>mlxtend</code> works with <code>scikit-learn</code> models, the first step of the selection, determining the best <span class="math inline">\(k\)</span>-input models, uses <code>LinearRegression</code>. Evaluating the models in the second step can use a different fitting method; we use <code>statsmodels</code> in the second step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.feature_selection <span class="im">import</span> SequentialFeatureSelector</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> feature_selection(X, y, method<span class="op">=</span><span class="st">"forward"</span>, max_features<span class="op">=</span><span class="va">None</span>, cv<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Performs forward selection similar to leaps::regsubsets(method="forward")</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co">    X : pandas DataFrame</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Predictors</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co">    y : pandas Series</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Response variable</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co">    max_features : int or None</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Maximum number of features to select</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : Results including selected features and metrics</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> max_features <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>        max_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize LinearRegression model</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> LinearRegression()</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    float_method <span class="op">=</span> <span class="va">False</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    forward_method <span class="op">=</span> <span class="va">True</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    num_features <span class="op">=</span> max_features</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> method<span class="op">==</span><span class="st">"backward"</span>:</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>        forward_method <span class="op">=</span> <span class="va">False</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        num_features <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> method<span class="op">==</span><span class="st">"stepwise"</span>:</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>        float_method <span class="op">=</span> <span class="va">True</span></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the sequential forward selector</span></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>    sfs <span class="op">=</span> SequentialFeatureSelector(lr,</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>                    k_features<span class="op">=</span>num_features,</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>                    forward<span class="op">=</span>forward_method,  </span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>                    floating<span class="op">=</span>float_method,</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>                    scoring<span class="op">=</span><span class="st">'r2'</span>,</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>                    cv<span class="op">=</span>cv</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    sfs.fit(X, y)</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit full model to get RSS for Cp</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>    X_full <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>    full_model <span class="op">=</span> sm.OLS(y, np.asarray(X_full)).fit()</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>    full_rss <span class="op">=</span> <span class="bu">sum</span>(full_model.resid <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>    p_full <span class="op">=</span> X.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for intercept</span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>    full_model.summary()     </span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Results container</span></span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>        <span class="st">'which'</span>: [],  <span class="co"># Boolean matrix of selected variables</span></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">'rsq'</span>: [],    <span class="co"># R-squared values</span></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">'rss'</span>: [],    <span class="co"># Residual sum of squares</span></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>        <span class="st">'adjr2'</span>: [],  <span class="co"># Adjusted R-squared</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cp'</span>: [],     <span class="co"># Mallow's Cp statistic</span></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bic'</span>: [],    <span class="co"># BIC</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">'var_names'</span>: X.columns.tolist(),</span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">'nvars'</span>: []   <span class="co"># Number of variables in each model</span></span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop through each subset size and get metrics</span></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, max_features <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get feature subset of size i</span></span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>        feature_subset <span class="op">=</span> <span class="bu">list</span>(sfs.subsets_[i][<span class="st">'feature_idx'</span>])</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a>        X_subset <span class="op">=</span> X.iloc[:, feature_subset]</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>        X_with_const <span class="op">=</span> sm.add_constant(X_subset)</span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> sm.OLS(y, X_with_const).fit()</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate metrics</span></span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a>        rsq <span class="op">=</span> model.rsquared</span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a>        rss <span class="op">=</span> <span class="bu">sum</span>(model.resid <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a>        adjr2 <span class="op">=</span> model.rsquared_adj</span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> i <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for intercept</span></span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a>        bic <span class="op">=</span> n <span class="op">*</span> np.log(rss <span class="op">/</span> n) <span class="op">+</span> p <span class="op">*</span> np.log(n)</span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a>        cp <span class="op">=</span> (rss <span class="op">/</span> (full_rss <span class="op">/</span> (n <span class="op">-</span> p_full))) <span class="op">-</span> (n <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> p)</span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create boolean vector for selected variables</span></span>
<span id="cb35-93"><a href="#cb35-93" aria-hidden="true" tabindex="-1"></a>        which <span class="op">=</span> [j <span class="kw">in</span> feature_subset <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb35-94"><a href="#cb35-94" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-95"><a href="#cb35-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store results</span></span>
<span id="cb35-96"><a href="#cb35-96" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'which'</span>].append(which)</span>
<span id="cb35-97"><a href="#cb35-97" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'rsq'</span>].append(rsq)</span>
<span id="cb35-98"><a href="#cb35-98" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'rss'</span>].append(rss)</span>
<span id="cb35-99"><a href="#cb35-99" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'adjr2'</span>].append(adjr2)</span>
<span id="cb35-100"><a href="#cb35-100" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'cp'</span>].append(cp)</span>
<span id="cb35-101"><a href="#cb35-101" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'bic'</span>].append(bic)</span>
<span id="cb35-102"><a href="#cb35-102" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">'nvars'</span>].append(i)</span>
<span id="cb35-103"><a href="#cb35-103" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-104"><a href="#cb35-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>forward_sel <span class="op">=</span> feature_selection(credit_encoded.drop(<span class="st">'Balance'</span>,axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>                  credit_encoded[<span class="st">'Balance'</span>],</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                  method<span class="op">=</span><span class="st">"forward"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(forward_sel[<span class="st">'which'</span>])):</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> <span class="bu">list</span>(compress(forward_sel[<span class="st">'var_names'</span>],forward_sel[<span class="st">'which'</span>][i]))</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best model with </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> predictors: </span><span class="sc">{</span>ll<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best model with 1 predictors: ['Rating']
Best model with 2 predictors: ['Income', 'Rating']
Best model with 3 predictors: ['Income', 'Rating', 'StudentYes']
Best model with 4 predictors: ['Income', 'Limit', 'Rating', 'StudentYes']
Best model with 5 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'StudentYes']
Best model with 6 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'StudentYes']
Best model with 7 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes']
Best model with 8 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'RegionWest']
Best model with 9 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionWest']
Best model with 10 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionSouth', 'RegionWest']
Best model with 11 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionSouth', 'RegionWest']</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>plot_regsubsets(forward_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
<p>The <code>mlxtend</code> library has its own plotting functions:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.plotting <span class="im">import</span> plot_sequential_feature_selection <span class="im">as</span> plot_sfs</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>sfs <span class="op">=</span> SequentialFeatureSelector(lr,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>                    k_features<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>                    forward<span class="op">=</span><span class="va">False</span>,  </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                    floating<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>                    scoring<span class="op">=</span><span class="st">'r2'</span>,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>                    cv<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>sfs.fit(credit_encoded.drop(<span class="st">'Balance'</span>,axis<span class="op">=</span><span class="dv">1</span>),credit_encoded[<span class="st">'Balance'</span>],)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SequentialFeatureSelector(cv=0, estimator=LinearRegression(), forward=False,
                          k_features=(1, 1), scoring='r2')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SequentialFeatureSelector<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>SequentialFeatureSelector(cv=0, estimator=LinearRegression(), forward=False,
                          k_features=(1, 1), scoring='r2')</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: LinearRegression</label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LinearRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>sfs.subsets_[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'feature_idx': (1,), 'cv_scores': array([0.74252218]), 'avg_score': 0.7425221799818015, 'feature_names': ('Limit',)}</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>fig1 <span class="op">=</span> plot_sfs(sfs.get_metric_dict(), kind<span class="op">=</span><span class="st">'std_dev'</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.8</span>, <span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Forward Selection (w. StdDev)'</span>)<span class="op">;</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>plt.grid()<span class="op">;</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="regfeature_files/figure-html/unnamed-chunk-16-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>The best subset selection and forward selection algorithm lead to similar models</p>
<table class="table">
<caption>Models selected by best subset and forward selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3705.5</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3706.4</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="backward-selection" class="level3">
<h3 class="anchored" data-anchor-id="backward-selection">Backward Selection</h3>
<p>Backward selection, also known as backward elimination, is similar to forward selection in that at each stage only a limited number of candidate models are considered, namely those models that have one less predictor than the model in the previous stage. In contrast to forward selection, backward selection starts with the full model with <span class="math inline">\(p\)</span> predictors and attempts to remove one variable at a time. The variable removed is the one that causes the smallest increase in SSE, smallest decrease in <span class="math inline">\(R^2\)</span>, or has the largest <span class="math inline">\(p\)</span>-value.</p>
<p>Backward selection has similar advantages and disadvantages compared to forward selection. It is computationally efficient because it visits only a subset of the possible models; <span class="math inline">\(1 + p(p+1)/2\)</span> models like forward selection. It is also not guaranteed to visit the best <span class="math inline">\(k\)</span>-size model or the best model overall.</p>
<p>If <span class="math inline">\(p &gt; n\)</span>, backward selection is not possible because the full model cannot be fit by least squares without regularization. On the other hand, starting with the full model provides the least biased estimate of the residual variance <span class="math inline">\(\sigma^2\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As with forward selection, a form of backward selection uses only <span class="math inline">\(p\)</span>-values or threshold values on change in SSE (<span class="math inline">\(R^2\)</span>) to stop the process of removing predictor variables if at any stage of the algorithm all variables exceed the threshold. That is, no variable can be removed without “significantly” deteriorating the model.</p>
</div>
</div>
<div class="example">
<div class="example-header">
<p>Example: Credit Data from ISLR2 (Cont’d)</p>
</div>
<div class="example-container">
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p>Backward selection can be performed with <code>method="backward"</code> in <code>regsubsets</code>. For this data set, the algorithm selects the same model as best subset selection.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>regfit <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Balance <span class="sc">~</span> ., <span class="at">data=</span>Credit, <span class="at">method=</span><span class="st">"backward"</span>, <span class="at">nvmax=</span><span class="cn">NULL</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>s_backw <span class="ot">&lt;-</span> <span class="fu">summary</span>(regfit)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>s_backw</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
Call: regsubsets.formula(Balance ~ ., data = Credit, method = "backward", 
    nvmax = NULL)
11 Variables  (and intercept)
            Forced in Forced out
Income          FALSE      FALSE
Limit           FALSE      FALSE
Rating          FALSE      FALSE
Cards           FALSE      FALSE
Age             FALSE      FALSE
Education       FALSE      FALSE
OwnYes          FALSE      FALSE
StudentYes      FALSE      FALSE
MarriedYes      FALSE      FALSE
RegionSouth     FALSE      FALSE
RegionWest      FALSE      FALSE
1 subsets of each size up to 11
Selection Algorithm: backward
          Income Limit Rating Cards Age Education OwnYes StudentYes MarriedYes
1  ( 1 )  " "    "*"   " "    " "   " " " "       " "    " "        " "       
2  ( 1 )  "*"    "*"   " "    " "   " " " "       " "    " "        " "       
3  ( 1 )  "*"    "*"   " "    " "   " " " "       " "    "*"        " "       
4  ( 1 )  "*"    "*"   " "    "*"   " " " "       " "    "*"        " "       
5  ( 1 )  "*"    "*"   "*"    "*"   " " " "       " "    "*"        " "       
6  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       " "    "*"        " "       
7  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
8  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
9  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
10  ( 1 ) "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
11  ( 1 ) "*"    "*"   "*"    "*"   "*" "*"       "*"    "*"        "*"       
          RegionSouth RegionWest
1  ( 1 )  " "         " "       
2  ( 1 )  " "         " "       
3  ( 1 )  " "         " "       
4  ( 1 )  " "         " "       
5  ( 1 )  " "         " "       
6  ( 1 )  " "         " "       
7  ( 1 )  " "         " "       
8  ( 1 )  " "         "*"       
9  ( 1 )  " "         "*"       
10  ( 1 ) "*"         "*"       
11  ( 1 ) "*"         "*"       </code></pre>
</div>
</div>
<p>Consider the full model with all 11 predictors first. The variable that causes the smallest increase in SSE or decrease in <span class="math inline">\(R^2\)</span> is <code>Education</code> and is removed. This variable is not considered in subsequent steps. The variable whose removal causes the smallest increase in SSE at the next step is <code>RegionSouth</code> and so on.</p>
<p>Based on BIC, backward selection chooses the same model as best subset selection–for these data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>s_backw<span class="sc">$</span>bic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  -530.7458  -801.5344 -1164.9522 -1198.0527 -1197.0957 -1195.7321
 [7] -1190.8790 -1185.5192 -1180.1989 -1174.9476 -1169.4433</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(s_backw<span class="sc">$</span>bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4</code></pre>
</div>
</div>
<table class="table">
<caption>Models selected by best subset, forward, and backward selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1197.1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Backward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
</tbody>
</table>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>backward_sel <span class="op">=</span> feature_selection(credit_encoded.drop(<span class="st">'Balance'</span>,axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>                  credit_encoded[<span class="st">'Balance'</span>],</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>                  method<span class="op">=</span><span class="st">"backward"</span>)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>plot_regsubsets(backward_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
<p>Based on BIC, backward selection chooses the same model as best subset selection–for these data.</p>
<table class="table">
<caption>Models selected by best subset, forward, and backward selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3705.5</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3706.4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Backward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3705.5</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="stepwise-selection" class="level3">
<h3 class="anchored" data-anchor-id="stepwise-selection">Stepwise Selection</h3>
<p>This selection method combines elements of forward and backward selection. A problem of those algorithms is that once a variable has been added it cannot be removed (forward) or once a variable has been removed it cannot be added (backward) at a later step. A stepwise procedure that starts from the null model examines after the addition of a variable if any of the variables now in the model should be removed. Stepwise procedures, also called hybrid procedures, examine more models than forward or backward methods but do not exhaust the entire space of models.</p>
<p>A variation is the sequential replacement algorithm of <span class="citation" data-cites="Miller1984">Miller (<a href="references.html#ref-Miller1984" role="doc-biblioref">1984</a>)</span> implemented in the <code>leaps</code> package. Instead of removing a variable from a model, replacement attempts to replace any variable in the model with a variable not in the model. Variables are considered for replacement at every step, allowing variables that are being replaced at one stage to re-enter the model at a later stage.</p>
<div class="example">
<div class="example-header">
<p>Example: Credit Data from ISLR2 (Cont’d)</p>
</div>
<div class="example-container">
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<p>Sequential replacement selection can be performed with <code>method="seqrep"</code> in <code>regsubsets</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>regfit <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Balance <span class="sc">~</span> ., <span class="at">data=</span>Credit, <span class="at">method=</span><span class="st">"seqrep"</span>, <span class="at">nvmax=</span><span class="cn">NULL</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>s_seqrep <span class="ot">&lt;-</span> <span class="fu">summary</span>(regfit)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>s_seqrep</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
Call: regsubsets.formula(Balance ~ ., data = Credit, method = "seqrep", 
    nvmax = NULL)
11 Variables  (and intercept)
            Forced in Forced out
Income          FALSE      FALSE
Limit           FALSE      FALSE
Rating          FALSE      FALSE
Cards           FALSE      FALSE
Age             FALSE      FALSE
Education       FALSE      FALSE
OwnYes          FALSE      FALSE
StudentYes      FALSE      FALSE
MarriedYes      FALSE      FALSE
RegionSouth     FALSE      FALSE
RegionWest      FALSE      FALSE
1 subsets of each size up to 11
Selection Algorithm: 'sequential replacement'
          Income Limit Rating Cards Age Education OwnYes StudentYes MarriedYes
1  ( 1 )  " "    " "   "*"    " "   " " " "       " "    " "        " "       
2  ( 1 )  "*"    "*"   " "    " "   " " " "       " "    " "        " "       
3  ( 1 )  "*"    " "   "*"    " "   " " " "       " "    "*"        " "       
4  ( 1 )  "*"    "*"   " "    "*"   " " " "       " "    "*"        " "       
5  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       " "    " "        " "       
6  ( 1 )  "*"    "*"   "*"    "*"   "*" "*"       " "    " "        " "       
7  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
8  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        " "       
9  ( 1 )  "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
10  ( 1 ) "*"    "*"   "*"    "*"   "*" " "       "*"    "*"        "*"       
11  ( 1 ) "*"    "*"   "*"    "*"   "*" "*"       "*"    "*"        "*"       
          RegionSouth RegionWest
1  ( 1 )  " "         " "       
2  ( 1 )  " "         " "       
3  ( 1 )  " "         " "       
4  ( 1 )  " "         " "       
5  ( 1 )  " "         " "       
6  ( 1 )  " "         " "       
7  ( 1 )  " "         " "       
8  ( 1 )  " "         "*"       
9  ( 1 )  " "         "*"       
10  ( 1 ) "*"         "*"       
11  ( 1 ) "*"         "*"       </code></pre>
</div>
</div>
<p>The <code>Rating</code> variable is the strongest predictor in a single-regressor model but is replaced in the two-regressor model. It re-enters in <span class="math inline">\(M_3^*\)</span> is replaced in <span class="math inline">\(M_4^*\)</span> and re-enters in <span class="math inline">\(M_5^*\)</span>. Judged by BIC the best model among the 11 stage models is the <span class="math inline">\(M_4^*\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>s_seqrep<span class="sc">$</span>bic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  -535.9468  -801.5344 -1173.3585 -1198.0527  -805.7491  -800.3585
 [7] -1190.8790 -1185.5192 -1180.1989 -1174.9476 -1169.4433</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(s_seqrep<span class="sc">$</span>bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4</code></pre>
</div>
</div>
<table class="table">
<caption>Models selected by best subset, forward, backward, and sequential replacement selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1197.1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Backward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">Seq. Repl.</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">-1198.1</td>
</tr>
</tbody>
</table>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p>A stepwise procedure can be performed with <code>SequentialFeatureSelection</code> of <code>mlxtend</code> by setting the <code>floating</code> parameter to True.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>stepwise_sel <span class="op">=</span> feature_selection(credit_encoded.drop(<span class="st">'Balance'</span>,axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>                  credit_encoded[<span class="st">'Balance'</span>],</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>                  method<span class="op">=</span><span class="st">"stepwise"</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>plot_regsubsets(stepwise_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
<p>In this case the procedure selects the 5-input model based on BIC, as in forward selection.</p>
<table class="table">
<caption>Models selected by best subset, forward, and backward selection</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Algorithm</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Best Subset</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3705.5</td>
</tr>
<tr class="even">
<td style="text-align: center;">Forward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3706.4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Backward</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3705.5</td>
</tr>
<tr class="even">
<td style="text-align: center;">Stepwise</td>
<td style="text-align: center;">Income</td>
<td style="text-align: center;">Limit</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Cards</td>
<td style="text-align: center;">StudentYes</td>
<td style="text-align: center;">3706.4</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="feature-selection-with-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection-with-cross-validation">Feature Selection with Cross-validation</h3>
<p>So far we have based the selection of the best <span class="math inline">\(k\)</span>-size model on indirect measures of test error, AIC, BIC, <span class="math inline">\(C_p\)</span>, or on Adjusted <span class="math inline">\(R^2\)</span>. Cross-validation is another option to choose among the <span class="math inline">\(M_k^*\)</span> models.</p>
<div class="example">
<div class="example-header">
<p>Example: Credit Data from ISLR2 (Cont’d)</p>
</div>
<div class="example-container">
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>The <code>caret::train</code> function makes this easy. The following code performs backward selection with 10-fold cross-validation. Set the <code>method</code> parameter of the <code>train()</code> function to <code>leapBackward</code>, <code>leapForward</code>, or <code>leapSeq</code> to pick the corresponding selection method from <code>leaps</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>train.control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">"cv"</span>, <span class="at">number=</span><span class="dv">10</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>bkwd.model <span class="ot">&lt;-</span> <span class="fu">train</span>(Balance <span class="sc">~</span> . , <span class="at">data=</span>Credit,</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">method =</span> <span class="st">"leapBackward"</span>, </span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>                    <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">nvmax =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">11</span>),</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl =</span> train.control)</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>bkwd.model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression with Backwards Selection 

400 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 359, 360, 360, 360, 361, 360, ... 
Resampling results across tuning parameters:

  nvmax  RMSE       Rsquared   MAE      
   1     233.70389  0.7550260  179.03474
   2     164.82730  0.8741834  124.94667
   3     104.18429  0.9500264   83.87919
   4      99.58394  0.9541938   79.31590
   5      99.97431  0.9537228   79.76912
   6      98.68603  0.9549101   79.01670
   7      99.23361  0.9543259   79.35933
   8      99.36847  0.9542728   79.41112
   9      99.43304  0.9541716   79.36891
  10      99.38019  0.9542248   79.39167
  11      99.05830  0.9545716   79.31319

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 6.</code></pre>
</div>
</div>
<p>For the ISLR2 Credit data 10-fold cross-validation for backward selection chooses <span class="math inline">\(M_6^*\)</span> as the best model. The coefficients of this model are as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(bkwd.model<span class="sc">$</span>finalModel,bkwd.model<span class="sc">$</span>bestTune<span class="sc">$</span>nvmax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> (Intercept)       Income        Limit       Rating        Cards          Age 
-493.7341870   -7.7950824    0.1936914    1.0911874   18.2118976   -0.6240560 
  StudentYes 
 425.6099369 </code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>To perform cross-validation selection with <code>SequentialFeatureSelection</code>, set the <code>cv=</code> parameter of <code>SequentialFeatureSelector</code> to the number of desired folds (for k-fold CV).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>forward_cv <span class="op">=</span> feature_selection(credit_encoded.drop(<span class="st">'Balance'</span>,axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                  credit_encoded[<span class="st">'Balance'</span>],</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>                  method<span class="op">=</span><span class="st">"forward"</span>,</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>                  cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(forward_cv[<span class="st">'which'</span>])):</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> <span class="bu">list</span>(compress(forward_cv[<span class="st">'var_names'</span>],forward_cv[<span class="st">'which'</span>][i]))</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best model with </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> predictors: </span><span class="sc">{</span>ll<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best model with 1 predictors: ['Rating']
Best model with 2 predictors: ['Income', 'Rating']
Best model with 3 predictors: ['Income', 'Rating', 'StudentYes']
Best model with 4 predictors: ['Income', 'Limit', 'Rating', 'StudentYes']
Best model with 5 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'StudentYes']
Best model with 6 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'StudentYes']
Best model with 7 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'StudentYes', 'MarriedYes']
Best model with 8 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'OwnYes', 'StudentYes', 'MarriedYes']
Best model with 9 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'OwnYes', 'StudentYes', 'MarriedYes']
Best model with 10 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionWest']
Best model with 11 predictors: ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'OwnYes', 'StudentYes', 'MarriedYes', 'RegionSouth', 'RegionWest']</code></pre>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>plot_regsubsets(forward_cv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-regularization" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="sec-regularization"><span class="header-section-number">8.2</span> Regularization</h2>
<p>Feature selection attempts to select from <span class="math inline">\(p\)</span> candidate features a set that models the signal in the data well and eliminates unimportant variables. Having too many predictor variables, especially ones that do not contribute substantially to the model, increases the variability of the least squares coefficient and leads to overfitting. Regularization approaches the problem from a different perspective: can we work with all <span class="math inline">\(p\)</span> features and allay the negative effects on ordinary least squares estimation?</p>
<section id="shrinkage-estimation" class="level3">
<h3 class="anchored" data-anchor-id="shrinkage-estimation">Shrinkage Estimation</h3>
<p>The answer is “Yes” and it requires a slight modification to the estimation criterion. Instead of solving <span class="math display">\[
\mathop{\mathrm{arg\,min}}_{\boldsymbol{\beta}} \left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)
\]</span> we add a term that controls the variability of the coefficients:</p>
<p><span class="math display">\[
\mathop{\mathrm{arg\,min}}_{\boldsymbol{\beta}} \left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right) + \lambda f(\boldsymbol{\beta})
\]</span> <span class="math inline">\(\lambda\)</span> is a hyper-parameter that controls the extent of the penalty and <span class="math inline">\(f(\boldsymbol{\beta})\)</span> is a positive-valued function of the coefficients. If <span class="math inline">\(\lambda=0\)</span>, the penalty term vanishes and ordinary least squares estimates result. Since <span class="math inline">\(f(\boldsymbol{\beta})\)</span> is positive, a large value of <span class="math inline">\(\lambda\)</span> adds a heftier penalty to the residual sum of squares. This has the effect of reducing the size of the <span class="math inline">\(\widehat{\beta}_j\)</span> in absolute value; hence the name <strong>shrinkage estimation</strong>.</p>
<p>Why does shrinkage estimation work? Suppose we want to estimate <span class="math inline">\(\theta\)</span> and have an unbiased estimator <span class="math inline">\(h(\textbf{Y})\)</span>. The mean-squared error of this estimator is thus <span class="math inline">\(\text{MSE}[h(\textbf{Y});\theta] = \text{Var}[h(\textbf{Y})]\)</span>. A simplistic shrinkage estimator could be <span class="math inline">\(g(\textbf{Y}) = c \times h(\textbf{Y})\)</span> where <span class="math inline">\(0 \le c \le 1\)</span> is the shrinkage factor. When will <span class="math inline">\(g(\textbf{Y})\)</span> be superior to <span class="math inline">\(h(\textbf{Y})\)</span> in terms of mean-squared error? <span class="math display">\[
\frac{\text{MSE}[g(\textbf{Y});\theta]}{\text{MSE}[h(\textbf{Y});\theta]} = \frac{c^2\text{Var}[h(\textbf{Y})]+(c-1)^2\theta^2}{\text{Var}[h(\textbf{Y})]}=c^2+(c-1)^2\frac{\theta^2}{\text{Var}[h(\textbf{Y})]}
\]</span></p>
<p>The shrinkage estimator is preferred when this expression is less than 1. Since <span class="math inline">\(0 \le c \le 1\)</span>, <span class="math inline">\(c^2 \le 1\)</span>, <span class="math inline">\((c-1)^2 \le 1\)</span> and it boils down to whether the reduction in variance (<span class="math inline">\(c^2\text{Var}[h(\textbf{Y})]\)</span>) can overcome the increase in bias (<span class="math inline">\((c-1)^2\theta^2\)</span>). If <span class="math inline">\(h(\textbf{Y})\)</span> is highly variable relative to its mean, more shrinkage can be applied.</p>
<p>Let’s return to the regularization setup. To make the procedure operational we need to choose <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(f(\boldsymbol{\beta})\)</span>.</p>
<p>Three penalty functions are common in statistical modeling and machine learning:</p>
<p><span id="eq-ridge-penalty"><span class="math display">\[
f(\boldsymbol{\beta}) = \sum_{j=1}^p \beta_j^2 = ||\,[\beta_1, \cdots, \beta_p]\, ||_2^2
\tag{8.2}\]</span></span></p>
<p><span id="eq-lasso-penalty"><span class="math display">\[
f(\boldsymbol{\beta}) = \sum_{j=1}^p |\beta_j|= ||\,[\beta_1,\cdots,\beta_p]\, ||_1
\tag{8.3}\]</span></span></p>
<p><span id="eq-elastinet-penalty"><span class="math display">\[
f(\boldsymbol{\beta},\alpha)  = \frac{1-\alpha}{2}\sum_{j=1}^p\beta_j^2 + \alpha\sum_{j=1}^p|\beta_j|
\tag{8.4}\]</span></span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The intercept <span class="math inline">\(\beta_0\)</span> is not included in the penalty term. It models the mean of <span class="math inline">\(Y\)</span> when all inputs are zero and does not need to be penalized.</p>
</div>
</div>
<p>The penalty function in <a href="#eq-ridge-penalty" class="quarto-xref">Equation&nbsp;<span>8.2</span></a> is known as a <span class="math inline">\(L_2\)</span> penalty (or <span class="math inline">\(L_2\)</span> regularization), since it is based on the (squared) <span class="math inline">\(L_2\)</span>-norm of the <span class="math inline">\([\beta_1, \cdots, \beta_p]\)</span>. The <span class="math inline">\(L_2\)</span>-norm of vector <span class="math inline">\(\textbf{z}\)</span> is <span class="math display">\[
||\textbf{z}||_2 = \sqrt{\sum_{j=1}^p z_j^2}
\]</span> The <span class="math inline">\(L_1\)</span>-norm of a vector, on the other hand, is <span class="math display">\[
||\textbf{z}||_1 = \sum_{j=1}^p |z_j|
\]</span></p>
<p>and this is the basis of the penalty function <a href="#eq-lasso-penalty" class="quarto-xref">Equation&nbsp;<span>8.3</span></a>. The function <a href="#eq-elastinet-penalty" class="quarto-xref">Equation&nbsp;<span>8.4</span></a> is a combination of <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> regularization: <span class="math inline">\(\alpha=0\)</span> results in the <span class="math inline">\(L_2\)</span> penalty, <span class="math inline">\(\alpha=1\)</span> results in the <span class="math inline">\(L_1\)</span> penalty and values <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span> mix the two.</p>
<p>Regularization using <a href="#eq-ridge-penalty" class="quarto-xref">Equation&nbsp;<span>8.2</span></a> is known as <strong>ridge</strong> regression. The <span class="math inline">\(L_1\)</span>-norm regularization in <a href="#eq-lasso-penalty" class="quarto-xref">Equation&nbsp;<span>8.3</span></a> leads to <strong>lasso</strong> regression (also Lasso or LASSO) and the mixture is known as an <strong>elastic net</strong> regression.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is a single regularization parameter <span class="math inline">\(\lambda\)</span> that applies to all coefficients. Because the size of <span class="math inline">\(\beta_j\)</span> depends on the scale of <span class="math inline">\(x_j\)</span>, it is highly recommended to standardize the columns of <span class="math inline">\(\textbf{X}\)</span> before applying any regularization. Software will often take care of standardization as part of model fitting. Check the documentation on whether that is the case and whether the results are reported for the standardized or for the original coefficients.</p>
</div>
</div>
<p>The value of <span class="math inline">\(\lambda\)</span> determines the extent of the shrinkage. For each value of <span class="math inline">\(\lambda\)</span> there is a set of coefficient estimates <span class="math inline">\(\widehat{\boldsymbol{\beta}}_\lambda\)</span> that minimize the objective function <span class="math display">\[
\left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right)^\prime\left(\textbf{Y}- \textbf{X}\boldsymbol{\beta}\right) + \lambda f(\boldsymbol{\beta})
\]</span></p>
<p>The value of <span class="math inline">\(\lambda\)</span> thus needs to be set a priori, chosen by cross-validation or some other method.</p>
</section>
<section id="sec-regularization-ridge" class="level3">
<h3 class="anchored" data-anchor-id="sec-regularization-ridge">Ridge Regression</h3>
<p>Ridge regression applies the <span class="math inline">\(L_2\)</span> regularization penalty <span class="math display">\[
\lambda \sum_{j=1}^p \beta_j^2
\]</span> and shrinks the coefficient estimates toward 0 unless <span class="math inline">\(\lambda=0\)</span>. A feature of ridge regression is that it shrinks <em>toward</em> zero in absolute value but the coefficients are not exactly zero. To make predictions in a ridge regression model requires information on all <span class="math inline">\(p\)</span> attributes; they all make non-zero contributions toward predicted values.</p>
<div class="example">
<div class="example-header">
<p>Example: Hitters Data (ISLR2) (Cont’d)</p>
</div>
<div class="example-container">
<p>To demonstrate regularization we use another data set from <span class="citation" data-cites="James2013_ISLR2">James et al. (<a href="references.html#ref-James2013_ISLR2" role="doc-biblioref">2021</a>)</span>. The <code>Hitters</code> data contains salaries and 19 other attributes about major league baseball players from the 1986 and 1987 seasons.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<p>Regression models with regularization can be fit with the <code>glmnet</code> function in the <code>glmnet</code> package. This function implements the elastic net regularization–by choosing the <code>alpha=</code> parameter you can choose between ridge, lasso, or elastic net regularization. <code>glmnet</code> does not support the formula syntax, instead you supply the <span class="math inline">\(\textbf{y}\)</span> vector and the <span class="math inline">\(\textbf{X}\)</span> matrix. The <code>model.matrix()</code> function in <code>R</code> extracts the model matrix based on the formula syntax.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>Hit <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(Hitters)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Salary <span class="sc">~</span> ., <span class="at">data=</span>Hit)[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Hit<span class="sc">$</span>Salary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To demonstrate the effects of shrinkage we examine the ridge regression estimates for several values of <span class="math inline">\(\lambda\)</span>. By default, <code>glmnet</code> standardizes the <span class="math inline">\(\textbf{X}\)</span> matrix and reports the results on the original (non-standardized) scale. We explicitly standardize <span class="math inline">\(\textbf{X}\)</span> here to compare the effects of shrinkage based on standardized ridge regression coefficients.</p>
<p>The following code computes the ridge regression estimates for <span class="math inline">\(\lambda=[100, 10, 0.1, 0]\)</span>. Setting <code>alpha=0</code> results in the <span class="math inline">\(L_2\)</span> regularization (ridge regression). Since we are passing a standardized <span class="math inline">\(\textbf{X}\)</span> matrix, we add <code>standardize=FALSE</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>xstd <span class="ot">&lt;-</span> <span class="fu">scale</span>(x)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>xstd[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                        AtBat       Hits      HmRun       Runs         RBI
-Alan Ashby       -0.60175321 -0.5945419 -0.5275454 -1.2038163 -0.52106946
-Alvin Davis       0.51156637  0.4913228  0.7285771  0.4406748  0.79254856
-Andre Dawson      0.62697145  0.7350884  0.9569630  0.4015202  1.02436351
-Andres Galarraga -0.56102200 -0.4615789 -0.1849665 -0.6164981 -0.36652617
-Alfredo Griffin   1.29224779  1.3555825 -0.8701243  0.7539112 -0.01880375
-Al Newman        -1.48426263 -1.5696041 -1.2127031 -1.2429709 -1.68014419
-Argenis Salazar  -0.71715829 -0.7718259 -1.3268961 -1.2038163 -1.06197100
-Andres Thomas    -0.54744494 -0.5945419 -0.6417383 -1.1255072 -0.75288441
-Andre Thornton   -0.01793928 -0.3507764  0.6143841 -0.2249526  0.56073362
-Alan Trammell     1.15647711  1.1339775  1.0711560  2.0460114  0.90845603
                        Walks      Years     CAtBat      CHits       CHmRun
-Alan Ashby       -0.09734151  1.3952334  0.3461306  0.1740416 -0.002914243
-Alvin Davis       1.60631004 -0.8994853 -0.4520036 -0.4091121 -0.075909091
-Andre Dawson     -0.18943079  0.7694010  1.2990809  1.3156652  1.894951816
-Andres Galarraga -0.51174324 -1.1080961 -0.9890495 -0.9583256 -0.696365303
-Alfredo Griffin  -0.28152006  0.7694010  0.7655337  0.6337765 -0.611204646
-Al Newman        -0.92614497 -1.1080961 -1.0686443 -1.0493469 -0.830189192
-Argenis Salazar  -1.57076988 -0.8994853 -0.9396308 -0.9475265 -0.842355000
-Andres Thomas    -1.52472525 -1.1080961 -1.0131029 -0.9814666 -0.769360151
-Andre Thornton    1.09981904  1.1866226  1.1145261  0.9407807  2.235594442
-Alan Trammell     0.82355122  0.5607902  0.8630591  0.8914132  0.252567726
                       CRuns        CRBI      CWalks    LeagueN  DivisionW
-Alan Ashby       -0.1214393  0.25847281  0.43450593  1.0567429  0.9792988
-Alvin Davis      -0.4143150 -0.19921055  0.01035326 -0.9427059  0.9792988
-Andre Dawson      1.4093644  1.56967378  0.35497730  1.0567429 -1.0172561
-Andres Galarraga -0.9457182 -0.87955068 -0.86067453  1.0567429 -1.0172561
-Alfredo Griffin   0.4220413  0.01726131 -0.25095507 -0.9427059  0.9792988
-Al Newman        -1.0000663 -0.99397151 -0.89475822  1.0567429 -1.0172561
-Argenis Salazar  -0.9668536 -0.90738277 -0.94020315 -0.9427059  0.9792988
-Andres Thomas    -0.9940276 -0.91666014 -0.95535146  1.0567429  0.9792988
-Andre Thornton    1.2765136  1.73048144  2.29396091 -0.9427059 -1.0172561
-Alan Trammell     1.0289280  0.53679377  0.86244567 -0.9427059 -1.0172561
                      PutOuts     Assists      Errors NewLeagueN
-Alan Ashby        1.21917406 -0.52219572  0.21294608  1.0730066
-Alvin Davis       2.10509535 -0.25337958  0.81840359 -0.9284171
-Andre Dawson     -0.32404367 -0.74276281 -0.84660456  1.0730066
-Andres Galarraga  1.83717561 -0.54287389 -0.69524018  1.0730066
-Alfredo Griffin  -0.03111808  2.08325298  2.48341175 -0.9284171
-Al Newman        -0.76700431  0.05679288 -0.24114705 -0.9284171
-Argenis Salazar  -0.60625247  1.13205742  0.06158171 -0.9284171
-Andres Thomas    -0.52766267  1.18030647  1.57522548  1.0730066
-Andre Thornton   -1.03849632 -0.81858274 -1.30069770 -0.9284171
-Alan Trammell    -0.18829766  2.24867830  2.02931862 -0.9284171</code></pre>
</div>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">10</span>, <span class="fl">0.1</span>, <span class="dv">0</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(xstd,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>                    y,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">alpha      =</span><span class="dv">0</span>,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">lambda     =</span>grid,</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">standardize=</span><span class="cn">FALSE</span>)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">coef</span>(ridge_reg)</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(c,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>20 x 4 sparse Matrix of class "dgCMatrix"
                   s0         s1         s2         s3
(Intercept) 535.92588  535.92588  535.92588  535.92588
AtBat       -16.83082 -177.44455 -286.63925 -286.92810
Hits         62.45187  193.42259  329.51110  329.93996
HmRun        -6.23675   -4.39810   34.88397   34.89111
Runs         29.79696   11.52654  -55.22778  -55.44889
RBI          21.97064   10.40385  -24.45369  -24.43937
Walks        47.54494   95.56907  133.47732  133.62728
Years       -13.69724  -51.64044  -16.16510  -16.16546
CAtBat       22.11360  -53.03444 -411.07544 -411.04487
CHits        53.70545  107.85792  139.86360  139.79069
CHmRun       44.61612   57.29178    0.51190    0.42362
CRuns        54.37626  157.62866  451.98210  452.33319
CRBI         56.03491  107.13165  237.22613  237.23363
CWalks      -11.25886 -121.63931 -207.16539 -207.48727
LeagueN      18.36541   29.51287   31.71804   31.73602
DivisionW   -54.39637  -62.18622  -58.63766  -58.64605
PutOuts      63.65551   76.76765   78.79568   78.79588
Assists      11.14021   34.39178   54.09800   54.09470
Errors      -17.34834  -25.43415  -22.67837  -22.70459
NewLeagueN    0.01310  -12.69060  -12.91619  -12.94903</code></pre>
</div>
</div>
<p>There are 19 predictors in addition to the intercept. The coefficient columns labeled <code>s0</code>, <code>s1</code>, <code>s2</code>, and <code>s3</code> correspond to the four values of <span class="math inline">\(\lambda = [100, 10, 0.1, 0]\)</span>. Note that the intercept is the same because the variables have been standardized and <span class="math inline">\(\beta_0\)</span> is not shrunk. For each of the predictors, the values are smaller (in absolute value) for the larger values of <span class="math inline">\(\lambda\)</span>. For example, the coefficient estimate of <code>AtBat</code> increases from -16.8308 at <span class="math inline">\(\lambda=100\)</span> to -177.4445 at <span class="math inline">\(\lambda=10\)</span> and to -286.6393 at <span class="math inline">\(\lambda=0.1\)</span>.</p>
<p><a href="#fig-ridge-standardized" class="quarto-xref">Figure&nbsp;<span>8.4</span></a> shows the standardized ridge regression coefficients for the four values of <span class="math inline">\(\lambda\)</span>. The larger variation of the coefficients for smaller values of <span class="math inline">\(\lambda\)</span> is evident.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ridge-standardized" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-standardized-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-ridge-standardized-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-standardized-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: Standardized Ridge Regression Coefficients
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>con <span class="op">=</span> duckdb.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"ads.ddb"</span>, read_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>hitters <span class="op">=</span> con.sql(<span class="st">"SELECT * FROM Hitters;"</span>).df().dropna()</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>con.close()</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>hitters_X <span class="op">=</span> pd.get_dummies(hitters, prefix_sep<span class="op">=</span><span class="st">''</span>, dtype<span class="op">=</span><span class="st">'float64'</span>)</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>hitters_Y <span class="op">=</span> hitters[<span class="st">'Salary'</span>]</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>hitters_X <span class="op">=</span> hitters_X.drop([<span class="st">'Salary'</span>, <span class="st">'LeagueA'</span>,<span class="st">'DivisionE'</span>,<span class="st">'NewLeagueA'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can fit ridge regression in Python with <code>Ridge</code> in <code>scikit-learn</code> and with <code>OLS.fit_regularized</code> in <code>statsmodels</code>. While <code>Ridge</code> performs ridge regression, <code>OLS.fit_regularized</code> implements the elastic net, a weighted combination of <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> penalty terms. In contrast to the previous notation, <code>OLS.fit_regularized</code> uses <code>alpha</code> to specify the penalty parameter and <code>L1_wt</code> to specify the fraction of the penalty assigned to the <span class="math inline">\(L_1\)</span> term.</p>
<p>The following code uses <code>Ridge</code> in <code>scikit-learn</code> and loops over the penalty parameter <code>alpha</code> as the function supports only a single value for each target variable. To prepare the data, the <code>scale</code> function is used to center and scale the <span class="math inline">\(\textbf{X}\)</span> matrix to zero mean and standard deviation one. In contrast to <code>scale()</code> in <code>R</code>, the <code>scale</code> function in <code>scikit-learn</code> uses <span class="math inline">\(\frac{1}{n}\)</span> in the computation of the standard deviation. We adjust the centered-and-scaled <span class="math inline">\(\textbf{X}\)</span> matrix here to match the results in <code>R</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale the input features</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> scale(hitters_X)</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> hitters_X.shape[<span class="dv">0</span>]</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust so that scaling uses the regular estimate of the standard deviation</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> xstd<span class="op">*</span>np.sqrt((n<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>n)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and fit ridge regression models for each value</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="co"># of the penalty parameter</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> [<span class="dv">50</span>, <span class="dv">5</span>, <span class="fl">0.05</span>, <span class="dv">0</span>]</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> []</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lambda_val <span class="kw">in</span> grid:</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    ridge_reg <span class="op">=</span> Ridge(alpha<span class="op">=</span>lambda_val, fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    ridge_reg.fit(xstd, hitters_Y)</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    coef <span class="op">=</span> np.insert(ridge_reg.coef_, <span class="dv">0</span>, ridge_reg.intercept_)</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>    coefficients.append(coef)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Ridge(alpha=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked=""><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Ridge<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html">?<span>Documentation for Ridge</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Ridge(alpha=0)</pre></div> </div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> np.<span class="bu">round</span>(np.column_stack(coefficients), <span class="dv">5</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(suppress<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 535.92588  535.92588  535.92588  535.92588]
 [ -23.26366 -189.97056 -290.78813 -291.64955]
 [  67.26925  204.97371  335.58575  338.47458]
 [  -7.52758   -2.98478   36.19846   37.92601]
 [  29.93122    8.37915  -58.02467  -60.68796]
 [  21.81253    9.08642  -25.45712  -27.04645]
 [  49.66219   99.30981  134.62364  135.33143]
 [ -16.89569  -52.50699  -18.49608  -16.72519]
 [  20.82683  -63.58969 -380.31278 -391.7842 ]
 [  56.36454  114.38858   95.26535   86.85289]
 [  45.82945   59.49999   -8.15202  -14.20876]
 [  57.40136  168.60935  466.63295  481.66372]
 [  59.19831  106.75119  250.27169  261.18691]
 [ -16.32932 -129.80901 -211.85833 -214.30006]
 [  65.31363   77.12275   78.91332   78.91146]
 [  12.40999   35.94587   53.45118   53.83493]
 [ -18.41519  -25.42489  -22.35317  -22.20311]
 [  19.40338   29.82435   31.33042   31.30834]
 [ -55.71797  -62.13789  -58.67069  -58.52543]
 [  -0.96799  -13.09184  -12.54061  -12.37236]]</code></pre>
</div>
</div>
<p>There are 19 predictors in addition to the intercept. The coefficient columns correspond to the four values of <span class="math inline">\(\lambda = [100, 10, 0.1, 0]\)</span>. Note that the intercept is the same because the variables have been standardized and <span class="math inline">\(\beta_0\)</span> is not shrunk. For each of the predictors, the values are smaller (in absolute value) for the larger values of <span class="math inline">\(\lambda\)</span>. For example, the coefficient estimate for the first input variable (<code>AtBat</code>) increases from -23.263 at <span class="math inline">\(\lambda=50\)</span> to -189.97 at <span class="math inline">\(\lambda=10\)</span> and to -290.788 at <span class="math inline">\(\lambda=0.05\)</span>. The values in the last column (<code>alpha=0</code>) are identical to the ordinary least squares results, as can be verified here:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>X_mat <span class="op">=</span> sm.add_constant(xstd)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>smfit <span class="op">=</span> sm.OLS(hitters_Y,xstd).fit()</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(smfit.params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x1    -291.649551
x2     338.474580
x3      37.926008
x4     -60.687965
x5     -27.046452
x6     135.331426
x7     -16.725186
x8    -391.784201
x9      86.852893
x10    -14.208762
x11    481.663717
x12    261.186912
x13   -214.300061
x14     78.911461
x15     53.834935
x16    -22.203114
x17     31.308341
x18    -58.525435
x19    -12.372355
dtype: float64</code></pre>
</div>
</div>
<p><a href="#fig-ridge-standardized-py" class="quarto-xref">Figure&nbsp;<span>8.5</span></a> shows the standardized ridge regression coefficients for the four values of <span class="math inline">\(\lambda\)</span>. The larger variation of the coefficients for smaller values of <span class="math inline">\(\lambda\)</span> is evident.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ridge-standardized-py" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-standardized-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-ridge-standardized-py-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-standardized-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.5: Standardized ridge regression coefficients.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<section id="cross-validation-for-lambda" class="level4">
<h4 class="anchored" data-anchor-id="cross-validation-for-lambda">Cross-validation for <span class="math inline">\(\lambda\)</span></h4>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p><code>cv.glmnet()</code> performs <span class="math inline">\(k\)</span>-fold cross-validation for <code>glmnet()</code> models. By default, <span class="math inline">\(k=10\)</span> and the function goes through its own sequence of <span class="math inline">\(\lambda\)</span> values. You can provide a grid with the <code>lambda</code> parameter. The evaluation metric can be set with the <code>type.measure=</code> option, for example, <code>"mse"</code> for mean-squared error or <code>"auc"</code> for the area under the ROC curve.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6543</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>cv.out <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x,y,<span class="at">alpha=</span><span class="dv">0</span>, <span class="at">nfolds=</span><span class="dv">10</span>, <span class="at">type.measure=</span><span class="st">"mse"</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/ridge_cv-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The numbers across the top of the plot indicate the number of predictors in the model. Ridge regression does not shrink coefficients to exactly zero, all 19 variables have non-zero coefficients for all values of <span class="math inline">\(\lambda\)</span>.</p>
<p>The left vertical line is drawn at the <span class="math inline">\(\lambda\)</span> value that produces the minimum cross-validation error. The dashed vertical line on the right is the value of <span class="math inline">\(\lambda\)</span> (or log(<span class="math inline">\(\lambda\)</span>) to be more exact) such that the error is within 1 standard error of the minimum.</p>
<p>You can access key results from the cross-validation from the return object of <code>cv.glmnet</code>. The following statements show how to locate the best value for lambda and the index of that value in the cross-validation sequence. That index is then used to access the coefficients of the winning model and the minimum cross-validation measure.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>bestlam <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>lambda.min</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>bestlam</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 25.52821</code></pre>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(bestlam)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.239784</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>bestIndex <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>index[<span class="dv">1</span>]</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>selcoef <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>glmnet.fit<span class="sc">$</span>beta[,bestIndex]</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(selcoef,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     AtBat       Hits      HmRun       Runs        RBI      Walks      Years 
   -0.6816     2.7723    -1.3657     1.0148     0.7130     3.3786    -9.0668 
    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks    LeagueN 
   -0.0012     0.1361     0.6980     0.2959     0.2571    -0.2790    53.2127 
 DivisionW    PutOuts    Assists     Errors NewLeagueN 
 -122.8345     0.2639     0.1699    -3.6856   -18.1051 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"10-fold CV error for Ridge regression, "</span>, cv.out<span class="sc">$</span>cvm[bestIndex])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>10-fold CV error for Ridge regression,  115445.5</code></pre>
</div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<p><code>RidgeCV</code> in <code>scikit-learn</code> performs cross-validation for ridge regression. You can pass to the <code>cv=</code> parameter either an integer value for <span class="math inline">\(k\)</span>-fold cross-validation, an object returned from <code>KFold</code>, or <code>None</code> for leave-one-out cross-validation. The code below determines the best penalty parameter (<code>alpha</code> in the terminology of <code>RidgeCV</code>) based on 10-fold CV.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> RidgeCV</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6543</span>)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the alphas to test</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">100</span>)  <span class="co"># Create a range of values</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform cross-validation for Ridge regression</span></span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>    alphas<span class="op">=</span>alphas,</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>    fit_intercept<span class="op">=</span><span class="va">True</span></span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(xstd, hitters_Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RidgeCV(alphas=array([  0.001     ,   0.00112332,   0.00126186,   0.00141747,
         0.00159228,   0.00178865,   0.00200923,   0.00225702,
         0.00253536,   0.00284804,   0.00319927,   0.00359381,
         0.00403702,   0.00453488,   0.00509414,   0.00572237,
         0.00642807,   0.00722081,   0.00811131,   0.00911163,
         0.01023531,   0.01149757,   0.0129155 ,   0.01450829,
         0.01629751,   0.01830738,   0.02056512,   0.0231013 ,
         0.02595024,   0.02915053,   0.032...
         4.32876128,   4.86260158,   5.46227722,   6.13590727,
         6.8926121 ,   7.74263683,   8.69749003,   9.77009957,
        10.97498765,  12.32846739,  13.84886371,  15.55676144,
        17.475284  ,  19.6304065 ,  22.0513074 ,  24.77076356,
        27.82559402,  31.2571585 ,  35.11191734,  39.44206059,
        44.30621458,  49.77023564,  55.90810183,  62.80291442,
        70.54802311,  79.24828984,  89.02150854, 100.        ]),
        cv=10, scoring='neg_mean_squared_error')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked=""><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RidgeCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html">?<span>Documentation for RidgeCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RidgeCV(alphas=array([  0.001     ,   0.00112332,   0.00126186,   0.00141747,
         0.00159228,   0.00178865,   0.00200923,   0.00225702,
         0.00253536,   0.00284804,   0.00319927,   0.00359381,
         0.00403702,   0.00453488,   0.00509414,   0.00572237,
         0.00642807,   0.00722081,   0.00811131,   0.00911163,
         0.01023531,   0.01149757,   0.0129155 ,   0.01450829,
         0.01629751,   0.01830738,   0.02056512,   0.0231013 ,
         0.02595024,   0.02915053,   0.032...
         4.32876128,   4.86260158,   5.46227722,   6.13590727,
         6.8926121 ,   7.74263683,   8.69749003,   9.77009957,
        10.97498765,  12.32846739,  13.84886371,  15.55676144,
        17.475284  ,  19.6304065 ,  22.0513074 ,  24.77076356,
        27.82559402,  31.2571585 ,  35.11191734,  39.44206059,
        44.30621458,  49.77023564,  55.90810183,  62.80291442,
        70.54802311,  79.24828984,  89.02150854, 100.        ]),
        cv=10, scoring='neg_mean_squared_error')</pre></div> </div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best alpha: </span><span class="sc">{</span>ridge_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best alpha: 3.0539</code></pre>
</div>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best MSE: </span><span class="sc">{</span><span class="op">-</span>ridge_cv<span class="sc">.</span>best_score_<span class="sc">:.5f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best MSE: 114203.33998</code></pre>
</div>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ridge_cv.alpha_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.0538555088334154</code></pre>
</div>
</div>
<p><a href="#fig-ridge-cv-py" class="quarto-xref">Figure&nbsp;<span>8.6</span></a> shows the results of cross-validating the penalty parameter with 10-fold CV on a grid of values from 0.001 to 100.</p>
<div class="cell">
<div class="cell-output-display">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RidgeCV(alphas=[100.0], cv=10, scoring='neg_mean_squared_error')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked=""><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RidgeCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html">?<span>Documentation for RidgeCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RidgeCV(alphas=[100.0], cv=10, scoring='neg_mean_squared_error')</pre></div> </div></div></div></div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ridge-cv-py" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-cv-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-ridge-cv-py-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-cv-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.6: Cross-validation results from Ridge regression.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="ridge-trace" class="level4">
<h4 class="anchored" data-anchor-id="ridge-trace">Ridge trace</h4>
<p>Another method of selecting <span class="math inline">\(\lambda\)</span> is based on the <strong>ridge trace</strong>, a plot of the standardized ridge regression coefficient estimates as a function of <span class="math inline">\(\lambda\)</span>. The point where the coefficients stop changing drastically as <span class="math inline">\(\lambda\)</span> increases is chosen. For the Credit data, the ridge trace stabilizes around <span class="math inline">\(\lambda\)</span>=20–25 (<a href="#fig-ridge-trace" class="quarto-xref">Figure&nbsp;<span>8.7</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ridge-trace" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-trace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="regfeature_files/figure-html/fig-ridge-trace-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2"><img src="regfeature_files/figure-html/fig-ridge-trace-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-trace-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.7: Ridge trace for credit data.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="high-dimensional-ridge-regression" class="level4">
<h4 class="anchored" data-anchor-id="high-dimensional-ridge-regression">High-dimensional ridge regression</h4>
<p>An important use case for regularized regression is in high-dimensional problems where <span class="math inline">\(p\)</span> is very large. If <span class="math inline">\(p &gt; n\)</span>, the ordinary least squares solution does not exist because <span class="math inline">\(\textbf{X}^\prime\textbf{X}\)</span> is not of full rank (it is a <span class="math inline">\((p \times p)\)</span> matrix of rank <span class="math inline">\(n &lt; p\)</span> in that case). Similarly, the cross-product matrix <span class="math inline">\(\textbf{X}^{*\prime} \textbf{X}^*\)</span> formed from the standardized <span class="math inline">\(\textbf{X}\)</span> matrix is not of full rank. However, the <strong>ridged matrix</strong> <span class="math display">\[
\textbf{X}^{*\prime}\textbf{X}^* + \lambda\textbf{I}
\]</span> is of full rank. The ridge regression estimator <span class="math display">\[
\widehat{\boldsymbol{\beta}}_R = \left( \textbf{X}^{*\prime}\textbf{X}^* + \lambda\textbf{I}\right)^{-1} \textbf{X}^{*\prime}\textbf{Y}
\]</span> can be computed.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<p>The following <code>R</code> statements simulate a data set with <span class="math inline">\(n=5\)</span>, <span class="math inline">\(p=10\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>vec <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">50</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(vec, <span class="at">nrow=</span><span class="dv">5</span>, <span class="at">ncol=</span><span class="dv">10</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">dim</span>(x)[<span class="dv">1</span>]) <span class="sc">+</span> <span class="fu">rowSums</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These matrix manipulations verify that <span class="math inline">\(\textbf{X}^{*\prime}\textbf{X}^*\)</span> is singular but the ridged cross-product matrix can be inverted.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>xstd <span class="ot">&lt;-</span> <span class="fu">scale</span>(x)</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>XpX <span class="ot">&lt;-</span> <span class="fu">t</span>(xstd) <span class="sc">%*%</span> xstd</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(XpX)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in solve.default(XpX): system is computationally singular: reciprocal condition number = 3.41198e-18</code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(XpX <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span><span class="fu">diag</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               [,1]         [,2]         [,3]         [,4]         [,5]
 [1,]  0.0821411908  0.003628743  0.004526331  0.017361000  0.009667878
 [2,]  0.0036287426  0.080470255 -0.005436822 -0.006134563  0.005396869
 [3,]  0.0045263311 -0.005436822  0.083568814 -0.001248939  0.003501061
 [4,]  0.0173610002 -0.006134563 -0.001248939  0.080073460 -0.013669623
 [5,]  0.0096678784  0.005396869  0.003501061 -0.013669623  0.080268426
 [6,]  0.0098875667  0.002636003 -0.003964861 -0.003660393  0.005067454
 [7,]  0.0089612445 -0.007389909 -0.011840167 -0.005062966  0.005296744
 [8,] -0.0008862907 -0.018453251 -0.007896700 -0.001721646  0.006448275
 [9,]  0.0041343402  0.003959455 -0.016026019 -0.000876888 -0.003877599
[10,] -0.0032869355  0.005193974  0.009113818 -0.002328403 -0.012638898
              [,6]         [,7]          [,8]          [,9]        [,10]
 [1,]  0.009887567  0.008961245 -0.0008862907  0.0041343402 -0.003286935
 [2,]  0.002636003 -0.007389909 -0.0184532509  0.0039594553  0.005193974
 [3,] -0.003964861 -0.011840167 -0.0078967001 -0.0160260191  0.009113818
 [4,] -0.003660393 -0.005062966 -0.0017216462 -0.0008768880 -0.002328403
 [5,]  0.005067454  0.005296744  0.0064482749 -0.0038775986 -0.012638898
 [6,]  0.080214593 -0.011206391  0.0070933814 -0.0014132303  0.013646288
 [7,] -0.011206391  0.086123672 -0.0059057078 -0.0075954321  0.012779318
 [8,]  0.007093381 -0.005905708  0.0799896388 -0.0002186338  0.003733199
 [9,] -0.001413230 -0.007595432 -0.0002186338  0.0775284851  0.003203787
[10,]  0.013646288  0.012779318  0.0037331994  0.0032037868  0.083988113</code></pre>
</div>
</div>
<p>A linear regression of <span class="math inline">\(\textbf{Y}\)</span> on <span class="math inline">\(\textbf{X}\)</span> produces a saturated model (a perfect fit). Only four of the predictors are used in the model, since least squares runs out of degrees of freedom.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>linreg <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linreg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
ALL 5 residuals are 0: no residual degrees of freedom!

Coefficients: (6 not defined because of singularities)
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)   -1.409        NaN     NaN      NaN
x1             3.677        NaN     NaN      NaN
x2            -1.336        NaN     NaN      NaN
x3             5.556        NaN     NaN      NaN
x4             2.660        NaN     NaN      NaN
x5                NA         NA      NA       NA
x6                NA         NA      NA       NA
x7                NA         NA      NA       NA
x8                NA         NA      NA       NA
x9                NA         NA      NA       NA
x10               NA         NA      NA       NA

Residual standard error: NaN on 0 degrees of freedom
Multiple R-squared:      1, Adjusted R-squared:    NaN 
F-statistic:   NaN on 4 and 0 DF,  p-value: NA</code></pre>
</div>
</div>
<p>The ridge regression estimates can be computed, however:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x,y,<span class="at">alpha=</span><span class="dv">0</span>,<span class="at">lambda=</span><span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">10</span>,<span class="fl">0.1</span>,<span class="fl">0.01</span>))</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">coef</span>(ridge_reg)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(c,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 4 sparse Matrix of class "dgCMatrix"
                  s0       s1       s2       s3
(Intercept)  4.06577  3.66008  1.40561  1.17276
V1          -0.00702 -0.03370  0.28411  0.35818
V2           0.00999  0.05776 -0.17253 -0.18980
V3           0.03661  0.28534  1.58285  1.75290
V4          -0.00096 -0.02597 -0.53019 -0.59407
V5          -0.02444 -0.16639 -0.06003  0.10446
V6           0.00657  0.03162 -0.35915 -0.40210
V7           0.05149  0.36197  0.96726  1.01550
V8           0.01292  0.09384  0.35413  0.34608
V9           0.06133  0.50795  3.62746  3.79823
V10         -0.02833 -0.19215 -0.26185 -0.21501</code></pre>
</div>
</div>
<p>Notice that all 10 predictors make non-zero contributions.</p>
<p>The ridge regression does not produce a perfect fit, although the predicted values are close to y if <span class="math inline">\(\lambda\)</span> is small.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>y <span class="sc">-</span> <span class="fu">predict</span>(ridge_reg,<span class="at">newx=</span>x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              s0         s1          s2           s3
[1,]  0.08844951 -0.0283334 -0.02216955 -0.002276488
[2,]  0.54213531  0.5889800  0.07612739  0.008183588
[3,] -1.29871702 -1.1272270 -0.09536399 -0.010107069
[4,]  1.44471028  1.1194956  0.05774551  0.005868841
[5,] -0.77657808 -0.5529153 -0.01633935 -0.001668871</code></pre>
</div>
</div>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<p>The following statements simulate a data set with <span class="math inline">\(n=5\)</span>, <span class="math inline">\(p=10\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1234</span>)</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> np.random.uniform(size<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> vec.reshape(<span class="dv">5</span>, <span class="dv">10</span>)</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.random.normal(size<span class="op">=</span>x.shape[<span class="dv">0</span>]) <span class="op">+</span> np.<span class="bu">sum</span>(x, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following matrix manipulations verify that <span class="math inline">\(\textbf{X}^{*\prime}\textbf{X}^*\)</span>, the scaled-and-centered cross-product matrix is rank-deficient but the ridged cross-product matrix can be inverted by computing the rank of the respective matrices.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> scale(x)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>XpX <span class="op">=</span> np.dot(xstd.T, xstd)</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rank of the cross-product matrix: </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>matrix_rank(XpX)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Rank of the cross-product matrix: 4</span></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rank of the ridged cross-product matrix: </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>matrix_rank(XpX <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> np.eye(x.shape[<span class="dv">1</span>]))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a><span class="co">## Rank of the ridged cross-product matrix: 10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A linear regression of <span class="math inline">\(\textbf{Y}\)</span> on <span class="math inline">\(\textbf{X}\)</span> produces a saturated model (a perfect fit) as seen from the <span class="math inline">\(R^2=1\)</span> in the following output. Only four degrees of freedom are associated with the model, identical to the rank of the cross-product matrix.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>x_with_int <span class="op">=</span> sm.add_constant(x)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y,x_with_int).fit()</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<table class="simpletable table table-sm table-striped small" data-quarto-postprocess="true">
<caption>OLS Regression Results</caption>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Dep. Variable:</td>
<td>y</td>
<td data-quarto-table-cell-role="th">R-squared:</td>
<td>1.000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Model:</td>
<td>OLS</td>
<td data-quarto-table-cell-role="th">Adj. R-squared:</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Method:</td>
<td>Least Squares</td>
<td data-quarto-table-cell-role="th">F-statistic:</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Date:</td>
<td>Fri, 06 Jun 2025</td>
<td data-quarto-table-cell-role="th">Prob (F-statistic):</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Time:</td>
<td>08:21:45</td>
<td data-quarto-table-cell-role="th">Log-Likelihood:</td>
<td>160.64</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">No. Observations:</td>
<td>5</td>
<td data-quarto-table-cell-role="th">AIC:</td>
<td>-311.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Df Residuals:</td>
<td>0</td>
<td data-quarto-table-cell-role="th">BIC:</td>
<td>-313.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Df Model:</td>
<td>4</td>
<td data-quarto-table-cell-role="th"></td>
<td></td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Covariance Type:</td>
<td>nonrobust</td>
<td data-quarto-table-cell-role="th"></td>
<td></td>
</tr>
</tbody>
</table>
<table class="simpletable table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td></td>
<td data-quarto-table-cell-role="th">coef</td>
<td data-quarto-table-cell-role="th">std err</td>
<td data-quarto-table-cell-role="th">t</td>
<td data-quarto-table-cell-role="th">P&gt;|t|</td>
<td data-quarto-table-cell-role="th">[0.025</td>
<td data-quarto-table-cell-role="th">0.975]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">const</td>
<td>1.1857</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">x1</td>
<td>0.4598</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x2</td>
<td>0.1756</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">x3</td>
<td>0.7694</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x4</td>
<td>0.7174</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">x5</td>
<td>0.8895</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x6</td>
<td>0.2448</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">x7</td>
<td>-0.4502</td>
<td>inf</td>
<td>-0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x8</td>
<td>1.7932</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">x9</td>
<td>0.9630</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">x10</td>
<td>1.1071</td>
<td>inf</td>
<td>0</td>
<td>nan</td>
<td>nan</td>
<td>nan</td>
</tr>
</tbody>
</table>
<table class="simpletable table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Omnibus:</td>
<td>nan</td>
<td data-quarto-table-cell-role="th">Durbin-Watson:</td>
<td>1.413</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Prob(Omnibus):</td>
<td>nan</td>
<td data-quarto-table-cell-role="th">Jarque-Bera (JB):</td>
<td>0.699</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Skew:</td>
<td>-0.810</td>
<td data-quarto-table-cell-role="th">Prob(JB):</td>
<td>0.705</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Kurtosis:</td>
<td>2.145</td>
<td data-quarto-table-cell-role="th">Cond. No.</td>
<td>10.3</td>
</tr>
</tbody>
</table>
<br><br>Notes:<br>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br>[2] The input rank is higher than the number of observations.
</div>
</div>
</div>
<hr>
<p>The ridge regression estimates can be computed, however:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>lambdas <span class="op">=</span> [<span class="dv">50</span>, <span class="dv">5</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span>]</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>ridge_coefs <span class="op">=</span> []</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>ridge_preds <span class="op">=</span> []</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> lambdas:</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha, fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>    ridge.fit(x, y)</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>    coefs <span class="op">=</span> np.insert(ridge.coef_, <span class="dv">0</span>, ridge.intercept_)</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>    ridge_coefs.append(coefs)</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    ridge_preds.append(ridge.predict(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Ridge(alpha=0.005)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Ridge<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html">?<span>Documentation for Ridge</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Ridge(alpha=0.005)</pre></div> </div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the coefficients</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>ridge_coefs_matrix <span class="op">=</span> np.<span class="bu">round</span>(np.column_stack(ridge_coefs), <span class="dv">5</span>)</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Ridge Regression Coefficients:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Ridge Regression Coefficients:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ridge_coefs_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 5.18812  4.91482  2.78675  2.62205]
 [ 0.01158  0.09603  0.40242  0.40228]
 [ 0.00645  0.05713  0.33944  0.32401]
 [ 0.01229  0.10542  0.71574  0.77444]
 [-0.00651 -0.05165 -0.0551  -0.02453]
 [ 0.00731  0.06545  0.51737  0.54017]
 [-0.0032  -0.03298 -0.5716  -0.64811]
 [-0.00087 -0.00963 -0.33787 -0.42012]
 [ 0.01865  0.16645  1.51073  1.65553]
 [ 0.00831  0.07804  0.89704  0.98841]
 [ 0.0091   0.08014  0.64624  0.70038]]</code></pre>
</div>
</div>
<p>Notice that all 10 predictors make non-zero contributions.</p>
<p>The ridge regression does not produce a perfect fit, however, although the predicted values are close to y if <span class="math inline">\(\lambda\)</span> is small.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, alpha <span class="kw">in</span> <span class="bu">enumerate</span>(lambdas):</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Residuals for lambda=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y <span class="op">-</span> ridge_preds[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Residuals for lambda=50:
[ 1.01938694 -0.75284922 -0.27866919  0.93164247 -0.919511  ]

Residuals for lambda=5:
[ 0.95731299 -0.68567526 -0.2681395   0.79105256 -0.79455079]

Residuals for lambda=0.05:
[ 0.11317993 -0.07438818 -0.05218782  0.05350635 -0.04011028]

Residuals for lambda=0.005:
[ 0.01254769 -0.00831946 -0.0063126   0.00588625 -0.00380188]</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-regularization-lasso" class="level3">
<h3 class="anchored" data-anchor-id="sec-regularization-lasso">Lasso Regression</h3>
<p>The lasso acronym stands for <em>least absolute shrinkage and selection operator</em> and hints at a key difference from Ridge regression: in addition to shrinking the estimates, the lasso can also be used to select features. The reason is that the lasso <span class="math inline">\(L_1\)</span> regularization can shrink estimates to exactly zero, whereas ridge regression shrinks estimates <em>toward</em> zero.</p>
<p>Lasso regression thus combines regularization with feature selection. The coefficients shrunk to zero are associated with variables that can be dropped from the model. It is an important feature of <span class="math inline">\(L_1\)</span> regularization that makes many data scientists prefer lasso over ridge regression. Neither approach dominates the other in terms of mean-squared error, however. In situations where some inputs dominate and many are irrelevant, the lasso tends to outperform ridge regression in MSE. When standardized coefficients are of similar size across the inputs, ridge regression tends to be superior.</p>
<p>In order to apply a model to predict new observations, information on all input variables is necessary. A ridge regression with <span class="math inline">\(p=50\)</span> requires data on 50 features. If lasso shrinks half of them to zero, only 25 attributes need to be measured to make a prediction.</p>
<div class="example">
<div class="example-header">
<p>Example: Hitters Data (ISLR2) (Cont’d)</p>
</div>
<div class="example-container">
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<p>The following statements fit a lasso regression to the <code>Hitters</code> data. The only change from previous code is the specification <code>alpha=1</code> to trigger the <span class="math inline">\(L_1\)</span> regularization penalty.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Salary <span class="sc">~</span> ., <span class="at">data=</span>Hit)[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Hit<span class="sc">$</span>Salary</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">10</span>, <span class="fl">0.1</span>, <span class="dv">0</span>)</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>lasso_reg <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x,y,<span class="at">alpha=</span><span class="dv">1</span>,<span class="at">lambda=</span>grid)</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">coef</span>(lasso_reg)</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>lasso_reg<span class="sc">$</span>lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 100.0  10.0   0.1   0.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(c,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>20 x 4 sparse Matrix of class "dgCMatrix"
                   s0         s1         s2         s3
(Intercept) 220.10409   -1.49700  160.56341  162.43338
AtBat         .          .         -1.94742   -1.95829
Hits          1.13626    2.01155    7.29164    7.35600
HmRun         .          .          3.76633    3.98321
Runs          .          .         -2.11611   -2.20911
RBI           .          .         -0.86604   -0.94010
Walks         1.18265    2.24853    6.10253    6.17861
Years         .          .         -3.27870   -3.51815
CAtBat        .          .         -0.17544   -0.17490
CHits         .          .          0.19355    0.19447
CHmRun        .          0.04705   -0.00305   -0.01667
CRuns         0.11012    0.21931    1.37504    1.37697
CRBI          0.31456    0.40399    0.73697    0.74204
CWalks        .          .         -0.78353   -0.79268
LeagueN       .         18.93190   61.82690   63.24387
DivisionW     .       -115.19852 -116.61419 -117.12570
PutOuts       0.00330    0.23596    0.28159    0.28164
Assists       .          .          0.36796    0.37108
Errors        .         -0.78124   -3.35896   -3.41847
NewLeagueN    .          .        -23.96279  -25.77874</code></pre>
</div>
</div>
<p>For <span class="math inline">\(\lambda=100\)</span> and <span class="math inline">\(\lambda=10\)</span>, several coefficients are shrunk to zero, leaving 5 and 9 non-zero coefficients, respectively (not counting the intercept). The smaller values for <span class="math inline">\(\lambda\)</span> shrink coefficients but not all the way to zero.</p>
<p>The following code chooses <span class="math inline">\(\lambda\)</span> by cross-validation</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">987</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>cv.out <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha=</span><span class="dv">1</span>)</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>bestlam <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>lambda.min</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>bestlam</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.674375</code></pre>
</div>
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(bestlam)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9837159</code></pre>
</div>
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-lasso-cv" class="quarto-figure quarto-figure-center quarto-float anchored" width="90%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-lasso-cv-1.png" id="fig-lasso-cv" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-lasso-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.8
</figcaption>
</figure>
</div>
</div>
</div>
<p>The optimal value for <span class="math inline">\(\lambda\)</span> per 10-fold cross-validation is 2.674. <a href="#fig-lasso-cv" class="quarto-xref">Figure&nbsp;<span>8.8</span></a> displays the results of cross-validation graphically. At the optimal value of <span class="math inline">\(\lambda\)</span>, the lasso model has 13 non-zero coefficients, six of the variables have been deselected from the model. The following output shows the final model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>bestIndex <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>index[<span class="dv">1</span>]</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(cv.out<span class="sc">$</span>glmnet.fit<span class="sc">$</span>beta[,bestIndex],<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     AtBat       Hits      HmRun       Runs        RBI      Walks      Years 
  -1.54734    5.66090    0.00000    0.00000    0.00000    4.72969   -9.59584 
    CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks    LeagueN 
   0.00000    0.00000    0.51082    0.65949    0.39275   -0.52916   32.06508 
 DivisionW    PutOuts    Assists     Errors NewLeagueN 
-119.29902    0.27240    0.17320   -2.05851    0.00000 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"10-fold CV error for lasso regression, "</span>, cv.out<span class="sc">$</span>cvm[bestIndex])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>10-fold CV error for lasso regression,  114101</code></pre>
</div>
</div>
<p>The CV error is lower for the lasso model than for the cross-validated ridge regression.</p>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<p>The following statements fit a lasso regression to the <code>Hitters</code> data using <code>OLS.fit.regularized</code> in <code>statsmodels</code>. The <code>alpha</code> parameter refers to the regularization parameter we called <span class="math inline">\(\lambda\)</span>. The <code>L1_wt</code> parameter determines the weight given to the <span class="math inline">\(L_1\)</span> penalty in the elastic net. <code>L1_wt=1</code> is a lasso regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> scale(hitters_X)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> hitters_X.shape[<span class="dv">0</span>]</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> xstd<span class="op">*</span>np.sqrt((n<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>n)</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>xstd_int <span class="op">=</span> sm.add_constant(xstd)</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> [<span class="dv">100</span>, <span class="dv">10</span>, <span class="fl">0.1</span>, <span class="dv">0</span>]</span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> []</span>
<span id="cb125-8"><a href="#cb125-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha_val <span class="kw">in</span> grid:</span>
<span id="cb125-9"><a href="#cb125-9" aria-hidden="true" tabindex="-1"></a>    lasso_reg <span class="op">=</span> sm.OLS(hitters_Y,xstd_int).fit_regularized(alpha<span class="op">=</span>alpha_val, L1_wt<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb125-10"><a href="#cb125-10" aria-hidden="true" tabindex="-1"></a>    coefficients.append(lasso_reg.params)</span>
<span id="cb125-11"><a href="#cb125-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-12"><a href="#cb125-12" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> np.<span class="bu">round</span>(np.column_stack(coefficients), <span class="dv">5</span>)</span>
<span id="cb125-13"><a href="#cb125-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-14"><a href="#cb125-14" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(suppress<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb125-15"><a href="#cb125-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 435.92588  525.92588  535.82588  535.92588]
 [   0.         0.      -329.37105 -338.53828]
 [  51.93754   88.59554  326.26264  329.06675]
 [   0.         0.         1.50745   -0.63548]
 [   0.         0.         0.        -2.68966]
 [   0.         0.         0.         8.51636]
 [  26.96188   52.6242   133.74006  135.92847]
 [   0.         0.       -96.0603   -95.21428]
 [   0.         0.       122.07674  125.96636]
 [   0.       135.82052  226.87747  225.21274]
 [   0.        77.08391  155.70507  172.86834]
 [   0.         0.         0.        42.3758 ]
 [ 135.56196    0.       -32.35523  -80.92148]
 [   0.         0.      -170.79595 -184.78967]
 [   0.        66.34508   78.24597   79.67741]
 [   0.         0.        41.36618   42.77009]
 [   0.        -5.4344   -25.14144  -25.50286]
 [   0.         9.67285   29.45303   31.12187]
 [   0.       -58.6076   -65.06146  -64.07542]
 [   0.         0.       -17.73594  -18.44659]]</code></pre>
</div>
</div>
<p>For larger values of <span class="math inline">\(\lambda\)</span>, in the columns toward the left of the coefficient printout, a greater regularization penalty is applied, resulting in more coefficients being shrunk to zero. For <span class="math inline">\(\lambda=100\)</span>, only 3 inputs have non-zero coefficient estimates (not counting the intercept). For <span class="math inline">\(\lambda=0.1\)</span>, 16 coefficients have non-zero estimates.</p>
</div>
</div>
</div>
</div>
</div>
<section id="high-dimensional-lasso-regression" class="level4">
<h4 class="anchored" data-anchor-id="high-dimensional-lasso-regression">High-dimensional lasso regression</h4>
<p>Like ridge regression, lasso regression can be used when <span class="math inline">\(p &gt; n\)</span>. Unlike ridge regression, the lasso will give you an idea about the important variables since it sets coefficients for redundant variables to zero.</p>
<p>To demonstrate, consider this small simulation study. Data are generated with <span class="math inline">\(n=30\)</span> and <span class="math inline">\(p=60\)</span> but only the first 5 predictors are significant and have the same coefficient 3.0.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-2" role="tab" aria-controls="tabset-11-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Matrix)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">60</span></span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">3</span>,p1),<span class="fu">rep</span>(<span class="dv">0</span>,p<span class="sc">-</span>p1))</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">&lt;-</span> <span class="fu">scale</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span>p),n,p))</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd =</span> <span class="fl">0.1</span>)</span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>fx <span class="ot">&lt;-</span> xmat <span class="sc">%*%</span> beta</span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>yvec <span class="ot">&lt;-</span> fx <span class="sc">+</span> eps</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s choose <span class="math inline">\(\lambda\)</span> by 10-fold cross-validation</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">527</span>)</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>cv.out <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(xmat,yvec,<span class="at">alpha=</span><span class="dv">1</span>)</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="regfeature_files/figure-html/lasso_sim_cv-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Let’s see what the coefficients look like for the best model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>lasso.fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(xmat,yvec,<span class="at">alpha=</span><span class="dv">1</span>,<span class="at">lambda=</span>cv.out<span class="sc">$</span>lambda.min)</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">coef</span>(lasso.fit)</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(c <span class="sc">!=</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  1  2  3  4  5  6 58</code></pre>
</div>
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(c[<span class="fu">which</span>(c <span class="sc">!=</span> <span class="dv">0</span>)],<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.015  2.857  2.929  2.882  2.851  2.962 -0.014</code></pre>
</div>
</div>
<p>The lasso regression recovered the true model pretty well. Recall that the true model has <span class="math inline">\(\beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 3\)</span> and all other coefficients were zero.</p>
</div>
<div id="tabset-11-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">12345</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define dimensions</span></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>p1 <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> np.concatenate([np.repeat(<span class="dv">3</span>, p1), np.zeros(p<span class="op">-</span>p1)])</span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>xmat <span class="op">=</span> scale(np.random.normal(size<span class="op">=</span>(n, p)))</span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>eps <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="fl">0.1</span>, size<span class="op">=</span>n)</span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>fx <span class="op">=</span> np.dot(xmat, beta)</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a>yvec <span class="op">=</span> fx <span class="op">+</span> eps</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s compute a lasso regression:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>xmat_int <span class="op">=</span> sm.add_constant(xmat)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>lasso_reg <span class="op">=</span> sm.OLS(yvec,xmat_int).fit_regularized(alpha<span class="op">=</span><span class="fl">0.25</span>, L1_wt<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(lasso_reg.params,<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.     2.7545 2.8027 2.5603 2.5887 2.6926 0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.0153 0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.    ]</code></pre>
</div>
</div>
<p>The lasso model recovered the true model quite well. Recall that the true model has <span class="math inline">\(\beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 3\)</span> and all other coefficients were zero. The estimates <span class="math inline">\(\widehat{\beta}_1,\cdots,\widehat{\beta}_5\)</span> are close to 3.0 and all but one other coefficients are shrunk to zero.</p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="sec-feature-dimred" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="sec-feature-dimred"><span class="header-section-number">8.3</span> Dimension Reduction</h2>
<p>We can think of regression as a dimension reduction technique. The target vector <span class="math inline">\(\textbf{Y}\)</span> is an <span class="math inline">\((n \times 1)\)</span> vector in <span class="math inline">\(n\)</span>-dimensional space. <span class="math inline">\(\textbf{X}\boldsymbol{\beta}\)</span> is a <span class="math inline">\((p+1 \times 1)\)</span> vector in <span class="math inline">\((p+1)\)</span>-dimensional space. We are finding the least squares solution by projecting <span class="math inline">\(\textbf{Y}\)</span> onto the column space of <span class="math inline">\(\textbf{X}\)</span>–in other words, we are finding the closest representation of <span class="math inline">\(\textbf{Y}\)</span> in a <span class="math inline">\((p+1)\)</span>-dimensional space. The techniques discussed so far in this chapter to deal with the problem of <span class="math inline">\(p\)</span> being large are</p>
<ol type="1">
<li>Set some <span class="math inline">\(\beta_j\)</span> to zero <span class="math inline">\(\rightarrow\)</span> feature selection</li>
<li>Impose constraints on the <span class="math inline">\(\beta_j \rightarrow\)</span> regularization</li>
</ol>
<p>A third technique to reduce the dimensionality of the problem is to apply a two-step procedure. In the first step we create <span class="math inline">\(M\)</span> linear combinations of the <span class="math inline">\(p\)</span> inputs, call them <span class="math inline">\(Z_1, \cdots, Z_M\)</span>. We choose <span class="math inline">\(M \ll p\)</span> and in the second step use <span class="math inline">\(Z_1\)</span> through <span class="math inline">\(Z_M\)</span> as the input variables in a regression model.</p>
<section id="principal-components" class="level3">
<h3 class="anchored" data-anchor-id="principal-components">Principal Components</h3>
<p>It is important that the <span class="math inline">\(Z_M\)</span> are linear combinations of <strong>all</strong> predictors <span id="eq-pca-scores"><span class="math display">\[
        Z_{im} = \sum_{j=1}^p \phi_{jm}X_{ij}
\tag{8.5}\]</span></span></p>
<p>The coefficients <span class="math inline">\(\phi_{jm}\)</span> are called the <strong>loadings</strong> or <strong>rotations</strong> and the <strong>scores</strong> <span class="math inline">\(Z_{im}\)</span> are constructed as the <strong>principal components</strong> of the <span class="math inline">\(\textbf{X}\)</span> matrix. We will discuss principal component analysis (PCA) and the construction of the <span class="math inline">\(Z_{im}\)</span> in detail in <a href="pca.html" class="quarto-xref"><span>Chapter 24</span></a>.</p>
<p>(PCA) finds linear combinations of <span class="math inline">\(p\)</span> inputs that explain decreasing amounts of variability among the <span class="math inline">\(x\)</span>’s. Not any linear combination will do, the principal components are orthogonal to each other and project in the directions in which the inputs are most variable. That means they decompose the variability in the inputs into non-overlapping chunks. The first principal component explains the most variability, the second principal component explains the second-most variability, and so forth.</p>
<p>Consider the following data set with <span class="math inline">\(n=10\)</span> and <span class="math inline">\(p=4\)</span>.</p>
<div id="tbl-pca-data" class="striped hover quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-pca-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8.1: Example data for principal component analysis. Sample mean and standard deviation of the columns shown in the last two rows.
</figcaption>
<div aria-describedby="tbl-pca-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover table">
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Obs</strong></th>
<th style="text-align: center;"><span class="math inline">\(X_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_3\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.344</td>
<td style="text-align: center;">0.364</td>
<td style="text-align: center;">0.806</td>
<td style="text-align: center;">0.160</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.363</td>
<td style="text-align: center;">0.354</td>
<td style="text-align: center;">0.696</td>
<td style="text-align: center;">0.249</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.196</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.437</td>
<td style="text-align: center;">0.248</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.200</td>
<td style="text-align: center;">0.212</td>
<td style="text-align: center;">0.590</td>
<td style="text-align: center;">0.160</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.227</td>
<td style="text-align: center;">0.229</td>
<td style="text-align: center;">0.437</td>
<td style="text-align: center;">0.187</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">0.204</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">0.090</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.499</td>
<td style="text-align: center;">0.169</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">0.165</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;">0.536</td>
<td style="text-align: center;">0.267</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.138</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">0.362</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">0.483</td>
<td style="text-align: center;">0.223</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\overline{x}_j\)</span></td>
<td style="text-align: center;">0.218</td>
<td style="text-align: center;">0.222</td>
<td style="text-align: center;">0.544</td>
<td style="text-align: center;">0.211</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(s_j\)</span></td>
<td style="text-align: center;">0.076</td>
<td style="text-align: center;">0.081</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.075</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>When the <span class="math inline">\(x\)</span>s are centered with their means and scaled by their standard deviations, and the principal components are computed, the matrix of loadings is <span class="math display">\[
\boldsymbol{\Phi} = \left [ \begin{array}{r r r r }
-0.555 &amp; 0.235 &amp;  0.460 &amp; -0.652\\
-0.574 &amp;0.052  &amp;0.336 &amp; 0.745\\
-0.530 &amp;0.208 &amp;-0.821 &amp;-0.053\\
0.286 &amp;0.948  &amp;0.047  &amp; 0.132\\
     \end{array} \right]
\]</span></p>
<p>This matrix can now be used, along with the data in <a href="#tbl-pca-data" class="quarto-xref">Table&nbsp;<span>8.1</span></a> to compute the scores <span class="math inline">\(Z_{im}\)</span>. For example,</p>
<p><span class="math display">\[\begin{align*}
    Z_{11} &amp;= -0.555 \frac{0.344-0.218}{0.076} -0.574\frac{0.364-0.222}{0.081} - 0.530\frac{0.806-0.544}{0.122} + 0.286\frac{0.16-0.211}{0.075} = -3.248 \\
    Z_{32} &amp;= 0.235 \frac{0.196-0.218}{0.076} +0.052\frac{0.189-0.222}{0.081} + 0.208\frac{0.437-0.544}{0.122} +0.948\frac{0.248-0.211}{0.075} = 0.194\\
\end{align*}\]</span></p>
<p><a href="#tbl-pca-scores" class="quarto-xref">Table&nbsp;<span>8.2</span></a> displays the four inputs and the four scores <span class="math inline">\(Z_1, \cdots Z_4\)</span> from the PCA.</p>
<div id="tbl-pca-scores" class="striped hover quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-pca-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8.2: Data (<span class="math inline">\(X_1,\cdots,X_4\)</span>) and principal component scores (<span class="math inline">\(Z_1,\cdots,Z_4\)</span>).
</figcaption>
<div aria-describedby="tbl-pca-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover table">
<colgroup>
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Obs</strong></th>
<th style="text-align: center;"><span class="math inline">\(X_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_3\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_4\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_3\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.344</td>
<td style="text-align: center;">0.364</td>
<td style="text-align: center;">0.806</td>
<td style="text-align: center;">0.160</td>
<td style="text-align: center;">-3.248</td>
<td style="text-align: center;">0.282</td>
<td style="text-align: center;">-0.440</td>
<td style="text-align: center;">0.029</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.363</td>
<td style="text-align: center;">0.354</td>
<td style="text-align: center;">0.696</td>
<td style="text-align: center;">0.249</td>
<td style="text-align: center;">-2.510</td>
<td style="text-align: center;">1.257</td>
<td style="text-align: center;">0.425</td>
<td style="text-align: center;">-0.025</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.196</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.437</td>
<td style="text-align: center;">0.248</td>
<td style="text-align: center;">0.993</td>
<td style="text-align: center;">0.194</td>
<td style="text-align: center;">0.465</td>
<td style="text-align: center;">0.001</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.200</td>
<td style="text-align: center;">0.212</td>
<td style="text-align: center;">0.590</td>
<td style="text-align: center;">0.160</td>
<td style="text-align: center;">-0.191</td>
<td style="text-align: center;">-0.629</td>
<td style="text-align: center;">-0.498</td>
<td style="text-align: center;">-0.041</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.227</td>
<td style="text-align: center;">0.229</td>
<td style="text-align: center;">0.437</td>
<td style="text-align: center;">0.187</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">-0.459</td>
<td style="text-align: center;">0.780</td>
<td style="text-align: center;">-0.001</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">0.204</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">0.090</td>
<td style="text-align: center;">-0.329</td>
<td style="text-align: center;">-1.614</td>
<td style="text-align: center;">0.055</td>
<td style="text-align: center;">0.023</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.499</td>
<td style="text-align: center;">0.169</td>
<td style="text-align: center;">0.286</td>
<td style="text-align: center;">-0.691</td>
<td style="text-align: center;">0.087</td>
<td style="text-align: center;">0.012</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">0.165</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;">0.536</td>
<td style="text-align: center;">0.267</td>
<td style="text-align: center;">1.058</td>
<td style="text-align: center;">0.479</td>
<td style="text-align: center;">-0.485</td>
<td style="text-align: center;">0.009</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.138</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">0.362</td>
<td style="text-align: center;">2.380</td>
<td style="text-align: center;">1.391</td>
<td style="text-align: center;">-0.098</td>
<td style="text-align: center;">0.023</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">0.483</td>
<td style="text-align: center;">0.223</td>
<td style="text-align: center;">1.306</td>
<td style="text-align: center;">-0.210</td>
<td style="text-align: center;">-0.291</td>
<td style="text-align: center;">-0.028</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>For each observation there is a corresponding component score and there are as many components as there are input variables. Although there is a 1:1 correspondence at the row level, there is no such correspondence at the column level. Instead, each PCA score <span class="math inline">\(Z_j\)</span> is a linear combination of <strong>all</strong> <span class="math inline">\(p\)</span> input variables. Even if we were to proceed with only <span class="math inline">\(Z_1\)</span> in a linear model <span class="math display">\[
Y_i = \theta_0 + \theta_1 Z_{i1} + \epsilon_i
\]</span> the model contains information from from <span class="math inline">\(X_1\)</span> through <span class="math inline">\(X_4\)</span> because <span class="math display">\[
Z_{i1} = \sum_{j=1}^p \phi_{j1}X_{ij}
\]</span></p>
<p>So what have we gained? The <span class="math inline">\(Z_j\)</span> have very special properties, not shared by the <span class="math inline">\(X_j\)</span>:</p>
<ul>
<li>They have zero mean :<span class="math inline">\(\sum_{i=1}^n Z_{ij} = 0\)</span> (if data was centered)</li>
<li>They are uncorrelated: <span class="math inline">\(\text{Corr}[Z_j, Z_k] = 0, \forall j \ne k\)</span></li>
<li><span class="math inline">\(\text{Var}\left[\sum_{j=1}^p Z_j\right] = \sum_{j=1}^p \text{Var}[Z_j] = p\)</span> (if data was scaled)</li>
<li>The components are ordered in terms of their variance: <span class="math inline">\(\text{Var}[Z_1] &gt; \text{Var}[Z_2] &gt; \cdots &gt; \text{Var}[Z_p]\)</span></li>
</ul>
<div id="tbl-pca-stats" class="striped quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-pca-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8.3: Statistics computed for <span class="math inline">\(X_j\)</span> and <span class="math inline">\(Z_j\)</span>.
</figcaption>
<div aria-describedby="tbl-pca-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table">
<colgroup>
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Statistic</strong></th>
<th style="text-align: center;"><span class="math inline">\(X_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_3\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X_4\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_3\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Z_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Sample Mean</td>
<td style="text-align: center;">0.218</td>
<td style="text-align: center;">0.222</td>
<td style="text-align: center;">0.544</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">Sample Sd</td>
<td style="text-align: center;">0.076</td>
<td style="text-align: center;">0.081</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.075</td>
<td style="text-align: center;">1.719</td>
<td style="text-align: center;">0.918</td>
<td style="text-align: center;">0.445</td>
<td style="text-align: center;">0.024</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Sample Var</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2.957</td>
<td style="text-align: center;">0.844</td>
<td style="text-align: center;">0.199</td>
<td style="text-align: center;">0.0006</td>
</tr>
<tr class="even">
<td style="text-align: center;">% Variance</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">73.9 %</td>
<td style="text-align: center;">21%</td>
<td style="text-align: center;">5%</td>
<td style="text-align: center;"><span class="math inline">\(&lt;\)</span> 1%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The sum of the sample variances of the <span class="math inline">\(Z_j\)</span> in <a href="#tbl-pca-stats" class="quarto-xref">Table&nbsp;<span>8.3</span></a> is (within rounding error) <span class="math display">\[
2.957 + 0.844 + 0.199 + 0.0006 = 4
\]</span> The first principal component, <span class="math inline">\(Z_1\)</span>, explains <span class="math inline">\(2.957/4 \times 100\% = 73.9\%\)</span> of the variability in the input variables.</p>
<p>As you can see from <a href="#eq-pca-scores" class="quarto-xref">Equation&nbsp;<span>8.5</span></a>, PCA is an unsupervised learning method, it does not involve a target variable. The result of PCA, however, can be used in a supervised learning method, such as a regression model. A regression model that uses principal components as the input is called a <strong>principal component regression</strong> (PCR).</p>
</section>
<section id="sec-pcr" class="level3">
<h3 class="anchored" data-anchor-id="sec-pcr">Principal Component Regression (PCR)</h3>
<p>Based on the variance decomposition of the principal components (see the last row of <a href="#tbl-pca-stats" class="quarto-xref">Table&nbsp;<span>8.3</span></a>), we can select a subset <span class="math inline">\(Z_1, \cdots, Z_M\)</span> from the scores <span class="math inline">\(Z_1, \cdots, Z_p\)</span>. The number of principal components included into the model depends on how much variability in the <span class="math inline">\(X\)</span>s we want to account for. If all <span class="math inline">\(p\)</span> principal components are included in the model we have not really reduced the dimensionality. In the example above, the first two principal components account for 73.9% + 21 % = 94.9% of the variability; there is not much gained in choosing <span class="math inline">\(M &gt; 2\)</span>.</p>
<p>Once the <span class="math inline">\(M\)</span> principal components have been selected, the linear model becomes</p>
<p><span class="math display">\[
\textbf{Y}_{n \times 1} = \theta_0 + \textbf{Z}_{n \times M}\boldsymbol{\theta}+ \boldsymbol{\epsilon}
\]</span> The dimension of the problem has been reduced from <span class="math inline">\(p+1\)</span> to <span class="math inline">\(M+1\)</span>.</p>
<p>You can show that this is equivalent to a linear model with coefficients <span class="math display">\[
    \beta_j = \sum_{m=1}^M\theta_m \phi_{jm}
\]</span> Principal component regression can be viewed as a method of constraining the coefficients, forcing the <span class="math inline">\(\beta_j\)</span> to take on this particular form.</p>
<p>The number of components <span class="math inline">\(M\)</span> in PCR can be chosen heuristically or through cross-validation as in the following example.</p>
<div class="example">
<div class="example-header">
<p>Example: Hitters Data (ISLR2) (Cont’d)</p>
</div>
<div class="example-container">
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-12-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-2" role="tab" aria-controls="tabset-12-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<p>To apply PCR to the <code>Hitters</code> data we use the <code>pcr</code> function in the <code>pls</code> library. The <code>validation=</code> option determines whether <span class="math inline">\(k\)</span>-fold cross-validation or leave-one-out cross-validation is performed. Here, we choose LOOCV. By default, <code>pcr</code> centers the data but does not scale it. <code>scale=TRUE</code> makes sure that the data are also scaled. We recommend that analyses based on principal components are always centered and scaled.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pls)</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>pcr.fit <span class="ot">&lt;-</span> <span class="fu">pcr</span>(Salary <span class="sc">~</span> ., <span class="at">data=</span>Hit, </span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">scale=</span><span class="cn">TRUE</span>, </span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">validation=</span><span class="st">"LOO"</span>)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pcr.fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data:   X dimension: 263 19 
    Y dimension: 263 1
Fit method: svdpc
Number of components considered: 19

VALIDATION: RMSEP
Cross-validated using 263 leave-one-out segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
CV             452      352    351.4    351.3      349    345.2    342.5
adjCV          452      352    351.4    351.2      349    345.2    342.5
       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
CV       343.5    345.3      347     348.9     350.0     351.6     355.6
adjCV    343.4    345.3      347     348.9     349.9     351.6     355.5
       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
CV        347.7     348.6     339.6     340.9     339.7     343.6
adjCV     347.6     348.6     339.5     340.8     339.6     343.5

TRAINING: % variance explained
        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
X         38.31    60.16    70.84    79.03    84.29    88.63    92.26    94.96
Salary    40.63    41.58    42.17    43.22    44.90    46.48    46.69    46.75
        9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps
X         96.28     97.26     97.98     98.65     99.15     99.47     99.75
Salary    46.86     47.76     47.82     47.85     48.10     50.40     50.55
        16 comps  17 comps  18 comps  19 comps
X          99.89     99.97     99.99    100.00
Salary     53.01     53.85     54.61     54.61</code></pre>
</div>
</div>
<p>There are 19 input variables and hence there are 19 principal components. The output displays two tables with 19 columns each. The first reports the cross-validated root mean square error of prediction and a bias-adjusted version. The smallest error is achieved with six components in the model. The second table displays the cumulative proportion of variability explained. Using just the first principal component explains 38.31 % of the variability in the <span class="math inline">\(X\)</span>s. That model has an <span class="math inline">\(R^2\)</span> of 0.4063. Adding the second principal component adds 21.84 % of variability in the <span class="math inline">\(X\)</span>s.</p>
<p>The model with 6 components, chosen by cross-validation, explains 88.63% of the variability in <span class="math inline">\(X\)</span> and 46.48% of the variability in the <code>Salary</code> target. The sharp drop-off in mean-square error after the first component enters the model is seen in <a href="#fig-pcr-hit" class="quarto-xref">Figure&nbsp;<span>8.9</span></a>. This is a pretty typical picture, because the components are ordered in terms of the proportion of variability explained. Selecting the hyper-parameter based on the “kink” or “elbow” in cross-validation plots is sometimes referred to as the “elbow method”.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">validationplot</span>(pcr.fit,<span class="at">val.type=</span><span class="st">"MSEP"</span>,<span class="at">legendpos=</span><span class="st">"topright"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-pcr-hit" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pcr-hit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regfeature_files/figure-html/fig-pcr-hit-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pcr-hit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.9: Mean square prediction error as a function of number of principal components in PCR.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The chosen model can be fit with the following statements. Note that there is no change to the percentages of variability explained. The components 7–19 are simply not used in the model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>pcr.final <span class="ot">&lt;-</span> <span class="fu">pcr</span>(Salary <span class="sc">~</span> ., <span class="at">data=</span>Hit, </span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">scale=</span><span class="cn">TRUE</span>, </span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">validation=</span><span class="st">"none"</span>,</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">ncomp=</span><span class="dv">6</span>)</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pcr.final)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data:   X dimension: 263 19 
    Y dimension: 263 1
Fit method: svdpc
Number of components considered: 6
TRAINING: % variance explained
        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
X         38.31    60.16    70.84    79.03    84.29    88.63
Salary    40.63    41.58    42.17    43.22    44.90    46.48</code></pre>
</div>
</div>
<p>Here are the loadings for the six components in the final model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">loadings</span>(pcr.final)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>],<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Comp 1  Comp 2  Comp 3  Comp 4  Comp 5  Comp 6
AtBat       0.1983  0.3838 -0.0886  0.0320 -0.0281 -0.0706
Hits        0.1959  0.3773 -0.0740  0.0180  0.0047 -0.0822
HmRun       0.2044  0.2371  0.2162 -0.2358 -0.0777 -0.1496
Runs        0.1983  0.3777  0.0172 -0.0499  0.0385 -0.1367
RBI         0.2352  0.3145  0.0731 -0.1390 -0.0243 -0.1117
Walks       0.2089  0.2296 -0.0456 -0.1306  0.0325 -0.0195
Years       0.2826 -0.2624 -0.0346  0.0953  0.0104  0.0332
CAtBat      0.3305 -0.1929 -0.0836  0.0911 -0.0117  0.0244
CHits       0.3307 -0.1829 -0.0863  0.0838 -0.0085  0.0294
CHmRun      0.3190 -0.1263  0.0863 -0.0743 -0.0327 -0.0408
CRuns       0.3382 -0.1723 -0.0530  0.0692  0.0176  0.0069
CRBI        0.3403 -0.1681 -0.0150  0.0067 -0.0280  0.0115
CWalks      0.3168 -0.1923 -0.0421  0.0304  0.0340  0.0340
LeagueN    -0.0545 -0.0952 -0.5477 -0.3960 -0.0120 -0.1368
DivisionW  -0.0257 -0.0367  0.0162  0.0427 -0.9857 -0.0909
PutOuts     0.0777  0.1557 -0.0513 -0.2876 -0.1059  0.9241
Assists    -0.0008  0.1687 -0.3979  0.5241  0.0111  0.0352
Errors     -0.0079  0.2008 -0.3829  0.4219 -0.0553  0.1482
NewLeagueN -0.0419 -0.0776 -0.5446 -0.4177 -0.0145 -0.1570</code></pre>
</div>
</div>
<p>The loadings give us the weights of the input variables for each component. They show that each principal component is a linear combination of all the inputs. Examining the magnitude of the loading values gives an idea which inputs influence the <span class="math inline">\(j\)</span><sup>th</sup> component most. For example, the first component has large values for inputs related to hits, at bats, and runs.</p>
<p>The <code>scores</code> represent the <span class="math inline">\(\textbf{X}\)</span> matrix of a linear regression of <span class="math inline">\(\textbf{Y}\)</span> on the principal components.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">scores</span>(pcr.final)[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                        Comp 1     Comp 2     Comp 3      Comp 4     Comp 5
-Alan Ashby       -0.009630358 -1.8669625 -1.2627377 -0.93370088 -1.1075240
-Alvin Davis       0.410650757  2.4247988  0.9074630 -0.26370961 -1.2296868
-Andre Dawson      3.460224766 -0.8243753 -0.5544124 -1.61364990  0.8558560
-Andres Galarraga -2.553449083  0.2305443 -0.5186536 -2.17210952  0.8187399
-Alfredo Griffin   1.025746581  1.5705427 -1.3288484  3.48735458 -0.9815556
-Al Newman        -3.973081710 -1.5044104  0.1551832  0.36913641  1.2070332
-Argenis Salazar  -3.445150319 -0.5988471  0.6252834  1.99597066 -0.8054899
-Andres Thomas    -3.425848614 -0.1133262 -1.9959449  0.76635168 -1.0141581
-Andre Thornton    3.892286472 -1.9441629  1.8170103 -0.02666265  1.1349640
-Alan Trammell     3.168770232  2.3878127 -0.7929565  2.56411717  0.9455254
                       Comp 6
-Alan Ashby        1.20966568
-Alvin Davis       1.82314071
-Andre Dawson     -1.02675473
-Andres Galarraga  1.48885745
-Alfredo Griffin   0.51269788
-Al Newman         0.03344990
-Argenis Salazar   0.20557943
-Andres Thomas    -0.27227807
-Andre Thornton   -0.81948303
-Alan Trammell    -0.06113485</code></pre>
</div>
</div>
<p>You can validate the score calculation by combining the <span class="math inline">\(\textbf{X}\)</span> matrix of the model with the loadings. For the selected PCR model with 6 components</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>xm <span class="ot">&lt;-</span> <span class="fu">scale</span>(<span class="fu">model.matrix</span>(Salary <span class="sc">~</span> .,<span class="at">data=</span>Hit)[,<span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%*%</span> <span class="fu">loadings</span>(pcr.final)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <span class="math inline">\(\textbf{X}\)</span> matrix is centered and scaled to match the computations of the <code>pcr()</code> function. The scores and the matrix calculated from the loadings should be identical</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">scores</span>(pcr.final)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>] <span class="sc">-</span> xm),<span class="dv">5</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p>If the first 6 components are used in a regression with target <code>Salary</code>, the <span class="math inline">\(R^2\)</span> of that regression should equal 0.4648, corresponding to 46.48% variance explained by 6 components in the PCR output.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Hit<span class="sc">$</span>Salary <span class="sc">~</span> <span class="fu">scores</span>(pcr.final)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]))<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4648</code></pre>
</div>
</div>
</div>
<div id="tabset-12-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-12-2-tab">
<p>To perform principal component regression in Python we create a pipeline with principal component analysis (PCA) to select the number of components in <span class="math inline">\(X\)</span>-space and follow that with a linear regression.</p>
<p>First, let’s run a PCA on the centered and scaled <span class="math inline">\(\textbf{X}\)</span> matrix for the Hitters data, using <code>PCA</code> from <code>sklearn.decomposition</code>. If you specify the number of principal components as a fraction (between 0 and 1), the module interprets the parameter as the proportion of total variance that needs to be achieved. The number of principal components are determined so that the cumulative variance exceeds the threshold.</p>
<p>In the following code we request PCA up to as many components to explain at least 80% of the variability in the inputs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-6"><a href="#cb150-6" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> scale(hitters_X)</span>
<span id="cb150-7"><a href="#cb150-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> hitters_X.shape[<span class="dv">0</span>]</span>
<span id="cb150-8"><a href="#cb150-8" aria-hidden="true" tabindex="-1"></a>xstd <span class="op">=</span> xstd<span class="op">*</span>np.sqrt((n<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>n)</span>
<span id="cb150-9"><a href="#cb150-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-10"><a href="#cb150-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb150-11"><a href="#cb150-11" aria-hidden="true" tabindex="-1"></a>pca.fit(xstd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-6 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-6 {
  color: var(--sklearn-color-text);
}

#sk-container-id-6 pre {
  padding: 0;
}

#sk-container-id-6 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-6 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-6 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-6 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-6 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-6 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-6 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-6 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-6 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-6 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-6 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-6 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-6 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-6 div.sk-label label.sk-toggleable__label,
#sk-container-id-6 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-6 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-6 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-6 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-6 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-6 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-6 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-6 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-6 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>PCA(n_components=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked=""><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;PCA<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html">?<span>Documentation for PCA</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>PCA(n_components=0.8)</pre></div> </div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PCA number of components: </span><span class="sc">{</span>pca<span class="sc">.</span>n_components_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a><span class="co">## PCA number of components: 5</span></span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total variance explained: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Total variance explained: 0.8429027516166474</span></span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(pca.explained_variance_ratio_,<span class="dv">4</span>))</span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a><span class="co">## [0.3831 0.2184 0.1069 0.0819 0.0526]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first principal component explains 38.3% of the variability in <span class="math inline">\(\textbf{X}\)</span>, the second component explains 21.8% and so forth. Five components are needed to explain more than 80% of the variability.</p>
<p>Next we build a pipeline of PCA and linear regression to perform principal component regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline </span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error </span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> LinearRegression() </span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'pca'</span>, pca), </span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a>                           (<span class="st">'reg'</span>, reg)]) </span>
<span id="cb152-8"><a href="#cb152-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb152-9"><a href="#cb152-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the pipeline to the data </span></span>
<span id="cb152-10"><a href="#cb152-10" aria-hidden="true" tabindex="-1"></a>pipeline.fit(xstd, hitters_Y) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-7 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-7 {
  color: var(--sklearn-color-text);
}

#sk-container-id-7 pre {
  padding: 0;
}

#sk-container-id-7 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-7 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-7 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-7 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-7 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-7 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-7 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-7 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-7 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-7 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-7 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-7 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-7 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-7 div.sk-label label.sk-toggleable__label,
#sk-container-id-7 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-7 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-7 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-7 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-7 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-7 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-7 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-7 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-7 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('pca', PCA(n_components=0.8)), ('reg', LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"><label for="sk-estimator-id-9" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('pca', PCA(n_components=0.8)), ('reg', LinearRegression())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox"><label for="sk-estimator-id-10" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;PCA<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html">?<span>Documentation for PCA</span></a></label><div class="sk-toggleable__content fitted"><pre>PCA(n_components=0.8)</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox"><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LinearRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div>
</div>
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> pipeline.predict(xstd) </span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(hitters_Y,y_pred) </span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(hitters_Y, y_pred) </span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mse) </span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> pipeline.score(xstd, hitters_Y) </span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-9"><a href="#cb153-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of features before PCR: </span><span class="sc">{</span>xstd<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>) </span>
<span id="cb153-10"><a href="#cb153-10" aria-hidden="true" tabindex="-1"></a><span class="co">## Number of features before PCR: 19</span></span>
<span id="cb153-11"><a href="#cb153-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of features after PCR: </span><span class="sc">{</span>pca<span class="sc">.</span>n_components_<span class="sc">}</span><span class="ss">'</span>) </span>
<span id="cb153-12"><a href="#cb153-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Number of features after PCR: 5</span></span>
<span id="cb153-13"><a href="#cb153-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-14"><a href="#cb153-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MAE : </span><span class="sc">{</span>mae<span class="sc">:.2f}</span><span class="ss">'</span>) </span>
<span id="cb153-15"><a href="#cb153-15" aria-hidden="true" tabindex="-1"></a><span class="co">## MAE : 227.10</span></span>
<span id="cb153-16"><a href="#cb153-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE : </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">'</span>) </span>
<span id="cb153-17"><a href="#cb153-17" aria-hidden="true" tabindex="-1"></a><span class="co">## MSE : 111697.59</span></span>
<span id="cb153-18"><a href="#cb153-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">'</span>) </span>
<span id="cb153-19"><a href="#cb153-19" aria-hidden="true" tabindex="-1"></a><span class="co">## RMSE: 334.21</span></span>
<span id="cb153-20"><a href="#cb153-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'R^2 : </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">'</span>) </span>
<span id="cb153-21"><a href="#cb153-21" aria-hidden="true" tabindex="-1"></a><span class="co">## R^2 : 0.45</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A principal component regression with five principal components explains 84% of the variability in the inputs but only 44.5% of the variability of the target variable <code>Salary</code>.</p>
</div>
</div>
</div>
</div>
</div>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;8.3: Fit statistics for the best <span class="math inline">\(k\)</span>-input models from best subset regression.</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;8.7: Ridge trace for credit data.</span>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-FurnivalWilson1974" class="csl-entry" role="listitem">
Furnival, George M., and Robert W. Wilson. 1974. <span>“Regression by Leaps and Bounds.”</span> <em>Technometrics</em> 16 (4): 499–511.
</div>
<div id="ref-James2013_ISLR2" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. <em>An Introduction to Statistical Learning: With Applications in r, 2nd Ed.</em> Springer. <a href="https://www.statlearning.com/">https://www.statlearning.com/</a>.
</div>
<div id="ref-Mallows1973" class="csl-entry" role="listitem">
Mallows, C. L. 1973. <span>“Some Comments on <span class="math inline">\(C_p\)</span>.”</span> <em>Technometrics</em> 15 (4): 661–75.
</div>
<div id="ref-Miller1984" class="csl-entry" role="listitem">
Miller, Alan J. 1984. <span>“Selection of Subsets of Regression Variables.”</span> <em>Journal of the Royal Statistical Society, Series A.</em> 147 (3): 389–425.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./regglobal.html" class="pagination-link" aria-label="The Classical Linear Model">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Classical Linear Model</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./regnlr.html" class="pagination-link" aria-label="Nonlinear Regression">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nonlinear Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Statistical Learning by Oliver Schabenberger</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","selector":".lightbox","loop":false,"descPosition":"bottom","closeEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>