<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Learning - 2&nbsp; Bias Variance Tradeoff</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./linalg.html" rel="next">
<link href="./statmodels.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./statmodels.html">Part I. Foundation</a></li><li class="breadcrumb-item"><a href="./biasvariance.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistical Learning</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part I. Foundation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./statmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./biasvariance.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learningtypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Types of Statistical Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Part II. Supervised Learning I: Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regglobal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Classical Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regfeature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Feature Selection and Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regnlr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nonlinear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regdiscrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Discrete Target Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reglocal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Local Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Part III. Supervised Learning II: Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classintro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Regression Approach to Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./class_random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Classification with Random Inputs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supportvectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vectors</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Part IV. Decision Trees</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decisiontrees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Regression and Classification Trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treesinR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Trees in <code>R</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Part V. Ensemble Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ensemble_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Bagging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Bayesian Model Averaging</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Part VI. Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsuper_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Principal Component Analysis (PCA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Cluster Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mbc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Model-based Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./arules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Association Rules</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Part VII. Supervised Learning III: Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Generalized Additive Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./corrdata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Correlated Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Mixed Models for Longitudinal Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Part VIII. Neural Networks and Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Training Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ann_R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Neural Networks in <code>R</code> (with Keras)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reinforcement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Part IX. Explainability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./explainability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Interpretability and Explainability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#a-simulation" id="toc-a-simulation" class="nav-link active" data-scroll-target="#a-simulation"><span class="header-section-number">2.1</span> A Simulation</a></li>
  <li><a href="#accuracy-and-precision" id="toc-accuracy-and-precision" class="nav-link" data-scroll-target="#accuracy-and-precision"><span class="header-section-number">2.2</span> Accuracy and Precision</a></li>
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error"><span class="header-section-number">2.3</span> Mean Squared Error</a></li>
  <li><a href="#overfitting-and-underfitting" id="toc-overfitting-and-underfitting" class="nav-link" data-scroll-target="#overfitting-and-underfitting"><span class="header-section-number">2.4</span> Overfitting and Underfitting</a></li>
  <li><a href="#sec-train-test-validate" id="toc-sec-train-test-validate" class="nav-link" data-scroll-target="#sec-train-test-validate"><span class="header-section-number">2.5</span> Training, Testing, and Validation</a>
  <ul>
  <li><a href="#training-data" id="toc-training-data" class="nav-link" data-scroll-target="#training-data">Training Data</a></li>
  <li><a href="#test-data" id="toc-test-data" class="nav-link" data-scroll-target="#test-data">Test Data</a></li>
  <li><a href="#validation-data" id="toc-validation-data" class="nav-link" data-scroll-target="#validation-data">Validation Data</a></li>
  <li><a href="#hold-out-sample" id="toc-hold-out-sample" class="nav-link" data-scroll-target="#hold-out-sample">Hold-out Sample</a></li>
  </ul></li>
  <li><a href="#sec-cross-validation" id="toc-sec-cross-validation" class="nav-link" data-scroll-target="#sec-cross-validation"><span class="header-section-number">2.6</span> Cross-validation</a>
  <ul>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">Loss Functions</a></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation"><span class="math inline">\(K\)</span>-fold Cross-validation</a></li>
  <li><a href="#leave-one-out-cross-validation" id="toc-leave-one-out-cross-validation" class="nav-link" data-scroll-target="#leave-one-out-cross-validation">Leave-One-Out Cross-validation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./statmodels.html">Part I. Foundation</a></li><li class="breadcrumb-item"><a href="./biasvariance.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-bias-variance" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias Variance Tradeoff</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The Bias-Variance tradeoff describes a fundamental tension in data science projects. The models we build are approximations because the true relationship between inputs and outputs is not known. If we work with statistical models, then the data-generating mechanism on which the model is based is also an approximation for the true—and unknown—process. The data we work with is typically the result of some selection mechanism. If we were to repeat the selection process different observations result. Apply the same method to a different set of data you will get different answers—there is variability in the results due to the inherent variability in the data.</p>
<section id="a-simulation" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="a-simulation"><span class="header-section-number">2.1</span> A Simulation</h2>
<p>To illustrate the concept, let’s start with a simulated example where we know the true function and collect multiple samples.</p>
<p>The following figure shows the relationship between an input variable <span class="math inline">\(X\)</span> and some output function <span class="math inline">\(f(x)\)</span>. The function depicts the true relationship, the dots mark design points at which we collect observations. Because the data is inherently variable our sample observations will not fall on the black line. If the sample is unbiased, they should spread evenly about the true trend.</p>
<div id="fig-true-func" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-true-func-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_true_func.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-true-func-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: A response function of one input variable.
</figcaption>
</figure>
</div>
<p>Suppose that we repeat the sampling process four times, drawing eleven observations each time.</p>
<div id="fig-four-draws" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-four-draws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_draws.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-four-draws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: Four random samples of size eleven.
</figcaption>
</figure>
</div>
<p>This is an unrealistic situation. In real life, we do not know the solid function <span class="math inline">\(f(x)\)</span> and we draw only one set of data, for example, we would work with only the black triangles or the blue dots in the previous figure.</p>
<p>Next, we train a model on the data and are considering two types of methods: a linear regression model and a smoothing spline.</p>
<div id="fig-four-reg" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-four-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_reg.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-four-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Linear regression models fit to the four data sets.
</figcaption>
</figure>
</div>
<p>The linear regression model is not flexible. It has only two parameters, the intercept of the vertical line at <span class="math inline">\(x = 0\)</span> and the slope of the line. The lines do not follow the curved trend in the function <span class="math inline">\(f(x)\)</span>. Because of this rigidity, the four lines are somewhat similar to each other, they do not show a high degree of variability from sample to sample.</p>
<div id="fig-four-splines" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-four-splines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_splines.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-four-splines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Smoothing splines with 6 degrees of freedom fit to the four data sets.
</figcaption>
</figure>
</div>
<p>The splines show more flexibility than the linear regression lines and follow the observed data more closely. The curviness of the true function <span class="math inline">\(f(x)\)</span> is echoed in the curviness of the splines, but some splines seem to try to connect the dots more than they are picking up the true trend. Because the splines follow the observed data more closely, the four functions show more variability from sample to sample than the linear regression lines.</p>
<p>Suppose the task is to develop a model that predicts a new observation well, one that did not participate in fitting the model. The model needs to generalize to previously unseen data. Should we choose linear regression or smoothing splines as our method? A method that is highly variable because it follows the data too closely will not generalize well—its predictions will be off because they are highly variable. A method that is not flexible enough also does not generalize well—its predictions will be off because the model is not correct.</p>
<p>Mathematically, we can express the problem of predicting a new observation as follows. Since the true function is unknown, it is also unknown at the new data location <span class="math inline">\(x_{0}\)</span>. However, we observed a value <span class="math inline">\(y\)</span> at <span class="math inline">\(x_{0}\)</span>. Based on the model we choose the function can be predicted at <span class="math inline">\(x_{0}\)</span>. But since we do not know the true function <span class="math inline">\(f(x)\)</span>, we can only measure the discrepancy between the value we observe and the value we predicted; this quantity is known as the error of prediction.</p>
<table class="table">
<caption>Components that contribute to bias and variance of an estimator. The last column designates whether the quantity can be measured in data science applications.</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 47%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Quantity</th>
<th>Meaning</th>
<th style="text-align: center;">Measurable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(f(x)\)</span></td>
<td>The true but unknown function</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="even">
<td><span class="math inline">\(f\left( x_{0} \right)\)</span></td>
<td>The value of the function at a data point <span class="math inline">\(x_0\)</span> that was not part of fitting the model</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span></td>
<td>The estimated value of the function at the new data point <span class="math inline">\(x_{0}\)</span></td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td><span class="math inline">\(f\left( x_{0} \right) - \widehat{f}\left( x_{0} \right)\)</span></td>
<td>The function discrepancy</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(y -\widehat{f}\left( x_{0} \right)\)</span></td>
<td>The error of prediction</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
<p>Multiple components contribute to the prediction error: the variability of the data <span class="math inline">\(y\)</span>, the discrepancy between <span class="math inline">\(f\left( x_{0} \right)\)</span> and <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span>, and the variability of the function <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span>. The variability of <span class="math inline">\(y\)</span> is also called the <strong>irreducible variability</strong> or the <strong>irreducible error</strong> because the observations will vary according to their natural variability. Once we have decided which attribute to observe, how to sample it, and how to measure it, this variability is a given. The other two sources relate to the <strong>accuracy</strong> and <strong>precision</strong> of the prediction; or, to use statistical terms, the bias and the variance.</p>
</section>
<section id="accuracy-and-precision" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="accuracy-and-precision"><span class="header-section-number">2.2</span> Accuracy and Precision</h2>
<p>In the context of measuring devices, accuracy and precision are defined as</p>
<ul>
<li><p><strong>Accuracy</strong>: How close are measurements to the true value</p></li>
<li><p><strong>Precision</strong>: How close are measurements to each other</p></li>
</ul>
<p>To demonstrate the difference between accuracy and precision, the dart board bullseye metaphor is helpful. The following figure shows four scenarios of shooting four darts each at a dart board. The goal is to hit the bullseye in the center of the board; the bullseye represents the true value we are trying to measure. <strong>A</strong> is the result of a thrower who is neither accurate nor precise. The throws vary greatly from each other (lack of precision), and the average location is far from the bullseye. <strong>B</strong> is the result of a thrower who is inaccurate but precise. The throws group tightly together (high precision) but the average location misses the bullseye (the average distance from the bullseye is not zero). The thrower with pattern <strong>C</strong> is not precise, but accurate. The throws vary widely (lack of precision) but the average distance of the darts from the bullseye is close to zero—on average the thrower hits the bullseye. Finally, the thrower in <strong>D</strong> is accurate and precise; the darts group tightly together and are centered around the bullseye.</p>
<div id="fig-dartboard" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dartboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Bullseye.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1"><img src="images/Bullseye.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dartboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Accuracy and precision—the dart board bullseye metaphor.
</figcaption>
</figure>
</div>
<p>We see that both accuracy and precision describe not a single throw, but a pattern over many replications. In statistical terms, this long-run behavior is the <strong>expected value</strong>.</p>
<p>What is the connection between accuracy and precision and expectations of random variables? The accuracy of a statistical estimator is the proximity of its expected value from the target value.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We use the term <em>target</em> here to describe the quantity we are interested in estimating. Please do not confuse this with the target variable in a statistical model. A function of the target variable such as its mean at <span class="math inline">\(x_0\)</span>, <span class="math inline">\(\text{E}[Y | x_0]\)</span> might well be the <em>target</em> we are trying to estimate.</p>
</div>
</div>
<p>An estimator that is not accurate is said to be <strong>biased</strong>.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Bias</p>
</div>
<div class="definition-container">
<p>An estimator <span class="math inline">\(h\left( \textbf{Y}\right)\)</span> of the parameter <span class="math inline">\(\theta\)</span> is said to be biased if its expected value does not equal <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\text{Bias}\left\lbrack h\left( \textbf{Y}\right);\theta \right\rbrack = \text{E}\left\lbrack h\left( \textbf{Y}\right) - \theta \right\rbrack = \text{E}\left\lbrack h\left( \textbf{Y}\right) \right\rbrack - \theta\]</span></p>
</div>
</div>
<p>The last equality in the definition follows because the expected value of a constant is identical to the constant. In the dartboard example, <span class="math inline">\(\theta\)</span> is the bullseye and <span class="math inline">\(h\left( \textbf{Y}\right)\)</span> is the distance of the dart from the bullseye. The bias is the expected value of that distance, the average across many repetitions (dart throws).</p>
</section>
<section id="mean-squared-error" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="mean-squared-error"><span class="header-section-number">2.3</span> Mean Squared Error</h2>
<p>With these definitions in place, let’s return to the question whether to favor the linear regression or the smoothing spline to predict a new observation at <span class="math inline">\(x_0\)</span>? The model can be written as</p>
<p><span class="math display">\[Y = f(x) + \epsilon\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> is a random variable with mean 0 and variance <span class="math inline">\(\sigma^{2}\)</span>, the irreducible variability. The observational model for <span class="math inline">\(n\)</span> observed data points is</p>
<p><span class="math display">\[Y_{i} = f\left( x_{i} \right) + \epsilon_{i}\ \ \ \ \ \ \ \ \ i = 1,\ldots,n\]</span></p>
<p>The <span class="math inline">\(Y_{i}\)</span> are observed unless there are missing values. However, for a new observation this might not be the case. The model for the new observation is no different than the previous model</p>
<p><span class="math display">\[Y_{0} = f\left( x_0 \right) + \epsilon\]</span></p>
<p>but only <span class="math inline">\(x_0\)</span> is known.</p>
<p>There are two possible targets for prediction: <span class="math inline">\(f\left( x_{0} \right)\)</span> and <span class="math inline">\(f\left( x_{0} \right) + \epsilon\)</span>. The former is the expected value of <span class="math inline">\(Y_{0}\)</span>: <span class="math display">\[\text{E}\left\lbrack Y_{0} \right\rbrack = f\left( x_0 \right) + \text{E}\lbrack\epsilon\rbrack = f\left( x_{0} \right)\]</span></p>
<p>This is a fixed quantity (a constant), not a random variable. The latter is a random variable. Interestingly, the estimator of both quantities is the same, <span class="math inline">\(\widehat{f}\left( x_0 \right)\)</span>. The difference comes into play when we consider the uncertainty associated with estimating <span class="math inline">\(f\left( x_0 \right)\)</span> or predicting <span class="math inline">\(f\left( x_0 \right) + \epsilon\)</span>—more on this later.</p>
<p>We need a way to express the discrepancy between the estimator and the target that incorporates the estimator’s accuracy and precision—this is the mean-squared error.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Mean-squared error (MSE)</p>
</div>
<div class="definition-container">
<p>The mean-squared error of estimator <span class="math inline">\(h\left( \textbf{Y}\right)\)</span> for target <span class="math inline">\(\theta\)</span> is the expected value of the squared differences between estimator and target</p>
<p><span class="math display">\[
    \text{MSE}\left\lbrack h\left( \textbf{Y}\right);\ \theta \right\rbrack = \text{E}\left\lbrack \left( h\left( \textbf{Y}\right) - \theta \right)^{2} \right\rbrack
\]</span></p>
</div>
</div>
<p>The mean-squared error is the expected square deviation between the estimator and its target. Expanding the right hand side and arranging terms we can write the MSE as the sum of two components</p>
<p><span class="math display">\[\begin{align*}
        \text{MSE}(h(\textbf{Y});\theta) &amp;= \text{E} \left [ \left( h(\textbf{Y}) - \theta \right)^2\right] \\
        &amp;= \text{E} \left [h(\textbf{Y})^2 - 2 h(\textbf{Y}) \theta + \theta^2\right ]\\
        &amp;= \text{E} \left [h(\textbf{Y})^2 - \mu^2 + \mu^2 - 2 h(\textbf{Y}) \theta + \theta^2\right ]\\
        &amp;= \text{E} \left [h(\textbf{Y})^2 \right ] - \mu^2  + \mu^2 - 2 \mu \theta + \theta^2 \\
        &amp;= \text{E} \left [h(\textbf{Y})^2 \right ] - \mu^2  + (\mu - \theta)^2 \\
        &amp;= \text{Var}[h(\textbf{Y})] + \text{Bias}(h(\textbf{Y});\theta)^2
\end{align*}\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>We use a common trick in the third line of this derivation, to add and subtract the same quantity: <span class="math inline">\(\mu^2\)</span>. This allows completion of the squares that lead to the variance and the squared bias terms.</p>
</div>
</div>
<p>The mean-squared error decomposes into the variance of the estimator, <span class="math inline">\(\text{Var}[h(\textbf{Y})]\)</span>, and the squared bias between the estimator and the target it is trying to estimate. The MSE equals the variance only if the estimator is unbiased. The bias enters in squared terms because the variance is measured in squared units and because negative and positive bias discrepancies should not balance out.</p>
<p>If we apply the MSE definition to the problem of using estimator <span class="math inline">\(\widehat{f}\left( x_0 \right)\)</span> to predict <span class="math inline">\(f\left( x_0 \right)\)</span>,</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right)\  \right\rbrack = \text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack + \text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack^{2}\]</span></p>
<p>we see how the variability of the estimator and its squared bias contribute to the overall MSE. Similarly, if the goal is to predict a new observation, rather than its mean, the expression becomes</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);Y_{0} \right\rbrack\text{ = MSE}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) + \epsilon\  \right\rbrack = \text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack + \text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack^{2} + \sigma^{2}\]</span></p>
<p>You now see why <span class="math inline">\(\sigma^{2}\)</span> is called the irreducible error. Even if the estimator <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span> would have no variability and be unbiased, the mean-squared error in predicting <span class="math inline">\(Y_{0}\)</span> can never be smaller than <span class="math inline">\(\sigma^{2}\)</span>.</p>
<div class="example">
<div class="example-header">
<p>Example: <span class="math inline">\(k\)</span>-Nearest Neighbor Regression</p>
</div>
<div class="example-container">
<p>The <span class="math inline">\(k\)</span>-nearest neighbor (<span class="math inline">\(k\)</span>-NN for short) regression estimator is a simple estimator of the local structure between a target variable <span class="math inline">\(y\)</span> and an input variable <span class="math inline">\(x\)</span>. The value <span class="math inline">\(k\)</span> represents the number of values in the neighborhood of some input <span class="math inline">\(x_{0}\)</span> that are used to predict <span class="math inline">\(y\)</span>. The extreme case is <span class="math inline">\(k = 1\)</span>, the value of <span class="math inline">\(f\left( x_{0} \right)\)</span> is predicted as the <span class="math inline">\(y\)</span>-value of the observation closest to <span class="math inline">\(x_{0}\)</span>.</p>
<p>Suppose our data come from a distribution with mean <span class="math inline">\(f(x)\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>. The mean-square error decomposition for the <span class="math inline">\(k\)</span>-NN estimator is then</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);Y_{0} \right\rbrack\text{ = }\frac{\sigma^{2}}{k}{+ \left\lbrack f\left( x_{0} \right) - \frac{1}{k}\sum_{}^{}Y_{(i)} \right\rbrack}^{2} + \sigma^{2}\]</span></p>
<p>where <span class="math inline">\(y_{(i)}\)</span> denotes the <span class="math inline">\(k\)</span> observations in the neighborhood of <span class="math inline">\(x_{0}\)</span>.</p>
<p>The three components of the MSE decomposition are easily identified:</p>
<ol type="1">
<li><p><span class="math inline">\(\sigma^{2}/k\)</span> is the variance of the estimator, <span class="math inline">\(\text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack\)</span>. Not surprisingly, it is the variance of the sample mean of <span class="math inline">\(k\)</span> observations drawn at random from a population with variance <span class="math inline">\(\sigma^{2}\)</span>.</p></li>
<li><p><span class="math inline">\(\left\lbrack f\left( x_{0} \right) - \frac{1}{k}\sum Y_{(i)} \right\rbrack^{2}\)</span> is the squared bias component of the MSE.</p></li>
<li><p><span class="math inline">\(\sigma^2\)</span> is the irreducible error, the variance in the population from which the data are drawn.</p></li>
</ol>
<p>While we cannot affect the irreducible error <span class="math inline">\(\sigma^{2}\)</span>, we can control the magnitude of the other components through the choice of <span class="math inline">\(k\)</span>. The variance contribution will be largest for <span class="math inline">\(k = 1\)</span>, when prediction relies on only the observation closest to <span class="math inline">\(x_{0}\)</span>. The bias contribution for this 1-NN estimator is <span class="math inline">\(\left\lbrack f\left( x_{0} \right) - Y_{(1)} \right\rbrack^{2}\)</span>.</p>
<p>As <span class="math inline">\(k\)</span> increases, the variance of the estimator decreases. For a large enough value of <span class="math inline">\(k\)</span>, all observations are included in the “neighborhood” and the estimator is equal to <span class="math inline">\(\overline{Y}\)</span>. If <span class="math inline">\(f(x)\)</span> changes with <span class="math inline">\(x\)</span>, the nearest neighbor method will then have smallest variance but large bias.</p>
</div>
</div>
<p>If we want to minimize the mean-squared error, we can strive for estimators with low bias and low variance. If we cannot have both, how do we balance between the bias and variance component of an estimator? That is the bias-variance tradeoff.</p>
<p>Statisticians resolve the tension with the <strong>UMVUE</strong> principle. Uniformly minimum-variance unbiased estimation requires to first identify unbiased estimators, those for which <span class="math inline">\(\text{Bias}\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \rbrack = 0\)</span>, and then to select the estimator with the smallest variance among the unbiased estimators. According to UMVUE you will never consider a biased estimator. It is comforting to know that on average the estimator will be on target. This principle would select estimator <strong>C</strong> in the dartboard example over estimator <strong>B</strong> because the latter is biased. If you have only one dart left and you need to get as close to the bullseye as possible, would you ask player <strong>B</strong> or player <strong>C</strong> to take a shot for the team?</p>
<p>UMVU estimators are not necessarily minimum mean-squared error estimators. It is possible that a biased estimator has a sharply reduced variance so that the sum of variance and squared bias is smaller than the variance of the best unbiased estimator. If we want to achieve a small mean-square error, then we should consider estimators with some bias and small variance. Resolving the bias-variance tradeoff by eliminating all biased estimators does not lead to the “best” predictive models. Of course, this depends on our definition of “best”.</p>
<p>In practice, <span class="math inline">\(f\left( x_{0} \right)\)</span> is not known and the bias component <span class="math inline">\(\text{Bias}\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \rbrack\)</span> cannot be evaluated by computing the difference of expected values. For many modeling techniques we can calculate—or at least estimate— <span class="math inline">\(\text{Var}\lbrack \widehat{f}\left( x_{0} \right) \rbrack\)</span>, the variance component of the MSE. Those derivations depend on strong assumptions about distributional properties and the correctness of the model. So, we essentially need to treat the MSE as an unknown quantity. Fortunately, we can estimate it from data.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Mean-squared prediction error (MSPE)</p>
</div>
<div class="definition-container">
<p>The mean-squared prediction error (MSPE) is the average squared prediction error in a sample of <span class="math inline">\(n\)</span> observations,</p>
<p><span class="math display">\[\text{MSPE} = \frac{1}{n}\sum_{i=1}^n\left( y_i - \widehat{f}\left( x_i \right) \right)^{2}\]</span></p>
</div>
</div>
<p>Taking the sample average replaces taking formal expectations over the distribution of <span class="math inline">\(( Y - \widehat{f}(x) )^2\)</span>.</p>
<p>Back to choosing between the regression and spline models. If we denote the two approaches <span class="math inline">\(\widehat{f}_{r}(x)\)</span> and <span class="math inline">\(\widehat{f}_{s}(x)\)</span>, respectively, selecting the winning model based on the mean-squared prediction error reduces to picking the model with the smaller MSPE:</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{f}}_{r}\left( x_{i} \right) \right)^{2}\]</span></p>
<p>or</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{f}}_{s}\left( x_{i} \right) \right)^{2}\]</span></p>
<p>As we will see, this is not without problems. These expressions are calculating the MSPE by averaging over the data points used in training the model; we call this the MSPE of the training set or MSE<sub>Tr</sub> for short. To identify models that generalize well to new observations, it is recommended to calculate the MSPE across a test set of observations that was not used to fit the model; this is called the MSPE of the test set or the MSE<sub>Te</sub> for short.</p>
<p>We will discuss training, test, and validation data sets in more detail below.</p>
<p>Whether you are working with MSPE in a regression context or MCR in a classification problem, the goal is to develop a model that is neither too complex nor too simple. We want to avoid over- and underfitting the model.</p>
</section>
<section id="overfitting-and-underfitting" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="overfitting-and-underfitting"><span class="header-section-number">2.4</span> Overfitting and Underfitting</h2>
<p>The preceding discussion might suggest that flexible models such as the smoothing spline have high variability and that rigid models such as the simple linear regression model have large bias. This generalization does not necessarily hold although in practice it often works out this way. The reason for this is not that simple linear regression models are biased—they can be unbiased. The reason why flexible models tend to have high variance and low bias and rigid models tend to have low variance and high bias has to do with <strong>overfitting</strong> and <strong>underfitting</strong>.</p>
<p>An overfit model follows the observed data <span class="math inline">\(Y_{i}\)</span> too closely and does not capture the mean trend <span class="math inline">\(f(x)\)</span>. The overfit model memorizes the training data too much. When you predict a new observation with an overfit model that memory causes high variability. Remember that the variability we are focusing on here is the variability across repetitions of the sample process. Imagine drawing 1,000 sets of <span class="math inline">\(n\)</span> observations, repeating the model training and predicting from each model at the new location <span class="math inline">\(x_{0}\)</span>. We now have 1,000 predictions at <span class="math inline">\(x_{0}\)</span>. Because the overfit model follows the training data too closely, its predictions will be variable at <span class="math inline">\(x_{0}\)</span>.</p>
<p>An underfit model, on the other hand, lacks the flexibility to capture the mean trend <span class="math inline">\(f(x)\)</span>. Underfit models result, for example, when important predictor variables are not included in the model.</p>
<p>The most extreme case of overfitting a model is the <strong>saturated</strong> model. It perfectly predicts the observed data. Suppose you collect only two pairs of <span class="math inline">\((x,y)\)</span> data: (1,0) and (2,1). A two-parameter straight line model will fit these data perfectly. The straight line has an intercept of –1 and a slope of +1. It passes through the observed points and the mean-squared prediction error is zero.</p>
<div id="fig-saturated" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-saturated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Saturated.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-saturated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: A straight line model saturates a data set with two $(x,y)$ pairs. The difference between observed values (the dots) and the predicted values (values on the line) is zero at each point. The saturated model has a MSPE of zero.
</figcaption>
</figure>
</div>
<p>Saturated models are not very interesting, they are just a re-parameterization of the data, capturing both signal <span class="math inline">\(f(x)\)</span> <strong>and</strong> noise <span class="math inline">\(\epsilon\)</span>. A useful model separates the signal from the noise. Saturated models are used behind the scenes of some statistical estimation methods, for example to measure how much of the variability in the data is captured by a model—this type of model metric is known as the deviance. Saturated models are never the end goal of data analytics.</p>
<p>On the other extreme lies the constant model; it does not use any input variables. It assumes that the mean of the target variable is the same everywhere:</p>
<p><span class="math display">\[Y_{i} = \mu + \epsilon_{i}\]</span></p>
<p>This model, also known as the intercept-only model, is slightly more useful than the saturated model. It is rarely the appropriate model in data science applications; it expresses the signal as a flat line, the least flexible model of all.</p>
<p>In our discussion of the model building process during the data science project life cycle we encountered an example of pharmacokinetic data, 500 observations on how a drug is absorbed and eliminated by the body over time (<span class="math inline">\(t\)</span>). The data are replayed in the next figure along with the fit of the constant model. The constant model underpredicts the drug concentration between times <span class="math inline">\(t = 3\)</span> and <span class="math inline">\(t = 12\)</span> and overpredicts everywhere else.</p>
<div id="fig-underfit-model" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-underfit-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Underfit.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-underfit-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: Concentration of a drug in patient’s bodies over time.
</figcaption>
</figure>
</div>
<p>Suppose we draw 1,000 sets of <span class="math inline">\(n = 500\)</span> observations, fit the constant model to each, and predict at the new time <span class="math inline">\(t_{0}\)</span>. Because the constant model does not depend on time, we get the same predicted value regardless of the value of <span class="math inline">\(t_{0}\)</span>. In each sample of size <span class="math inline">\(n\)</span>, the predicted value will be the sample mean, <span class="math inline">\(\overline{y} = \frac{1}{500}\sum_{}^{}y_{i}\)</span>. The variability of the 1,000 predictions will be small; it is the variance of the sample mean:</p>
<p><span class="math display">\[\text{Var}\left\lbrack \widehat{f}\left( x_0 \right) \right\rbrack = \frac{\sigma^2}{500}\]</span></p>
<p>If the true model does depend on <span class="math inline">\(t\)</span>—and the plot of the data suggests this is the case—the bias of the predictions will be large. The mean-squared prediction error is dominated by the squared bias component in this case.</p>
<p>Somewhere between the two extremes of a hopelessly overfit saturated model and a hopelessly underfit constant model are models that capture the signal <span class="math inline">\(f(x)\)</span> well enough without chasing the noisy signal <span class="math inline">\(f(x) + \epsilon\)</span> too much. Those models permit a small amount of bias if that results in a reduction of the variance of the predictions.</p>
<p>To summarize,</p>
<ul>
<li><p><strong>Overfit</strong> models do not generalize well because they follow the training data too closely. They tend to have low bias and a large variance.</p></li>
<li><p><strong>Underfit</strong> models do not generalize well because they do not capture the salient trend (signal) in the data. They tend to have high bias and low variance.</p></li>
<li><p>A large mean-squared prediction error can result in either case but is due to a different cause.</p></li>
<li><p>For a small mean-squared prediction error you need to have small bias and small variance.</p></li>
<li><p>In practice, zero-bias methods with high variance are rarely the winning approaches. The best MSPE is often achieved by allowing some bias to substantially decrease the variance.</p></li>
</ul>
<p>The danger of overfitting is large when models contain many parameters, and when the number of parameters <span class="math inline">\(p\)</span> is large relative to the sample size <span class="math inline">\(n\)</span>. When many attributes (inputs) are available and you throw them all into the model, the result will likely be an overfit model that does not generalize well. It will have a large prediction error. In other words, there is a cost to adding unimportant information to a model. Methods for dealing with such high-dimensional problems play an important role in statistics and machine learning and are discussed in detail in a more advanced section. We mention here briefly:</p>
<ul>
<li><p><strong>Feature Selection</strong>: Structured approaches that use algorithms to determine which subset of the inputs should be in the model. The decision is binary in that an input is either included or excluded. Also known as variable selection.</p></li>
<li><p><strong>Regularization</strong>: Deliberately introducing some bias in the estimation through penalty terms that control the variability of the model parameters which in turn controls the variability of the predictions. The parameters are shrunk toward zero in absolute value compared to an unbiased estimator—regularization is thus also known as <strong>shrinkage estimation</strong>. The Lasso methods can shrink parameters to zero and thus combines regularization with feature selection. The Ridge regression methods also applies a shrinkage penalty but allows all inputs to contribute.</p></li>
<li><p><strong>Ensemble Methods</strong>: Ensemble methods combine multiple methods into an overall, averaged prediction or classification. Ensembles can be homogeneous, where the methods are the same, or heterogeneous. An example of a homogeneous ensemble is a bagged decision tree, where several hundred individual trees are trained independently and the predictions from the trees are averaged to obtain an overall predicted value. Due to averaging, the variance of the ensemble estimator is smaller than any individual estimator. <strong>Bagging</strong> and <strong>boosting</strong> are common ensemble methods to reduce variance.</p></li>
</ul>
</section>
<section id="sec-train-test-validate" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-train-test-validate"><span class="header-section-number">2.5</span> Training, Testing, and Validation</h2>
<p>Training, testing, and validation refers to different stages of the model building process and also to different types of data used in the model building process.</p>
<section id="training-data" class="level3">
<h3 class="anchored" data-anchor-id="training-data">Training Data</h3>
<p>Training data is the set of <span class="math inline">\(n\)</span> observations used to train the model. The training data is useful to diagnose whether model assumptions are met, for example,</p>
<ul>
<li><p>does the model adequately describe the mean trend in the (training) data,</p></li>
<li><p>are distributional assumptions such as normality of the model errors met,</p></li>
<li><p>is it reasonable to assume that the data points are uncorrelated (or even independent)</p></li>
</ul>
<p>We can also use the <strong>training data</strong> after the model fit to detect data points that have a high influence of the analysis—that is, the presence of those points substantially affects an important aspect of the model. And based on the training data we can study the interdependence of the model inputs and whether those relationships affect the model performance negatively.</p>
<p>The diagnostic techniques just mentioned rely on</p>
<ul>
<li><p>Residual diagnostics</p></li>
<li><p>Case-deletion and influence diagnostics</p></li>
<li><p>Collinearity diagnostics</p></li>
</ul>
<p>These diagnostics are all very helpful, but they do not answer an important question: how well does the model generalize to observations not used in training the model; how well does the model predict new observations? We also need to figure out, given a single training data set, how to select the values for the <strong>hyperparameters</strong> of the various techniques.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Hyperparameter</p>
</div>
<div class="definition-container">
<p>A <strong>hyperparameter</strong> is a variable that controls the overall configuration of a statistical model or machine learning technique. Hyperparameters are sometimes referred to as external parameters, whereas the parameters of the model function (slopes, intercepts, etc.) are called the internal parameters.</p>
</div>
</div>
<p>Hyperparameters are not directly derived from the data, they need to be set to values before the model can be trained; their values can greatly impact the performance of the model. The process of determining the values for hyperparameters given a particular data set is called <strong>hyperparameter tuning</strong>.</p>
<p>Hyperparameters include, for example,</p>
<ul>
<li><p>The number of terms in a polynomial model</p></li>
<li><p>The smoothing parameters in non-parametric regression models</p></li>
<li><p>The bandwidth in kernel-based estimation methods such as LOESS, kernel regression, local polynomial regression</p></li>
<li><p>The shrinkage penalty in Lasso, Ridge regression, smoothing splines</p></li>
<li><p>The depth of decision trees</p></li>
<li><p>The number <span class="math inline">\(k\)</span> in <span class="math inline">\(k\)</span>-nearest neighbor methods</p></li>
<li><p>The convergence rate and other tolerances in numerical optimization</p></li>
<li><p>The learning rate, number of nodes, and number of layers in neural networks</p></li>
</ul>
<p>We can calculate the MSPE or MCR of the trained model, depending on whether we are dealing with a regression or a classification problem. Doing so for the training data has some serious drawbacks. We have seen earlier that saturated models have no prediction error since they perfectly connect the dots in the data. Trying to minimize the MSPE based on the training data (MSE<sub>Tr</sub>) invariably leads to overfit models since you can always drive MSE<sub>Tr</sub> toward zero.</p>
</section>
<section id="test-data" class="level3">
<h3 class="anchored" data-anchor-id="test-data">Test Data</h3>
<p>To measure the true predictive performance of a model we need to apply the model to a different set of observations; a set that was not used in training the model. This set of observations is called the <strong>test data</strong> set. With a test data set we can measure how well the model generalizes and we can also use it to select the appropriate amount of flexibility of the model. The following graph shows the general behavior of test and train mean-squared prediction error as a function of model flexibility and complexity.</p>
<p>The MSPE of the test data set is on average higher than the MSPE of the training data set. Since these are random variables, it can happen in a particular application that the test error is lower than the training error, but this is rare. The model complexity/flexibility is measured here by the number of inputs in the model. As this number increases, the MSE<sub>Tr</sub> decreases toward zero. The MSE<sub>Te</sub>, on the other hand, first decreases, reaches a minimum, and increases again. The MSE<sub>Te</sub> is high for models with few parameters because of bias, it increases with model flexibility past the minimum because of variability. The two contributors to the MSE work at different ends of the spectrum—you find models that balance bias and variance somewhere in-between.</p>
<div id="fig-train-test-error" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-train-test-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSETe_MSE_Tr.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-train-test-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: MSETr and MSETe as a function of model flexibility (complexity).
</figcaption>
</figure>
</div>
<p>The big question is: where do we get the test data?</p>
</section>
<section id="validation-data" class="level3">
<h3 class="anchored" data-anchor-id="validation-data">Validation Data</h3>
<p>Before discussing ways to obtain test data sets, a few words about another type of data set, the <strong>validation data</strong>. The terms test data and validation data are often used interchangeably, but there is a difference. Test data represents new data that should otherwise be representative of the training data. A test data set drawn at random from the training data set typically satisfies that.</p>
<p>Validation data can be a separate data set with known properties, for example, a benchmark data set. Such a data set can be used to compare approaches from different model families, for example, a random forest and a neural network. It can be used to measure model performance against known conditions (typical and atypical) to ensure a model works properly.</p>
<div class="example">
<div class="example-header">
<p>Example: Computer Vision</p>
</div>
<div class="example-container">
<p><a href="https://www.image-net.org/">ImageNet</a> is a data set of images organized according to the WordNet hierarchy. ImageNet provides an average of 1,000 images for each meaningful concept in WordNet. The data set is used as a benchmark for object categorization algorithms and currently contains over 14 million images that are labeled and annotated by humans.</p>
<p>The most used subset of ImageNet data is the Large Scale Visual Recognition Challenge (ILSVRC) data set. It is used to evaluate object classification algorithms since 2010. The data sets for the challenges are themselves broken down into training, test, and validation sets.</p>
<p>The IARPA Janus Benchmark (IJB) datasets contain images and videos used in face detection and face recognition challenges. There are several data sets, for example IJB-B consists of 1,845 subjects with human-labeled face bounding boxes, eye &amp; nose location, and metadata such as skin tone and facial hair for 21,798 still images and 55,026 video frames. The collection methodology for the IJB-B data set is documented .</p>
</div>
</div>
<p>Test data tells us how well a model performs, validation data tells us which model is best.</p>
<div class="example">
<div class="example-header">
<p>Example: Programming Competition</p>
</div>
<div class="example-container">
<p>Suppose we want to send one student from a group of students to a programming competition. The goal is to win the competition. In <strong>training</strong> the students encounter problems from past programming competitions.</p>
<p>Students that do well during training are not necessarily the best candidates for the competition. We need to find out whether a student does well because they memorized the solution or whether they truly understand how to solve the programming problem. To answer this a <strong>validation</strong> step is used and a set of new programming problems is presented, specifically designed to test student’s ability to apply general concepts in problem solving. At the end of the validation step we have identified the best student to represent the group at the competition.</p>
<p>We are not done, however. Does the best student in the group have a chance in the competition? We now enter the <strong>testing</strong> phase to answer the question: how well will the best student perform? After administering a real test with new problems, we find out that the student scores above 90%: they are ready for the competition. If, however, we find out that the student scores below 25%, we will not send them to the competition. Instead, we return to the drawing board with a new training procedure and/or a set of new training problems.</p>
</div>
</div>
<p>Validation and test data are often used interchangeably because the test data <strong>is</strong> often used as the validation data. The questions “which model is best?” and “how well does the model perform?” are answered simultaneously: the best model is the one that achieves the best metric on the test data set. Often that results in choosing the model with the lowest MSE<sub>Te</sub> or MCR<sub>Te</sub>.</p>
</section>
<section id="hold-out-sample" class="level3">
<h3 class="anchored" data-anchor-id="hold-out-sample">Hold-out Sample</h3>
<p>Let’s return to the important question: where do we find the test data set?</p>
<p>Maybe you just happen to have a separate set of data lying around that is just like the training data, but you did not use it. Well, that is highly unlikely.</p>
<p>Typically, we use the data collected, generated, or available for the study to carve out observations for training and testing. This is called a <strong>hold-out sample</strong>, a subset of the observations is held back for testing and validation. If we start with <span class="math inline">\(n\)</span> observations, we use <span class="math inline">\(n - m\)</span> observation to train the model (the training data set), and <span class="math inline">\(m\)</span> observations to test/validate the model.</p>
<p>In Python you can create this train:test split with the train_test_split() function in sklearn. The following statements load the fitness data from DuckDB into a Pandas DataFrame and split it into two frames of 15 and 16 observations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>con <span class="op">=</span> duckdb.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"ads.ddb"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> con.sql(<span class="st">"SELECT * FROM fitness"</span>).df()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> train_test_split(fit,random_state<span class="op">=</span><span class="dv">235</span>,train_size<span class="op">=</span><span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>random_state=</code> parameter sets the seed for the random number generator. By setting this to a non-zero integer, the random number generator starts to produce numbers with that seed value. This makes the selection reproducible, subsequent runs of the program will produce identical—yet random—results. The <code>train_size=</code> parameter specifies the proportion of observations in the training set—if the value is between 0 and 1—or the number of observations in the training set—if the value is an integer &gt; 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>train.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(15, 7)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Age     Weight     Oxygen  ...  RestPulse   RunPulse    MaxPulse
count  15.000000  15.000000  15.000000  ...  15.000000   15.00000   15.000000
mean   49.666667  75.539333  47.693067  ...  52.733333  171.00000  174.133333
std     4.654747   8.076112   4.516180  ...   7.731814   10.96097    9.210760
min    40.000000  59.080000  39.203000  ...  40.000000  148.00000  155.000000
25%    48.000000  70.760000  45.215500  ...  48.000000  166.00000  169.000000
50%    51.000000  76.320000  46.672000  ...  51.000000  170.00000  172.000000
75%    53.000000  80.400000  49.772000  ...  58.500000  178.00000  180.500000
max    57.000000  91.630000  59.571000  ...  67.000000  186.00000  188.000000

[8 rows x 7 columns]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>test.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(16, 7)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>test.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Age     Weight     Oxygen  ...  RestPulse    RunPulse    MaxPulse
count  16.000000  16.000000  16.000000  ...  16.000000   16.000000   16.000000
mean   45.812500  79.230625  47.078375  ...  54.125000  168.375000  173.437500
std     5.140931   8.415590   6.125977  ...   7.701731    9.721968    9.408994
min    38.000000  61.240000  37.388000  ...  45.000000  146.000000  155.000000
25%    43.750000  73.285000  43.665750  ...  48.000000  162.000000  167.500000
50%    44.500000  80.170000  47.023500  ...  53.500000  169.000000  174.000000
75%    48.500000  86.295000  50.040750  ...  59.000000  174.500000  180.000000
max    57.000000  91.630000  60.055000  ...  70.000000  186.000000  192.000000

[8 rows x 7 columns]</code></pre>
</div>
</div>
<p>The two data sets have very similar properties as judged by the descriptive statistics. If the goal is to develop a model that can predict the difficult to measure oxygen intake from easy to measure attributes such as age, weight, and pulse, then we would use the 15 observations in the <code>train</code> frame to fit the model and the 16 observations in the <code>test</code> frame to evaluate the model.</p>
<p>If we cull the test data from the overall data, how should we determine an appropriate size for the test data? The previous example used a 50:50 split, would it have mattered if we had taken a 20:80 or a 90:10 split? For the two data sets to serve their respective functions, you need enough observations in the training data set to fit the model well enough so it can be tested, and you need enough observations in the test data set to produce a stable estimate of MSE<sub>Te</sub>. In practice splits that allocate between 50 and 90% of the observations to the training data set are common.</p>
<p>With small training proportions you run the risk that the model cannot be fit and/or that the data does not support the intended model. For example, with a 10:90 train:test split in the fitness example, the training data contains only 3 observations and evaluating the effect of all input variables on oxygen intake is not possible—the model is saturated after three inputs are in the model. With categorical inputs, you need to make sure that the training and test data sets contain all the categories. For example, if you categorize age into four age groups and only three groups are present in the training data after the split, the resulting model no longer applies to a population with four age groups.</p>
<p>From this discussion we can glean the general advantages and disadvantages of hold-out test samples.</p>
<table class="table">
<caption>Advantages and disadvantages of hold-out samples generated by random train:test splits.</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Easy to do</td>
<td>Involves a random selection; results change depending on which observations selected</td>
</tr>
<tr class="even">
<td>No separate test data set needed</td>
<td>Potentially large variability from run to run, especially for noisy data</td>
</tr>
<tr class="odd">
<td>A general method that can be applied regardless of how model performance is measured</td>
<td>Must decide how large to make the training (test) set</td>
</tr>
<tr class="even">
<td>Reproducible if fixing random number seed</td>
<td>An observation is used either for testing or for training</td>
</tr>
<tr class="odd">
<td></td>
<td>Tends to overestimate the test error compared to cross-validation methods</td>
</tr>
</tbody>
</table>
<p>The last two disadvantages in the table weigh heavily. Since we cannot rely on the training error for model selection, we are <em>sacrificing</em> observations by excluding them from training. At least we expect then a good estimate of the test error. The reason for overestimating the true test error with a train:test hold-out sample is that models tend to perform worse when trained on fewer observations. Reducing the size of the training data set results in less precise parameter estimates which in turn increases the variability of predictions.</p>
<p>To compare the variability of the hold-out sample method with other techniques, we draw on the Auto data set from ISLR2 (An Introduction to Statistical Learning by James et al.). The data comprise information on fuel mileage and other vehicle attributes of 392 automobiles. Suppose we want to model mileage as a function of horsepower. The next figure shows the raw data and fits of a linear and quadratic model</p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_{1}\text{hp}_{i} + \epsilon_{i}\]</span></p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_{1}\text{hp}_{i} + {\beta_{2}\text{hp}_{i}^{2} + \epsilon}_{i}\]</span></p>
<div id="fig-auto-linquad" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-linquad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_lin_quad.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-linquad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Simple linear and quadratic polynomial fit for miles per gallon versus horsepower in Auto data set.
</figcaption>
</figure>
</div>
<p>A simple linear regression—the red line in the figure—does not seem appropriate. The model does not pick up the curvature in the underlying trend. A quadratic model seems more appropriate. Can this be quantified? What about a cubic model</p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_{1}\text{hp}_{i} + {\beta_{2}\text{hp}_{i}^{2} + \beta_{3}\text{hp}_{i}^{3} + \epsilon}_{i}\]</span></p>
<p><a href="#fig-auto-valid1" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> shows the hold-out test errors for all polynomial models up to degree 10. The simple linear regression (SLR) model has degree 1 and is shown on the left. The test error is large for the SLR model and for the 10-degree polynomial. The former is biased as can be seen from the previous graph. The latter is too wiggly and leads to a poor test error because of high variability. The test error is minimized for the quadratic model but we note that the test error is also low for degrees 7—9.</p>
<div id="fig-auto-valid1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-valid1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_valid1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-valid1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: Hold-out test errors for polynomial models from first to tenth degree. The horizontal line marks the minimum, achieved at degree 2.
</figcaption>
</figure>
</div>
<p>Based on this result we would probably choose the second-degree polynomial. To what extent is this decision the result of having selected the specific 196 observations in the 50:50 split? We can evaluate this by repeating the sampling process a few more times. The next graph shows the results of 9 other 50:50 random splits.</p>
<p>The variability in the results is considerable. Most replications would select a second-degree polynomial as the model with the lowest MSE<sub>Te</sub>, but several replications achieve a smallest MSE<sub>Te</sub> for much higher degree polynomials (5<sup>th</sup> degree, 7<sup>th</sup> degree, etc.).</p>
<div id="fig-auto-valid10" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-valid10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_valid10.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-valid10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: Test errors in ten hold-out samples, 50:50 splits. The errors from the previous graph are shown in red.
</figcaption>
</figure>
</div>
<p>Having spent time, energy, resources, money to build a great data set, it seems wasteful to use some observations only for training and the others only for testing. Is there a way in which we can use all observation for training and testing and still get a good estimate (maybe even a better estimate) of the test error?</p>
<p>How about the following proposal:</p>
<ul>
<li><p>Split the data 50:50 into sets <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span></p></li>
<li><p>Use <span class="math inline">\(t_1\)</span> as the training data set and determine the mean-squared prediction error from <span class="math inline">\(t_{2}\)</span>, call this MSE<sub>Te</sub>(<span class="math inline">\(t_{2}\)</span>)</p></li>
<li><p>Reverse the roles of <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>, using <span class="math inline">\(t_2\)</span> to train the model and <span class="math inline">\(t_1\)</span> to compute the test error MSE<sub>Te</sub>(<span class="math inline">\(t_1\)</span>)</p></li>
<li><p>Compute the overall test error as the average MSE<sub>Te</sub> = 0.5 x (MSE<sub>Te</sub>(<span class="math inline">\(t_1\)</span>) + MSE<sub>Te</sub>(<span class="math inline">\(t_2\)</span>))</p></li>
</ul>
<p>Each observation is used once for training and once for testing. Because of averaging, the combined estimate of test error is more reliable than the individual test errors.</p>
<p>This proposal describes a special case of <strong>cross-validation</strong>, namely 2-fold cross-validation.</p>
</section>
</section>
<section id="sec-cross-validation" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="sec-cross-validation"><span class="header-section-number">2.6</span> Cross-validation</h2>
<p>Cross-validation is a general method to measure the performance of a model. It is commonly used for predictive models to evaluate how well a model generalizes to new observations, but it can also be used to, for example, select hyperparameters. Cross-validation extends the concept of the hold-out sample to address the drawbacks of train:test splits. It is also general in that you are not limited to MSE or MCR as performance measurements. So, first, a few words about loss functions.</p>
<section id="loss-functions" class="level3">
<h3 class="anchored" data-anchor-id="loss-functions">Loss Functions</h3>
<div class="definition">
<div class="definition-header">
<p>Definition: Loss function</p>
</div>
<div class="definition-container">
<p>A <strong>loss function</strong> or <strong>cost function</strong> maps an event to a real number that reflects some loss or cost incurred from the event.</p>
<p>In data analytics, loss functions measure the discrepancy between observed and predicted values and the losses are typically referred to as <em>errors</em>.</p>
</div>
</div>
<p>The following table displays common loss functions in data science.</p>
<table class="table">
<caption>Loss functions common in data science applications. <span class="math inline">\(y\)</span> and <span class="math inline">\(\widehat{y}\)</span> denote observed and predicted value, respectively.<span class="math inline">\(\widehat{p}_j\)</span> denotes the sample proportion in category <span class="math inline">\(j\)</span> of a classification problem with <span class="math inline">\(k\)</span> categories.</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 48%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Loss Function</th>
<th style="text-align: center;">Expression</th>
<th>Application Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Squared Error</td>
<td style="text-align: center;"><span class="math inline">\(\left( y - \widehat{y} \right)^{2}\)</span></td>
<td>Regression with continuous response</td>
</tr>
<tr class="even">
<td>Zero-one (0—1)</td>
<td style="text-align: center;"><span class="math inline">\(I\left( y \neq \widehat{y} \right)\)</span></td>
<td>Classification</td>
</tr>
<tr class="odd">
<td>Absolute Value</td>
<td style="text-align: center;"><span class="math inline">\(\left| y - \widehat{y} \right|\)</span></td>
<td>Robust regression</td>
</tr>
<tr class="even">
<td>Misclassification</td>
<td style="text-align: center;"><span class="math inline">\(1 - \max_{j}{\widehat{p}}_{j}\)</span></td>
<td>Pruning of decision trees</td>
</tr>
<tr class="odd">
<td>Gini Index</td>
<td style="text-align: center;"><span class="math inline">\(\sum_{j = 1}^{k}{{\widehat{p}}_{j}\left( 1 - {\widehat{p}}_{j} \right)}\)</span></td>
<td>Growing of decision trees, neural networks</td>
</tr>
<tr class="even">
<td>Cross-entropy (deviance)</td>
<td style="text-align: center;"><span class="math inline">\(- 2\sum_{j = 1}^{k}{{n_{j}\log}{\widehat{p}}_{j}}\)</span></td>
<td>Growing of decision trees, neural networks</td>
</tr>
<tr class="odd">
<td>Entropy</td>
<td style="text-align: center;"><span class="math inline">\(- \sum_{j = 1}^{k}{{\widehat{p}}_{j}\log{\widehat{p}}_{j}}\)</span></td>
<td>Growing of decision trees</td>
</tr>
</tbody>
</table>
<p>Squared error and zero-one loss dominate data science work in regression and classification problems. For specific methods you will find additional loss functions used to optimize a particular aspect of the model, for example, growing and pruning of decision trees.</p>
<p>Suppose the loss associated with an observation is denoted <span class="math inline">\(\mathcal{l}_{i}\)</span>. Cross-validation estimates the average loss for each of <span class="math inline">\(k\)</span> sets of observations and averages the <span class="math inline">\(k\)</span> estimates into an overall cross-validation estimate of the loss.</p>
<p>Suppose we create two random sets of (near) equal size for the 31 observations in the fitness data set; <span class="math inline">\(k = 2\)</span>. The sets will have <span class="math inline">\(n_1 = 15\)</span> and <span class="math inline">\(n_2 = 16\)</span> observations. This leads to one cross-validation estimate of the loss function for each set:</p>
<p><span class="math display">\[CV_1\left( \mathcal{l} \right) = \frac{1}{n_1}\sum_{i = 1}^{n_1}\mathcal{l}_{i}\]</span></p>
<p><span class="math display">\[CV_2\left( \mathcal{l} \right) = \frac{1}{n_2}\sum_{i = 1}^{n_1}\mathcal{l}_i\]</span></p>
<p>The overall cross-validation loss is the average of the two:</p>
<p><span class="math display">\[CV\left( \mathcal{l} \right) = \frac{1}{2}\left( CV_{1}\left( \mathcal{l} \right) + CV_{2}\left( \mathcal{l} \right) \right)\]</span></p>
<p>This is a special case of <span class="math inline">\(k\)</span>-fold cross-validation; the sets are referred to as folds. The other special case is leave-one-out cross-validation.</p>
</section>
<section id="k-fold-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="k-fold-cross-validation"><span class="math inline">\(K\)</span>-fold Cross-validation</h3>
<p>The set of <span class="math inline">\(n\)</span> observations is divided randomly into <span class="math inline">\(k\)</span> groups of (approximately) equal size. The groups are called the <span class="math inline">\(k\)</span> folds. The model is fit <span class="math inline">\(k\)</span> times, holding out a different fold each time. After computing the loss in each fold</p>
<p><span class="math display">\[{CV}_{j}\left( \mathcal{l} \right) = \frac{1}{n_{j}}\sum_{i = 1}^{n_{j}}\mathcal{l}_{i}\]</span></p>
<p>the overall loss is calculated as the average</p>
<p><span class="math display">\[CV\left( \mathcal{l} \right) = \frac{1}{k}\sum_{j = 1}^{k}{{CV}_{j}\left( \mathcal{l} \right)}\]</span></p>
<p><a href="#fig-cv-folds5" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> shows 5-fold cross-validation for <span class="math inline">\(n = 100\)</span> observations. The observations are randomly divided into 5 groups of 20 observations each. The model is trained five times. The first time around, observations in fold 1 serve as the test data set, folds 2—5 serve as the training data set. The second time around, fold 2 serves as the test data set and folds 1, 3, 4, and 5 are the training data set; and so forth. Each time, the average loss is calculated for the 20 observations not included in training. At the end, five average cross-validation losses are averaged to calculate the overall loss.</p>
<div id="fig-cv-folds5" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cv-folds5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/five_fold_CV.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2"><img src="images/five_fold_CV.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cv-folds5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.12: Example of 5-fold cross-validation for 100 observations. Numbers in the cells represent observation numbers. The records were randomly arranged prior to assigning the folds.
</figcaption>
</figure>
</div>
<table class="table">
<caption>Advantages and disadvantages of <span class="math inline">\(k\)</span>-fold cross-validation.</caption>
<colgroup>
<col style="width: 43%">
<col style="width: 38%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantgages</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Not as variable as the train:test hold-out sample</td>
<td>Still has a random element due to randomly splitting the data into <span class="math inline">\(k\)</span> sets</td>
<td></td>
</tr>
<tr class="even">
<td>Less bias in test error than train:test hold-out sample</td>
<td>Can be computationally intensive if the model must be fit <span class="math inline">\(k\)</span> times</td>
<td></td>
</tr>
<tr class="odd">
<td>Not as computationally intensive as leave-one-out cross-validation (see below)</td>
<td>Must decide on the number of folds</td>
<td></td>
</tr>
<tr class="even">
<td>Every observation is used for training (<span class="math inline">\(k - 1\)</span> times) and testing (once)</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Reproducible if fixing random number seed</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>A general method that can be applied regardless of how model performance is measured</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The most common values for <span class="math inline">\(k\)</span> found in practice are 5, 10, and <span class="math inline">\(n\)</span>. <span class="math inline">\(k = n\)</span> is a special case, called leave-one-out cross-validation; see below. Values of 5 and 10 have shown to lead to good estimates of loss while limiting the variability of the results. The averaging of the losses from the folds has a powerful effect of stabilizing the results.</p>
<p>For the Auto data set, the following figures show the results of repeating 5-fold and 10-fold cross-validation ten times. The results vary considerably less than the ten repetitions of the 50:50 hold-out sample in <a href="#fig-auto-valid10" class="quarto-xref">Figure&nbsp;<span>2.11</span></a>.</p>
<div id="fig-auto-cv5sim" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-cv5sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_5fold_sim.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-cv5sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.13: Ten repetitions of 5-fold cross-validation for polynomials of degree 1—10; Auto data set.
</figcaption>
</figure>
</div>
<div id="fig-auto-cv10sim" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-cv10sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_10fold_sim.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-cv10sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.14: Ten repetitions of 10-fold cross-validation for polynomials of degree 1—10; Auto data set.
</figcaption>
</figure>
</div>
<p>Also, the 10-fold cross-validation shows less variability than the 5-fold CV. This is the effect of averaging 10 quantities rather than 5. In other words, the effect of averaging the results from the folds is larger than the averaging of observations within the folds. But if training a model is computationally intensive, 5-fold cross-validation is a good solution.</p>
</section>
<section id="leave-one-out-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="leave-one-out-cross-validation">Leave-One-Out Cross-validation</h3>
<p>Abbreviated LOOCV, this method takes the random element out of selecting observations into the folds. Instead, each observation is used once as a test set of size 1 and the model is fit to the remaining <span class="math inline">\(n - 1\)</span> observations. The observation is put back and the next observation is removed from the training set.</p>
<p>LOOCV thus estimates the model <span class="math inline">\(n\)</span> times, each time removing one of the observations. It is a special case of <span class="math inline">\(k\)</span>-fold cross-validation where <span class="math inline">\(k = n\)</span>.</p>
<p>A pseudo-algorithm for LOOCV is as follows:</p>
<ul>
<li><p>Step 0: Set <span class="math inline">\(i = 1\)</span></p></li>
<li><p>Step 1: Set the index of the hold-out observation to <span class="math inline">\(i\)</span></p></li>
<li><p>Step 2. Remove observation <span class="math inline">\(i\)</span> and fit the model to the remaining <span class="math inline">\(n - 1\)</span> observations</p></li>
<li><p>Step 3. Compute the loss <span class="math inline">\(\mathcal{l}_i\)</span> for the held-out observation</p></li>
<li><p>Step 4. Put the observation back into the data. If <span class="math inline">\(i = n\)</span>, go to Step 5. Otherwise, increment <span class="math inline">\(i\)</span> and return to Step 1.</p></li>
<li><p>Step 5. Compute the LOOCV loss as the average of the <span class="math inline">\(n\)</span> losses: <span class="math inline">\(CV\left( \mathcal{l} \right) = \frac{1}{n}\sum_{i} mathcal{l}_i\)</span></p></li>
</ul>
<table class="table">
<caption>Advantages and disadvantage of leave-one-out cross-validation.</caption>
<colgroup>
<col style="width: 29%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No randomness involved. Identical results upon repetition.</td>
<td>Can become computationally intensive if fitting a model is expensive and no closed-form expressions (or approximations) are available to compute the loss per observation based on a single fit</td>
</tr>
<tr class="even">
<td>Every observation is used in training (<span class="math inline">\(n - 1\)</span> times) and in testing (once)</td>
<td></td>
</tr>
<tr class="odd">
<td>A general method that can be applied to any loss function and model</td>
<td></td>
</tr>
<tr class="even">
<td>Good estimate of test error</td>
<td></td>
</tr>
</tbody>
</table>
<p>The results of LOOCV for the Auto data set are shown in <a href="#fig-auto-loocv" class="quarto-xref">Figure&nbsp;<span>2.15</span></a>. LOOCV selects the seventh-degree polynomial.</p>
<div id="fig-auto-loocv" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-auto-loocv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_Loocv.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-auto-loocv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.15: Leave-one-out cross-validation for polynomials in the Auto data set.
</figcaption>
</figure>
</div>
<p>Fortunately, the leave-one-out cross-validation error can be computed for some model classes without fitting the model <span class="math inline">\(n\)</span> times. For linear regression models, formulas exist to compute the LOO prediction error from information available after just training the model once on all observations. Wait, what?</p>
<p>Suppose we are predicting the target value of the <span class="math inline">\(i\)</span><sup>th</sup> observation in the LOO step when that observation is not in the training set and denote this predicted value as <span class="math inline">\(\widehat{y}_{-i}\)</span>. The LOO cross-validation error using a squared error loss function is then</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{y}}_{- i} \right)^{2}\]</span></p>
<p>The sum in this expression is called the PRESS statistic (for <strong>pre</strong>diction <strong>s</strong>um of <strong>s</strong>quares). The interesting result is that<span class="math inline">\({\widehat{\ y}}_{- i}\)</span> can be calculated as</p>
<p><span class="math display">\[y_i - \widehat{y}_{-i} = \frac{y_i - \widehat{y}_i}{1 - h_{ii}}\]</span></p>
<p>where <span class="math inline">\(h_{ii}\)</span> is called the <strong>leverage</strong> of the <span class="math inline">\(i\)</span><sup>th</sup> observation. We will discuss the leverage in more detail in the context of linear model diagnostics. At this point it is sufficient to note that the leverage measures how unusual an observation is with respect to the input variables of the model and that <span class="math inline">\(0 &lt; h_{ii} &lt; 1\)</span>.</p>
<p>The term in the numerator is the regular residual for <span class="math inline">\(y_{i}\)</span>. In other words, we can calculate the leave-one-out prediction error from the difference between observed and predicted values in the full training data by adjusting for the leverage. Since <span class="math inline">\(0 &lt; h_{ii} &lt; 1\)</span>, it follows that</p>
<p><span class="math display">\[y_i - \widehat{y}_{-i} &gt; y_i - \widehat{y}_i\]</span></p>
<p>Predicting an observation that was not used in training the model cannot be more precise than predicting the observation if it is part of the training set.</p>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;2.5: Accuracy and precision—the dart board bullseye metaphor.</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;2.12: Example of 5-fold cross-validation for 100 observations. Numbers in the cells represent observation numbers. The records were randomly arranged prior to assigning the folds.</span>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./statmodels.html" class="pagination-link" aria-label="Statistical Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistical Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./linalg.html" class="pagination-link" aria-label="Linear Algebra Review">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Statistical Learning by Oliver Schabenberger</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","closeEffect":"zoom","selector":".lightbox","loop":false,"descPosition":"bottom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>